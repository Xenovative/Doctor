#!/usr/bin/env python3
"""
Comprehensive AI Analysis Unit Test Suite
Tests medical reference relevance and CHP guideline mapping accuracy
"""

import json
import requests
import time
from datetime import datetime
import sys
import os

class AIAnalysisTester:
    def __init__(self, base_url="http://localhost:5000"):
        self.base_url = base_url
        self.test_results = []
        self.chp_content = None

    def load_chp_content(self):
        """Load CHP content database for reference"""
        try:
            with open('assets/content.json', 'r', encoding='utf-8') as f:
                self.chp_content = json.load(f)
                print(f"âœ… Loaded {len(self.chp_content)} CHP entries")
        except Exception as e:
            print(f"âŒ Failed to load CHP content: {e}")
            return False
        return True

    def test_ai_analysis(self, symptoms, expected_chp_topics=None, test_name=""):
        """Test single AI analysis with symptom set"""
        print(f"\nğŸ§ª Testing: {test_name}")
        print(f"   Symptoms: {symptoms}")

        try:
            # Make request to AI analysis endpoint
            response = requests.post(
                f"{self.base_url}/analyze",
                json={"symptoms": symptoms},
                timeout=30
            )

            if response.status_code != 200:
                return {
                    "test_name": test_name,
                    "symptoms": symptoms,
                    "status": "FAILED",
                    "error": f"HTTP {response.status_code}",
                    "response": None
                }

            result = response.json()
            analysis = result.get('analysis', '')

            # Extract symptoms from analysis for CHP mapping
            extracted_symptoms = self.extract_symptoms_from_analysis(analysis)

            # Test CHP relevance
            chp_relevance = self.test_chp_relevance(extracted_symptoms, expected_chp_topics)

            # Test PubMed relevance (if available)
            pubmed_relevance = self.test_pubmed_relevance(analysis, symptoms)

            test_result = {
                "test_name": test_name,
                "symptoms": symptoms,
                "extracted_symptoms": extracted_symptoms,
                "status": "PASSED",
                "chp_relevance": chp_relevance,
                "pubmed_relevance": pubmed_relevance,
                "analysis_preview": analysis[:200] + "..." if len(analysis) > 200 else analysis
            }

            return test_result

        except Exception as e:
            return {
                "test_name": test_name,
                "symptoms": symptoms,
                "status": "FAILED",
                "error": str(e),
                "response": None
            }

    def extract_symptoms_from_analysis(self, analysis_text):
        """Extract medical terms from AI analysis text"""
        symptoms = []

        # Look for symptom sections in Chinese analysis
        import re

        # Common patterns for symptom extraction
        patterns = [
            r'ç—‡ç‹€åˆ†æï¼š(.*?)(?=ç›¸é—œå°ˆç§‘|ç·Šæ€¥ç¨‹åº¦|è³‡è¨Š|$)',
            r'ä¸»è¦ç—‡ç‹€åŒ…æ‹¬ï¼š(.*?)(?=ç›¸é—œå°ˆç§‘|ç·Šæ€¥ç¨‹åº¦|è³‡è¨Š|$)',
            r'æ‚£è€…å‡ºç¾(.*?)(?=ç›¸é—œå°ˆç§‘|ç·Šæ€¥ç¨‹åº¦|è³‡è¨Š|$)'
        ]

        for pattern in patterns:
            match = re.search(pattern, analysis_text, re.DOTALL)
            if match:
                symptom_text = match.group(1)
                # Extract individual symptoms
                symptom_list = re.findall(r'[\u4e00-\u9fff]{2,6}', symptom_text)
                symptoms.extend(symptom_list)
                break

        return list(set(symptoms))  # Remove duplicates

    def test_chp_relevance(self, symptoms, expected_topics=None):
        """Test CHP content relevance for given symptoms"""
        if not self.chp_content:
            return {"score": 0, "matched_topics": [], "error": "CHP content not loaded"}

        relevant_entries = []
        matched_symptoms = []

        # Symptom to CHP topic mapping (same as in medical-evidence.js)
        symptom_mappings = {
            'å¿ƒè‡Ÿç—…': ['å¿ƒè‡Ÿç—…'],
            'ç³–å°¿ç—…': ['ç³–å°¿ç—…'],
            'é«˜è¡€å£“': ['å¿ƒè‡Ÿç—…'],
            'æµæ„Ÿ': ['ä¹™å‹æµæ„Ÿå—œè¡€æ¡¿èŒæ„ŸæŸ“'],
            'æ„Ÿå†’': ['2019å† ç‹€ç—…æ¯’ç—…'],
            'å’³å—½': ['2019å† ç‹€ç—…æ¯’ç—…', 'è‚ºç‚çƒèŒæ„ŸæŸ“'],
            'ç™¼ç‡’': ['2019å† ç‹€ç—…æ¯’ç—…', 'æ°´ç—˜'],
            'å–‰åš¨ç—›': ['2019å† ç‹€ç—…æ¯’ç—…', 'çŒ©ç´…ç†±'],
            'å‘¼å¸å›°é›£': ['2019å† ç‹€ç—…æ¯’ç—…', 'è‚ºç‚çƒèŒæ„ŸæŸ“'],
            'è‚ºç‚': ['è‚ºç‚çƒèŒæ„ŸæŸ“', 'è‚ºç‚æ”¯åŸé«”æ„ŸæŸ“'],
            'è…¹ç—›': ['è«¾å¦‚ç—…æ¯’æ„ŸæŸ“'],
            'è…¹ç€‰': ['è«¾å¦‚ç—…æ¯’æ„ŸæŸ“'],
            'å˜”å': ['è«¾å¦‚ç—…æ¯’æ„ŸæŸ“'],
            'èƒ¸ç—›': ['å¿ƒè‡Ÿç—…'],
            'ç–²å€¦': ['ç³–å°¿ç—…', 'å¿ƒè‡Ÿç—…'],
            'å¤šå°¿': ['ç³–å°¿ç—…'],
            'å¤šé£²': ['ç³–å°¿ç—…'],
            'çš®ç–¹': ['æ°´ç—˜', 'æ‰‹è¶³å£ç—…'],
            'é ­ç—›': ['2019å† ç‹€ç—…æ¯’ç—…'],
            'é ­æšˆ': ['å¿ƒè‡Ÿç—…', 'ç³–å°¿ç—…'],
            'æ‰‹è¶³å£': ['æ‰‹è¶³å£ç—…'],
            'æ°´ç—˜': ['æ°´ç—˜'],
            'æŠ‘é¬±': ['å¿ƒç†å¥åº·'],
            'ç„¦æ…®': ['å¿ƒç†å¥åº·'],
            'ç‡Ÿé¤Š': ['é£²é£Ÿèˆ‡ç‡Ÿé¤Š'],
            'é£²é£Ÿ': ['é£²é£Ÿèˆ‡ç‡Ÿé¤Š']
        }

        for symptom in symptoms:
            for key, topics in symptom_mappings.items():
                if key in symptom or symptom in key:
                    matched_symptoms.append(symptom)
                    for topic in topics:
                        # Find actual CHP entries
                        chp_entries = [entry for entry in self.chp_content
                                     if entry.get('title', '').find(topic) >= 0]
                        relevant_entries.extend(chp_entries)
                    break

        # Remove duplicates
        seen_urls = set()
        unique_entries = []
        for entry in relevant_entries:
            if entry['url'] not in seen_urls:
                seen_urls.add(entry['url'])
                unique_entries.append(entry)

        # Calculate relevance score
        total_matched = len(matched_symptoms)
        total_entries = len(unique_entries)

        if total_matched == 0:
            relevance_score = 0
        else:
            # Score based on coverage and quality
            coverage_score = min(total_entries / max(total_matched, 1), 1.0) * 50
            quality_score = min(total_entries * 10, 50)  # Max 50 points for quality
            relevance_score = min(coverage_score + quality_score, 100)

        return {
            "score": round(relevance_score, 1),
            "matched_symptoms": matched_symptoms,
            "matched_topics": [entry['title'].replace('è¡ç”Ÿé˜²è­·ä¸­å¿ƒ - ', '') for entry in unique_entries[:3]],
            "total_entries": total_entries,
            "expected_topics": expected_topics or []
        }

    def test_pubmed_relevance(self, analysis_text, original_symptoms):
        """Test PubMed reference relevance"""
        # This is a simplified check - in reality we'd need to test the actual PubMed integration
        pubmed_mentions = analysis_text.count('PubMed') + analysis_text.count('é†«å­¸æ–‡ç»')

        # Check if analysis mentions medical literature
        has_medical_refs = pubmed_mentions > 0

        # Basic relevance scoring based on medical terminology
        medical_terms = ['è‡¨åºŠ', 'ç ”ç©¶', 'è­‰æ“š', 'é†«å­¸', 'æ²»ç™‚', 'è¨ºæ–·', 'è‡¨åºŠè©¦é©—']
        medical_term_count = sum(1 for term in medical_terms if term in analysis_text)

        relevance_score = min(medical_term_count * 15 + (pubmed_mentions * 20), 100)

        return {
            "score": round(relevance_score, 1),
            "has_medical_references": has_medical_refs,
            "pubmed_mentions": pubmed_mentions,
            "medical_terms_found": medical_term_count
        }

    def run_comprehensive_tests(self):
        """Run comprehensive test suite"""
        print("ğŸš€ Starting Comprehensive AI Analysis Test Suite")
        print("=" * 60)

        if not self.load_chp_content():
            print("âŒ Cannot proceed without CHP content")
            return []

        # Test cases with various symptom combinations
        test_cases = [
            # Respiratory infections
            {
                "name": "Common Cold Symptoms",
                "symptoms": ["å–‰åš¨ç—›", "é¼»å¡", "è¼•å¾®å’³å—½"],
                "expected_chp": ["2019å† ç‹€ç—…æ¯’ç—…"]
            },
            {
                "name": "Flu-like Symptoms",
                "symptoms": ["ç™¼ç‡’", "å’³å—½", "é ­ç—›", "å–‰åš¨ç—›"],
                "expected_chp": ["2019å† ç‹€ç—…æ¯’ç—…"]
            },
            {
                "name": "Severe Respiratory",
                "symptoms": ["é«˜ç‡’", "åŠ‡çƒˆå’³å—½", "å‘¼å¸å›°é›£"],
                "expected_chp": ["2019å† ç‹€ç—…æ¯’ç—…", "è‚ºç‚çƒèŒæ„ŸæŸ“"]
            },

            # Gastrointestinal
            {
                "name": "Food Poisoning",
                "symptoms": ["è…¹ç—›", "è…¹ç€‰", "å˜”å"],
                "expected_chp": ["è«¾å¦‚ç—…æ¯’æ„ŸæŸ“"]
            },
            {
                "name": "Stomach Issues",
                "symptoms": ["èƒƒç—›", "è…¹ç€‰", "å™å¿ƒ"],
                "expected_chp": ["è«¾å¦‚ç—…æ¯’æ„ŸæŸ“"]
            },

            # Chronic diseases
            {
                "name": "Diabetes Symptoms",
                "symptoms": ["å£æ¸´", "å¤šå°¿", "ç–²å€¦", "é«”é‡æ¸›è¼•"],
                "expected_chp": ["ç³–å°¿ç—…"]
            },
            {
                "name": "Heart Disease",
                "symptoms": ["èƒ¸ç—›", "å‘¼å¸å›°é›£", "ç–²å€¦"],
                "expected_chp": ["å¿ƒè‡Ÿç—…"]
            },
            {
                "name": "Hypertension",
                "symptoms": ["é ­ç—›", "é ­æšˆ", "é«˜è¡€å£“"],
                "expected_chp": ["å¿ƒè‡Ÿç—…"]
            },

            # Skin conditions
            {
                "name": "Chickenpox",
                "symptoms": ["ç™¼ç‡’", "çš®ç–¹", "æ°´æ³¡"],
                "expected_chp": ["æ°´ç—˜"]
            },
            {
                "name": "Hand Foot Mouth",
                "symptoms": ["ç™¼ç‡’", "å£è…”æ½°ç˜", "æ‰‹è¶³çš®ç–¹"],
                "expected_chp": ["æ‰‹è¶³å£ç—…"]
            },

            # Mental health
            {
                "name": "Mental Health",
                "symptoms": ["æŠ‘é¬±", "ç„¦æ…®", "å£“åŠ›å¤§"],
                "expected_chp": ["å¿ƒç†å¥åº·"]
            },

            # Mixed symptoms
            {
                "name": "Complex Case",
                "symptoms": ["ç™¼ç‡’", "å’³å—½", "èƒ¸ç—›", "ç–²å€¦"],
                "expected_chp": ["2019å† ç‹€ç—…æ¯’ç—…", "å¿ƒè‡Ÿç—…"]
            }
        ]

        all_results = []

        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“Š Test {i}/{len(test_cases)}")

            result = self.test_ai_analysis(
                symptoms=test_case["symptoms"],
                expected_chp_topics=test_case["expected_chp"],
                test_name=test_case["name"]
            )

            all_results.append(result)

            # Show immediate results
            status_emoji = "âœ…" if result["status"] == "PASSED" else "âŒ"
            chp_score = result.get("chp_relevance", {}).get("score", 0)
            pubmed_score = result.get("pubmed_relevance", {}).get("score", 0)

            print(f"   {status_emoji} CHP Relevance: {chp_score}/100")
            print(f"   {status_emoji} PubMed Relevance: {pubmed_score}/100")

            if result["status"] == "FAILED":
                print(f"   âŒ Error: {result.get('error', 'Unknown')}")

        return all_results

    def generate_report(self, results):
        """Generate comprehensive test report"""
        print("\n" + "="*80)
        print("ğŸ“Š COMPREHENSIVE AI ANALYSIS TEST REPORT")
        print("="*80)

        # Summary statistics
        total_tests = len(results)
        passed_tests = sum(1 for r in results if r["status"] == "PASSED")
        failed_tests = total_tests - passed_tests

        print("
ğŸ¯ OVERALL RESULTS:"        print(f"   Total Tests: {total_tests}")
        print(f"   âœ… Passed: {passed_tests}")
        print(f"   âŒ Failed: {failed_tests}")
        print(".1f"
        # CHP Relevance Analysis
        chp_scores = [r.get("chp_relevance", {}).get("score", 0) for r in results if r["status"] == "PASSED"]
        if chp_scores:
            avg_chp = sum(chp_scores) / len(chp_scores)
            print("
ğŸ¥ CHP GUIDELINES ANALYSIS:"            print(".1f"            print(f"   Highest: {max(chp_scores)}/100")
            print(f"   Lowest: {min(chp_scores)}/100")

        # PubMed Relevance Analysis
        pubmed_scores = [r.get("pubmed_relevance", {}).get("score", 0) for r in results if r["status"] == "PASSED"]
        if pubmed_scores:
            avg_pubmed = sum(pubmed_scores) / len(pubmed_scores)
            print("
ğŸ“š PUBMED REFERENCES ANALYSIS:"            print(".1f"            print(f"   Highest: {max(pubmed_scores)}/100")
            print(f"   Lowest: {min(pubmed_scores)}/100")

        # Detailed results
        print("
ğŸ“‹ DETAILED TEST RESULTS:"        print("-" * 80)

        for i, result in enumerate(results, 1):
            status = result["status"]
            status_emoji = "âœ…" if status == "PASSED" else "âŒ"

            print(f"\n{i}. {status_emoji} {result['test_name']}")

            if status == "PASSED":
                chp = result.get("chp_relevance", {})
                pubmed = result.get("pubmed_relevance", {})

                print(f"   Symptoms: {', '.join(result['symptoms'])}")
                print(f"   Extracted: {', '.join(result.get('extracted_symptoms', []))}")
                print(f"   CHP Score: {chp.get('score', 0)}/100")
                print(f"   PubMed Score: {pubmed.get('score', 0)}/100")

                if chp.get("matched_topics"):
                    print(f"   CHP Topics: {', '.join(chp['matched_topics'][:2])}")

            else:
                print(f"   Error: {result.get('error', 'Unknown')}")

        # Recommendations
        print("
ğŸ’¡ RECOMMENDATIONS:"        print("-" * 80)

        if avg_chp < 70:
            print("âš ï¸  CHP mapping needs improvement - consider expanding symptom coverage")

        if avg_pubmed < 60:
            print("âš ï¸  PubMed integration may need enhancement")

        if failed_tests > 0:
            print(f"âš ï¸  {failed_tests} tests failed - check AI analysis endpoint")

        print("
âœ… Testing completed!"        print(f"Report generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        return {
            "summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "avg_chp_score": round(sum(chp_scores) / len(chp_scores), 1) if chp_scores else 0,
                "avg_pubmed_score": round(sum(pubmed_scores) / len(pubmed_scores), 1) if pubmed_scores else 0
            },
            "detailed_results": results
        }


def main():
    """Main test runner"""
    tester = AIAnalysisTester()

    # Run comprehensive tests
    results = tester.run_comprehensive_tests()

    # Generate report
    report = tester.generate_report(results)

    # Save results to file
    with open('ai_analysis_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print("
ğŸ’¾ Results saved to ai_analysis_test_results.json"    return report


if __name__ == "__main__":
    main()
