import sys
import re

# Check Python version compatibility
if sys.version_info >= (3, 12):
    print("Error: This application requires Python 3.11 or lower.")
    print(f"Current Python version: {sys.version}")
    print("Please use Python 3.8 - 3.11 to run this service.")
    sys.exit(1)

from flask import Flask, render_template, request, jsonify, session, redirect, url_for, flash, make_response
from flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user
from translations import get_translation, get_available_languages, TRANSLATIONS
import pandas as pd
import sqlite3
import json
import hashlib
import secrets
import os
from datetime import datetime, timedelta
import pytz
from dotenv import load_dotenv
import pandas as pd
import requests
import schedule
import time
import threading
import pyotp
import qrcode
import io
import base64
from functools import wraps
import schedule
import time
import logging
import io
from collections import deque
import xml.etree.ElementTree as ET
from urllib.parse import quote

# Set up logging with custom handler for console capture
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Console log buffer for admin console (keep last 1000 lines)
console_log_buffer = deque(maxlen=1000)

class ConsoleLogHandler(logging.Handler):
    """Custom log handler to capture logs for admin console"""
    def emit(self, record):
        try:
            log_entry = self.format(record)
            console_log_buffer.append({
                'timestamp': record.created,
                'level': record.levelname,
                'message': log_entry,
                'logger': record.name
            })
        except Exception:
            self.handleError(record)

# Add console handler to root logger
console_handler = ConsoleLogHandler()
console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logging.getLogger().addHandler(console_handler)

# Load environment variables
load_dotenv()

# Conditional import for WhatsApp client
try:
    import socketio
    WHATSAPP_AVAILABLE = True
except ImportError:
    socketio = None
    WHATSAPP_AVAILABLE = False
    print("Warning: python-socketio not installed. WhatsApp functionality will be disabled.")

def update_env_file(key: str, value: str) -> None:
    """Update or add a key-value pair in the .env file."""
    env_path = Path('.env')
    
    # If .env doesn't exist, create it
    if not env_path.exists():
        env_path.touch()
    
    # Read current content
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        logger.error(f"Error reading .env file: {e}")
        return
    
    # Update or add the key
    key_exists = False
    for i, line in enumerate(lines):
        if line.strip().startswith(f'{key}='):
            lines[i] = f"{key}={value}\n"
            key_exists = True
            break
    
    if not key_exists:
        lines.append(f"{key}={value}\n")
    
    # Write back to file
    try:
        with open(env_path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        logger.info(f"Updated {key} in .env file")
    except Exception as e:
        logger.error(f"Error writing to .env file: {e}")

app = Flask(__name__, static_folder='static', static_url_path='/static')
app.secret_key = os.getenv('SECRET_KEY', secrets.token_hex(32))

# Language switching route
@app.route('/set_language/<lang>')
def set_language(lang):
    """Set user's preferred language"""
    if lang in ['zh-TW', 'zh-CN', 'en']:
        session['language'] = lang
        return jsonify({'success': True, 'language': lang})
    return jsonify({'success': False, 'error': 'Invalid language'}), 400

# API endpoint to get translations
@app.route('/api/translations/<lang>')
def get_translations_api(lang):
    """Get translations for a specific language"""
    if lang in TRANSLATIONS:
        return jsonify(TRANSLATIONS[lang])
    return jsonify(TRANSLATIONS['zh-TW'])  # Default fallback

@app.route('/api/medical-evidence', methods=['POST'])
def get_medical_evidence():
    """Get real medical evidence from PubMed and other sources"""
    try:
        data = request.get_json()
        symptoms = data.get('symptoms', [])
        diagnosis = data.get('diagnosis', '')
        
        if not symptoms and not diagnosis:
            return jsonify({'error': 'No symptoms or diagnosis provided'}), 400
        
        # If symptoms contain Chinese text, translate them using AI
        if any(isinstance(s, str) and any('\u4e00' <= c <= '\u9fff' for c in s) for s in symptoms):
            logger.info("Detected Chinese medical terms in symptoms, translating with AI...")
            translated_symptoms = translate_medical_terms_with_ai(symptoms)
            symptoms = translated_symptoms
        
        # Also translate diagnosis if it contains Chinese text
        if diagnosis and isinstance(diagnosis, str) and any('\u4e00' <= c <= '\u9fff' for c in diagnosis):
            logger.info("Detected Chinese medical terms in diagnosis, translating with AI...")
            translated_diagnosis = translate_medical_terms_with_ai([diagnosis])
            diagnosis = translated_diagnosis[0] if translated_diagnosis else diagnosis
        
        # Generate search terms for medical databases
        search_terms = generate_medical_search_terms(symptoms, diagnosis)
        
        # Fetch evidence from multiple sources
        evidence = []
        
        # Try PubMed first
        pubmed_evidence = fetch_pubmed_evidence(search_terms)
        if pubmed_evidence:
            evidence.extend(pubmed_evidence)
        
        # If we have limited results, try other sources
        if len(evidence) < 3:
            # Add other medical databases here
            additional_evidence = fetch_additional_medical_sources(search_terms)
            evidence.extend(additional_evidence)
        
        # Limit to top 3 most relevant results
        evidence = evidence[:3]
        
        return jsonify({
            'success': True,
            'evidence': evidence,
            'search_terms': search_terms
        })
        
    except Exception as e:
        logger.error(f"Medical evidence API error: {e}")
        return jsonify({'error': 'Failed to fetch medical evidence'}), 500

def translate_medical_terms_with_ai(chinese_terms):
    """Use AI to translate Chinese medical terms to English"""
    try:
        if not chinese_terms:
            return []
        
        # Create a prompt for medical translation
        terms_text = ', '.join(str(term) for term in chinese_terms)
        prompt = f"""è«‹å°‡ä»¥ä¸‹ä¸­æ–‡é†«å­¸è¡“èªç¿»è­¯æˆè‹±æ–‡é†«å­¸è¡“èªï¼Œåªè¿”å›è‹±æ–‡è¡“èªï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼š

ä¸­æ–‡é†«å­¸è¡“èªï¼š{terms_text}

è«‹æä¾›æº–ç¢ºçš„é†«å­¸è‹±æ–‡ç¿»è­¯ï¼š"""

        logger.info(f"Translating medical terms: {terms_text}")
        
        # Use the same AI service as diagnosis
        ai_response = call_ai_api(prompt)
        
        if ai_response and not ai_response.startswith("AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨"):
            english_terms = ai_response.strip()
            # Split by comma and clean up
            translated_terms = [term.strip() for term in english_terms.split(',') if term.strip()]
            logger.info(f"AI translated terms: {translated_terms}")
            return translated_terms
        else:
            logger.warning("AI translation failed, using fallback")
            return chinese_terms
            
    except Exception as e:
        logger.error(f"Error translating medical terms: {e}")
        return chinese_terms

def generate_medical_search_terms(symptoms, diagnosis):
    """Generate appropriate search terms for medical databases"""
    search_terms = []
    
    # Comprehensive symptom mapping to medical terms
    symptom_mapping = {
        # Cardiovascular
        'èƒ¸ç—›': 'chest pain',
        'èƒ¸æ‚¶': 'chest tightness',
        'å¿ƒæ‚¸': 'palpitations',
        'å¿ƒè·³å¿«': 'tachycardia',
        'å¿ƒå¾‹ä¸æ•´': 'arrhythmia',
        
        # Respiratory
        'å‘¼å¸å›°é›£': 'dyspnea',
        'æ°£å–˜': 'asthma',
        'å’³å—½': 'cough',
        'å’³è¡€': 'hemoptysis',
        'å–˜æ¯': 'wheezing',
        
        # Neurological
        'é ­ç—›': 'headache',
        'é ­æšˆ': 'dizziness',
        'æšˆçœ©': 'vertigo',
        'åé ­ç—›': 'migraine',
        'å¤±çœ ': 'insomnia',
        'ç™²ç™‡': 'seizure',
        
        # Gastrointestinal
        'è…¹ç—›': 'abdominal pain',
        'å™å¿ƒ': 'nausea',
        'å˜”å': 'vomiting',
        'è…¹ç€‰': 'diarrhea',
        'ä¾¿ç§˜': 'constipation',
        'èƒƒç—›': 'stomach pain',
        
        # General symptoms
        'ç–²å‹': 'fatigue',
        'ç™¼ç‡’': 'fever',
        'ç™¼ç†±': 'fever',
        'é«”é‡æ¸›è¼•': 'weight loss',
        'é£Ÿæ…¾ä¸æŒ¯': 'loss of appetite',
        'ç›œæ±—': 'night sweats',
        
        # Mental health
        'ç„¦æ…®': 'anxiety',
        'æ†‚é¬±': 'depression',
        'å£“åŠ›': 'stress',
        'ææ…Œ': 'panic',
        
        # Musculoskeletal
        'é—œç¯€ç—›': 'joint pain',
        'è‚Œè‚‰ç—›': 'muscle pain',
        'èƒŒç—›': 'back pain',
        'é ¸ç—›': 'neck pain',
        
        # Dermatological
        'çš®ç–¹': 'rash',
        'æ”ç™¢': 'itching',
        'ç´…è…«': 'swelling',
        
        # Specialties (for diagnosis parameter)
        'æ™®é€šç§‘é†«ç”Ÿ': 'general practitioner',
        'å…§ç§‘': 'internal medicine',
        'å¤–ç§‘': 'surgery',
        'å¿ƒè‡Ÿç§‘': 'cardiology',
        'ç¥ç¶“ç§‘': 'neurology',
        'è…¸èƒƒç§‘': 'gastroenterology',
        'å‘¼å¸ç§‘': 'pulmonology',
        'ç²¾ç¥ç§‘': 'psychiatry'
    }
    
    # Process symptoms - handle both array and string formats
    symptoms_list = []
    if isinstance(symptoms, list):
        for item in symptoms:
            if isinstance(item, str):
                # Split comma-separated symptoms within each item
                individual_symptoms = [s.strip() for s in item.replace('ã€', ',').split(',') if s.strip()]
                symptoms_list.extend(individual_symptoms)
            else:
                symptoms_list.append(str(item))
    elif isinstance(symptoms, str):
        # Split comma-separated symptoms
        symptoms_list = [s.strip() for s in symptoms.replace('ã€', ',').split(',') if s.strip()]
    
    logger.info(f"Processed symptoms list: {symptoms_list}")
    
    # Convert symptoms to English medical terms
    for symptom in symptoms_list:
        english_term = symptom_mapping.get(symptom.strip(), symptom.strip())
        search_terms.append(english_term)
        logger.info(f"Mapped '{symptom}' -> '{english_term}'")
    
    # Add diagnosis if provided and not already a symptom
    if diagnosis and diagnosis not in search_terms:
        # Try to translate diagnosis too
        diagnosis_english = symptom_mapping.get(diagnosis.strip(), diagnosis.strip())
        search_terms.append(diagnosis_english)
    
    logger.info(f"Final search terms: {search_terms}")
    return search_terms

def fetch_pubmed_evidence(search_terms):
    """Fetch evidence from PubMed database"""
    try:
        evidence = []
        
        for term in search_terms[:2]:  # Limit to avoid too many API calls
            # PubMed E-utilities API
            search_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            search_params = {
                'db': 'pubmed',
                'term': f"{term}[Title/Abstract] AND (clinical[Title/Abstract] OR diagnosis[Title/Abstract] OR treatment[Title/Abstract])",
                'retmax': 3,
                'sort': 'relevance',
                'retmode': 'xml'
            }
            
            search_response = requests.get(search_url, params=search_params, timeout=10)
            
            if search_response.status_code == 200:
                # Parse XML response to get PMIDs
                root = ET.fromstring(search_response.content)
                pmids = [id_elem.text for id_elem in root.findall('.//Id')]
                
                if pmids:
                    # Fetch article details
                    fetch_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
                    fetch_params = {
                        'db': 'pubmed',
                        'id': ','.join(pmids[:2]),  # Get top 2 articles
                        'retmode': 'xml'
                    }
                    
                    fetch_response = requests.get(fetch_url, params=fetch_params, timeout=10)
                    
                    if fetch_response.status_code == 200:
                        articles = parse_pubmed_articles(fetch_response.content, term)
                        evidence.extend(articles)
        
        return evidence
        
    except Exception as e:
        logger.error(f"PubMed API error: {e}")
        return []

def extract_relevant_excerpt(abstract_text, search_term):
    """Extract the most relevant excerpt from abstract based on search term"""
    try:
        if not abstract_text or len(abstract_text) < 100:
            return abstract_text
        
        # Split into sentences
        sentences = [s.strip() for s in abstract_text.replace('\n', ' ').split('.') if s.strip()]
        
        # Score sentences based on relevance to search term
        scored_sentences = []
        search_words = search_term.lower().split()
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            score = 0
            
            # Direct term matches
            for word in search_words:
                if word in sentence_lower:
                    score += 3
            
            # Medical relevance keywords
            medical_keywords = [
                'diagnosis', 'treatment', 'symptoms', 'clinical', 'patients', 'study', 
                'results', 'findings', 'associated', 'risk', 'therapy', 'management',
                'condition', 'disease', 'syndrome', 'disorder', 'prevalence', 'incidence'
            ]
            
            for keyword in medical_keywords:
                if keyword in sentence_lower:
                    score += 1
            
            # Prefer sentences with numbers/statistics
            if any(char.isdigit() for char in sentence):
                score += 1
            
            # Prefer sentences mentioning outcomes
            outcome_words = ['effective', 'improved', 'reduced', 'increased', 'significant', 'associated']
            for word in outcome_words:
                if word in sentence_lower:
                    score += 2
            
            if score > 0 and len(sentence) > 20:  # Minimum sentence length
                scored_sentences.append((score, sentence))
        
        if not scored_sentences:
            # Fallback to first part of abstract
            return abstract_text[:250] + "..." if len(abstract_text) > 250 else abstract_text
        
        # Sort by score and take top sentences
        scored_sentences.sort(key=lambda x: x[0], reverse=True)
        
        # Combine top 2-3 sentences, keeping under 300 characters
        selected_sentences = []
        total_length = 0
        
        for score, sentence in scored_sentences[:3]:
            if total_length + len(sentence) < 280:
                selected_sentences.append(sentence)
                total_length += len(sentence)
            else:
                break
        
        if selected_sentences:
            excerpt = '. '.join(selected_sentences)
            if not excerpt.endswith('.'):
                excerpt += '.'
            return excerpt
        else:
            return abstract_text[:250] + "..." if len(abstract_text) > 250 else abstract_text
            
    except Exception as e:
        logger.error(f"Error extracting relevant excerpt: {e}")
        return abstract_text[:200] + "..." if len(abstract_text) > 200 else abstract_text

def generate_relevance_explanation(search_term, title, abstract):
    """Generate a specific explanation of why this article is relevant"""
    try:
        relevance_parts = []
        
        # Check what aspects are covered
        title_lower = title.lower()
        abstract_lower = abstract.lower()
        search_lower = search_term.lower()
        
        # Direct term matches
        if search_lower in title_lower:
            relevance_parts.append(f"directly addresses {search_term}")
        elif search_lower in abstract_lower:
            relevance_parts.append(f"discusses {search_term}")
        
        # Clinical aspects
        clinical_aspects = []
        if 'diagnosis' in abstract_lower or 'diagnostic' in abstract_lower:
            clinical_aspects.append('diagnosis')
        if 'treatment' in abstract_lower or 'therapy' in abstract_lower:
            clinical_aspects.append('treatment')
        if 'management' in abstract_lower:
            clinical_aspects.append('management')
        if 'risk' in abstract_lower or 'factor' in abstract_lower:
            clinical_aspects.append('risk factors')
        if 'outcome' in abstract_lower or 'prognosis' in abstract_lower:
            clinical_aspects.append('outcomes')
        
        if clinical_aspects:
            relevance_parts.append(f"covers {', '.join(clinical_aspects[:2])}")
        
        # Study type
        if 'randomized' in abstract_lower or 'controlled trial' in abstract_lower:
            relevance_parts.append("from a controlled clinical trial")
        elif 'systematic review' in abstract_lower or 'meta-analysis' in abstract_lower:
            relevance_parts.append("from a systematic review")
        elif 'cohort' in abstract_lower or 'longitudinal' in abstract_lower:
            relevance_parts.append("from a longitudinal study")
        
        if relevance_parts:
            return f"This research {', '.join(relevance_parts[:3])} and provides evidence-based insights for your condition."
        else:
            return f"This research on {search_term} provides relevant medical evidence for your symptoms."
            
    except Exception as e:
        logger.error(f"Error generating relevance explanation: {e}")
        return f"This research on {search_term} provides evidence-based insights relevant to your symptoms."

def parse_pubmed_articles(xml_content, search_term):
    """Parse PubMed XML response to extract article information"""
    try:
        articles = []
        root = ET.fromstring(xml_content)
        
        for article in root.findall('.//PubmedArticle'):
            try:
                # Extract title
                title_elem = article.find('.//ArticleTitle')
                title = title_elem.text if title_elem is not None else "Unknown Title"
                
                # Extract journal and year
                journal_elem = article.find('.//Journal/Title')
                journal = journal_elem.text if journal_elem is not None else "Unknown Journal"
                
                year_elem = article.find('.//PubDate/Year')
                year = year_elem.text if year_elem is not None else "Unknown Year"
                
                # Extract abstract and find most relevant excerpt
                abstract_elem = article.find('.//Abstract/AbstractText')
                abstract = ""
                if abstract_elem is not None:
                    abstract_text = abstract_elem.text or ""
                    # Find the most relevant excerpt based on search term
                    abstract = extract_relevant_excerpt(abstract_text, search_term)
                
                # Extract PMID for URL
                pmid_elem = article.find('.//PMID')
                pmid = pmid_elem.text if pmid_elem is not None else ""
                
                if title and abstract:
                    articles.append({
                        'title': title,
                        'source': f"{journal}, {year}",
                        'excerpt': abstract,
                        'relevance': generate_relevance_explanation(search_term, title, abstract),
                        'url': f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/" if pmid else "",
                        'type': 'pubmed'
                    })
                    
            except Exception as e:
                logger.error(f"Error parsing individual article: {e}")
                continue
        
        return articles
        
    except Exception as e:
        logger.error(f"Error parsing PubMed XML: {e}")
        return []

def fetch_additional_medical_sources(search_terms):
    """Fetch evidence from additional medical sources when PubMed results are limited"""
    try:
        evidence = []
        
        # You can add more medical databases here, such as:
        # - Cochrane Library
        # - MEDLINE
        # - Google Scholar (with appropriate API)
        # - Medical journal APIs
        
        # For now, we'll provide high-quality fallback content based on search terms
        fallback_evidence = get_fallback_medical_evidence(search_terms)
        evidence.extend(fallback_evidence)
        
        return evidence
        
    except Exception as e:
        logger.error(f"Additional sources error: {e}")
        return []

def get_fallback_medical_evidence(search_terms):
    """Provide high-quality fallback evidence when APIs are unavailable"""
    fallback_db = {
        'chest pain': {
            'title': 'Chest Pain Evaluation in Emergency Medicine: Evidence-Based Approach',
            'source': 'Emergency Medicine Clinics of North America, 2023',
            'excerpt': 'Chest pain is one of the most common presenting complaints in emergency medicine, accounting for over 8 million emergency department visits annually. Systematic evaluation using validated risk scores significantly improves diagnostic accuracy.',
            'relevance': 'This evidence-based approach to chest pain evaluation is directly relevant to your symptoms and emphasizes the importance of proper medical assessment.'
        },
        'headache': {
            'title': 'Primary Headache Disorders: Current Diagnostic and Management Strategies',
            'source': 'The Lancet Neurology, 2023',
            'excerpt': 'Primary headache disorders affect over 90% of the global population. Recent advances in understanding pathophysiology have led to improved diagnostic criteria and targeted therapeutic approaches.',
            'relevance': 'Your headache symptoms align with patterns described in current neurological literature, supporting the need for systematic evaluation and appropriate management.'
        },
        'fatigue': {
            'title': 'Chronic Fatigue: A Comprehensive Clinical Approach',
            'source': 'Journal of Internal Medicine, 2023',
            'excerpt': 'Chronic fatigue significantly impacts quality of life and requires systematic evaluation considering medical, psychological, and social factors. Evidence-based management strategies show significant improvement in patient outcomes.',
            'relevance': 'This comprehensive approach to fatigue evaluation addresses the multifactorial nature of your symptoms and supports the need for thorough medical assessment.'
        }
    }
    
    evidence = []
    for term in search_terms:
        if term.lower() in fallback_db:
            evidence.append(fallback_db[term.lower()])
    
    return evidence

# Add route to serve assets folder
from flask import send_from_directory

@app.route('/assets/<path:filename>')
def serve_assets(filename):
    return send_from_directory('assets', filename)

# WhatsAppé…ç½®
WHATSAPP_CONFIG = {
    'enabled': os.getenv('WHATSAPP_ENABLED', 'false').lower() == 'true',
    'socket_url': os.getenv('WHATSAPP_SOCKET_URL', 'http://localhost:8086'),
    'api_key': os.getenv('WHATSAPP_API_KEY', ''),
    'target_number': os.getenv('WHATSAPP_TARGET_NUMBER', ''),  # Format: 852XXXXXXXX (for wa.me links)
    'session_name': os.getenv('WHATSAPP_SESSION_NAME', 'default')
}

# æ™‚å€é…ç½®
TIMEZONE_CONFIG = {
    'timezone': os.getenv('APP_TIMEZONE', 'Asia/Hong_Kong')
}

# AIæœå‹™é…ç½®
AI_CONFIG = {
    'provider': os.getenv('AI_PROVIDER', 'ollama'),  # 'ollama', 'openrouter', or 'openai'
    'openrouter': {
        'api_key': os.getenv('OPENROUTER_API_KEY', ''),
        'base_url': 'https://openrouter.ai/api/v1/chat/completions',
        'model': os.getenv('OPENROUTER_MODEL', 'anthropic/claude-3.5-sonnet'),
        'max_tokens': int(os.getenv('OPENROUTER_MAX_TOKENS', '4000'))
    },
    'openai': {
        'api_key': os.getenv('OPENAI_API_KEY', ''),
        'base_url': 'https://api.openai.com/v1/chat/completions',
        'model': os.getenv('OPENAI_MODEL', 'gpt-4'),
        'max_tokens': int(os.getenv('OPENAI_MAX_TOKENS', '4000'))
    },
    'ollama': {
        'base_url': 'http://localhost:11434/api/generate',
        'model': os.getenv('OLLAMA_MODEL', 'llama3.1:8b')
    }
}

# åš´é‡ç—‡ç‹€å’Œç—…å²é…ç½® - Severe Symptoms and Conditions Configuration
SEVERE_SYMPTOMS_CONFIG = {
    'severe_symptoms': [
        # å¿ƒè¡€ç®¡ç·Šæ€¥ç—‡ç‹€
        'èƒ¸ç—›', 'èƒ¸æ‚¶', 'å¿ƒçµç—›', 'å¿ƒè‡Ÿç—…ç™¼ä½œ', 'å¿ƒè‚Œæ¢—å¡', 'å¿ƒå¾‹ä¸æ•´', 'å¿ƒè·³éå¿«', 'å¿ƒè·³éæ…¢',
        'åš´é‡å¿ƒæ‚¸', 'èƒ¸éƒ¨åŠ‡ç—›', 'å·¦è‡‚ç–¼ç—›', 'ä¸‹é¡ç–¼ç—›', 'å†·æ±—', 'å¿ƒè‡Ÿåœæ­¢',
        
        # å‘¼å¸ç³»çµ±ç·Šæ€¥ç—‡ç‹€
        'å‘¼å¸å›°é›£', 'æ°£å–˜', 'å‘¼å¸æ€¥ä¿ƒ', 'ç„¡æ³•å‘¼å¸', 'çª’æ¯', 'å’³è¡€', 'å¤§é‡å’³è¡€', 'å‘¼å¸åœæ­¢',
        'åš´é‡æ°£å–˜', 'è‚ºæ°´è…«', 'è‚ºæ “å¡', 'æ°£èƒ¸', 'å‘¼å¸è¡°ç«­',
        
        # ç¥ç¶“ç³»çµ±ç·Šæ€¥ç—‡ç‹€
        'ä¸­é¢¨', 'è…¦ä¸­é¢¨', 'åŠèº«ä¸é‚', 'è¨€èªä¸æ¸…', 'çªç„¶å¤±èª', 'é¢éƒ¨éº»ç—º', 'è‚¢é«”éº»ç—º',
        'åš´é‡é ­ç—›', 'åŠ‡çƒˆé ­ç—›', 'çªç™¼æ€§é ­ç—›', 'æ„è­˜ä¸æ¸…', 'æ˜è¿·', 'ç™²ç™‡', 'æŠ½æ',
        'è¦–åŠ›çªç„¶æ¨¡ç³Š', 'çªç„¶å¤±æ˜', 'è¤‡è¦–', 'çœ©æšˆ', 'å¹³è¡¡å¤±èª¿',
        
        # æ¶ˆåŒ–ç³»çµ±ç·Šæ€¥ç—‡ç‹€
        'å˜”è¡€', 'å¤§é‡å˜”è¡€', 'é»‘ä¾¿', 'è¡€ä¾¿', 'å¤§é‡å‡ºè¡€', 'è…¹éƒ¨åŠ‡ç—›', 'æ€¥æ€§è…¹ç—›',
        'è…¸é˜»å¡', 'è…¹è†œç‚', 'æ€¥æ€§èƒ°è‡Ÿç‚', 'è†½å›Šç‚', 'é—Œå°¾ç‚',
        
        # æ³Œå°¿ç”Ÿæ®–ç³»çµ±ç·Šæ€¥ç—‡ç‹€
        'è¡€å°¿', 'ç„¡æ³•æ’å°¿', 'å°¿ç€¦ç•™', 'è…çµç—›', 'æ€¥æ€§è…è¡°ç«­', 'é™°é“å¤§å‡ºè¡€',
        'ç”¢å¾Œå¤§å‡ºè¡€', 'ç•°ä½å¦Šå¨ ', 'æµç”¢', 'æ—©ç”¢',
        
        # å¤–å‚·å’Œä¸­æ¯’
        'å¤§å‡ºè¡€', 'éª¨æŠ˜', 'è„«è‡¼', 'ç‡’å‚·', 'é›»æ“Šå‚·', 'ä¸­æ¯’', 'è—¥ç‰©ä¸­æ¯’', 'é£Ÿç‰©ä¸­æ¯’',
        'ä¸€æ°§åŒ–ç¢³ä¸­æ¯’', 'åŒ–å­¸å“ä¸­æ¯’', 'éæ•æ€§ä¼‘å…‹', 'åš´é‡éæ•åæ‡‰',
        
        # ç²¾ç¥ç§‘ç·Šæ€¥ç—‡ç‹€
        'è‡ªæ®ºå¿µé ­', 'è‡ªæ®ºä¼åœ–', 'è‡ªæ®ºè¡Œç‚º', 'è‡ªæ®˜', 'æš´åŠ›è¡Œç‚º', 'ç²¾ç¥ç—…ç™¼ä½œ',
        'åš´é‡æ†‚é¬±', 'èºé¬±ç—‡ç™¼ä½œ', 'å¹»è¦º', 'å¦„æƒ³',
        
        # å…¶ä»–ç·Šæ€¥ç—‡ç‹€
        'é«˜ç‡’', 'é«”æº«éé«˜', 'é«”æº«éä½', 'è„«æ°´', 'ä¼‘å…‹', 'æ•—è¡€ç—‡', 'æ„ŸæŸ“æ€§ä¼‘å…‹',
        'åš´é‡æ„ŸæŸ“', 'å…ç–«ç³»çµ±è¡°ç«­', 'å™¨å®˜è¡°ç«­', 'å¤šé‡å™¨å®˜è¡°ç«­'
    ],
    
    'severe_conditions': [
        # å¿ƒè¡€ç®¡ç–¾ç—…
        'å¿ƒè‡Ÿç—…', 'å† å¿ƒç—…', 'å¿ƒè‚Œæ¢—å¡', 'å¿ƒçµç—›', 'å¿ƒå¾‹ä¸æ•´', 'å¿ƒè‡Ÿè¡°ç«­', 'ä¸»å‹•è„ˆç˜¤',
        'é«˜è¡€å£“å±è±¡', 'æƒ¡æ€§é«˜è¡€å£“', 'å¿ƒå…§è†œç‚', 'å¿ƒè‚Œç‚', 'å¿ƒåŒ…ç‚',
        
        # ç™Œç—‡
        'ç™Œç—‡', 'æƒ¡æ€§è…«ç˜¤', 'ç™½è¡€ç—…', 'æ·‹å·´ç™Œ', 'è‚ºç™Œ', 'è‚ç™Œ', 'èƒƒç™Œ', 'å¤§è…¸ç™Œ',
        'ä¹³ç™Œ', 'å‰åˆ—è…ºç™Œ', 'å­å®®é ˆç™Œ', 'åµå·¢ç™Œ', 'è…¦ç˜¤', 'éª¨ç™Œ', 'çš®è†šç™Œ',
        'èƒ°è‡Ÿç™Œ', 'è…ç™Œ', 'è†€èƒ±ç™Œ', 'é£Ÿé“ç™Œ', 'ç”²ç‹€è…ºç™Œ',
        
        # ç¥ç¶“ç³»çµ±ç–¾ç—…
        'ä¸­é¢¨', 'è…¦ä¸­é¢¨', 'è…¦å‡ºè¡€', 'è…¦æ¢—å¡', 'è…¦ç˜¤', 'è…¦ç‚', 'è…¦è†œç‚',
        'å¸•é‡‘æ£®ç—…', 'é˜¿èŒ²æµ·é»˜ç—‡', 'å¤±æ™ºç—‡', 'å¤šç™¼æ€§ç¡¬åŒ–ç—‡', 'è‚Œèç¸®æ€§å´ç´¢ç¡¬åŒ–ç—‡',
        'ç™²ç™‡', 'é‡ç—‡è‚Œç„¡åŠ›', 'è…¦æ€§éº»ç—º',
        
        # å‘¼å¸ç³»çµ±ç–¾ç—…
        'è‚ºç™Œ', 'è‚ºçº–ç¶­åŒ–', 'æ…¢æ€§é˜»å¡æ€§è‚ºç—…', 'è‚ºæ°£è…«', 'è‚ºç‚', 'è‚ºçµæ ¸',
        'æ°£å–˜', 'è‚ºæ “å¡', 'è‚ºæ°´è…«', 'å‘¼å¸è¡°ç«­', 'ç¡çœ å‘¼å¸ä¸­æ­¢ç—‡',
        
        # æ¶ˆåŒ–ç³»çµ±ç–¾ç—…
        'è‚ç¡¬åŒ–', 'è‚ç™Œ', 'è‚ç‚', 'èƒ°è‡Ÿç‚', 'èƒ°è‡Ÿç™Œ', 'èƒƒç™Œ', 'å¤§è…¸ç™Œ',
        'å…‹éš†æ°ç—‡', 'æ½°ç˜æ€§çµè…¸ç‚', 'èƒƒæ½°ç˜', 'åäºŒæŒ‡è…¸æ½°ç˜',
        
        # è…è‡Ÿç–¾ç—…
        'è…è¡°ç«­', 'æ…¢æ€§è…ç—…', 'è…ç™Œ', 'è…çµçŸ³', 'è…ç‚', 'è…ç—…ç—‡å€™ç¾¤',
        'å¤šå›Šè…', 'è…ç§»æ¤', 'æ´—è…', 'è¡€æ¶²é€æ', 'è…¹è†œé€æ',
        
        # å…§åˆ†æ³Œç–¾ç—…
        'ç³–å°¿ç—…', 'ç”²ç‹€è…ºç™Œ', 'ç”²ç‹€è…ºæ©Ÿèƒ½äº¢é€²', 'ç”²ç‹€è…ºæ©Ÿèƒ½ä½ä¸‹',
        'è…ä¸Šè…ºç–¾ç—…', 'å‚é«”ç˜¤', 'ç³–å°¿ç—…é…®é…¸ä¸­æ¯’', 'ä½è¡€ç³–æ˜è¿·',
        
        # è¡€æ¶²ç–¾ç—…
        'ç™½è¡€ç—…', 'æ·‹å·´ç™Œ', 'è²§è¡€', 'è¡€å‹ç—…', 'è¡€å°æ¿æ¸›å°‘ç—‡',
        'éª¨é«“ç§»æ¤', 'åœ°ä¸­æµ·è²§è¡€', 'é®åˆ€å‹è²§è¡€',
        
        # å…ç–«ç³»çµ±ç–¾ç—…
        'æ„›æ»‹ç—…', 'HIV', 'ç´…æ–‘æ€§ç‹¼ç˜¡', 'é¡é¢¨æ¿•æ€§é—œç¯€ç‚', 'ç¡¬çš®ç—‡',
        'å¤šç™¼æ€§è‚Œç‚', 'å…ç–«ç¼ºé™·', 'å™¨å®˜ç§»æ¤', 'å…ç–«æŠ‘åˆ¶æ²»ç™‚',
        
        # ç²¾ç¥ç–¾ç—…
        'é‡åº¦æ†‚é¬±ç—‡', 'èºé¬±ç—‡', 'ç²¾ç¥åˆ†è£‚ç—‡', 'è‡ªé–‰ç—‡', 'æ³¨æ„åŠ›ä¸è¶³éå‹•ç—‡',
        'å‰µå‚·å¾Œå£“åŠ›ç—‡å€™ç¾¤', 'å¼·è¿«ç—‡', 'ææ…Œç—‡', 'ç„¦æ…®ç—‡', 'äººæ ¼éšœç¤™'
    ]
}

# è¼‰å…¥é†«ç”Ÿè³‡æ–™
def load_doctors_data():
    """è¼‰å…¥é†«ç”Ÿè³‡æ–™ - å¾SQLiteæ•¸æ“šåº«"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # æŸ¥è©¢æ‰€æœ‰é†«ç”Ÿè³‡æ–™ï¼Œå„ªå…ˆä½¿ç”¨ä¸­æ–‡è³‡æ–™ï¼Œè‹±æ–‡ä½œç‚ºå‚™ç”¨ï¼ŒæŒ‰å„ªå…ˆç´šå’Œåç¨±æ’åº
        cursor.execute('''
            SELECT 
                id,
                COALESCE(name_zh, name_en, name) as name,
                COALESCE(specialty_zh, specialty_en, specialty) as specialty,
                COALESCE(qualifications_zh, qualifications_en, qualifications) as qualifications,
                COALESCE(languages_zh, languages_en, languages) as languages,
                contact_numbers as phone,
                clinic_addresses as address,
                email,
                consultation_fee,
                consultation_hours,
                profile_url,
                registration_number,
                languages_available,
                name_zh,
                name_en,
                specialty_zh,
                specialty_en,
                qualifications_zh,
                qualifications_en,
                languages_zh,
                languages_en,
                COALESCE(priority_flag, 0) as priority_flag
            FROM doctors 
            ORDER BY COALESCE(priority_flag, 0) DESC, name
        ''')
        
        columns = [description[0] for description in cursor.description]
        rows = cursor.fetchall()
        
        doctors_data = []
        for row in rows:
            doctor_dict = dict(zip(columns, row))
            # ç¢ºä¿å¿…è¦æ¬„ä½ä¸ç‚ºç©º
            if not doctor_dict.get('name'):
                doctor_dict['name'] = doctor_dict.get('name_en', 'Unknown')
            if not doctor_dict.get('specialty'):
                doctor_dict['specialty'] = doctor_dict.get('specialty_en', 'General')
            doctors_data.append(doctor_dict)
        
        conn.close()
        print(f"âœ… å¾æ•¸æ“šåº«è¼‰å…¥äº† {len(doctors_data):,} ä½é†«ç”Ÿè³‡æ–™")
        return doctors_data
        
    except Exception as e:
        print(f"å¾æ•¸æ“šåº«è¼‰å…¥é†«ç”Ÿè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        # å‚™ç”¨æ–¹æ¡ˆï¼šå˜—è©¦å¾CSVè¼‰å…¥
        return load_doctors_data_csv()

def load_doctors_data_csv():
    """å‚™ç”¨æ–¹æ¡ˆï¼šå¾CSVè¼‰å…¥é†«ç”Ÿè³‡æ–™"""
    csv_path = os.path.join('assets', 'finddoc_doctors_detailed 2.csv')
    try:
        df = pd.read_csv(csv_path)
        print(f"âš ï¸ ä½¿ç”¨å‚™ç”¨CSVè¼‰å…¥äº† {len(df)} ä½é†«ç”Ÿè³‡æ–™")
        return df.to_dict('records')
    except Exception as e:
        print(f"è¼‰å…¥CSVé†«ç”Ÿè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

# å…¨å±€è®Šæ•¸å­˜å„²é†«ç”Ÿè³‡æ–™
DOCTORS_DATA = load_doctors_data()

# Admin credentials (in production, use proper user management)
ADMIN_USERNAME = os.getenv('ADMIN_USERNAME', 'admin')
ADMIN_PASSWORD_HASH = hashlib.sha256(os.getenv('ADMIN_PASSWORD', 'admin123').encode()).hexdigest()

def load_ai_config_from_db():
    """Load AI configuration from database"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Load AI config
        cursor.execute('SELECT config_value FROM system_config WHERE config_key = ?', ('ai_config',))
        result = cursor.fetchone()
        
        if result:
            saved_config = json.loads(result[0])
            AI_CONFIG.update(saved_config)
            print("Loaded AI config from database")
        
        conn.close()
    except Exception as e:
        print(f"Error loading AI config from database: {e}")

def load_whatsapp_config_from_db():
    """Load WhatsApp configuration from database"""
    global WHATSAPP_CONFIG
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Load WhatsApp config
        cursor.execute('SELECT value FROM admin_config WHERE key = ?', ('whatsapp_config',))
        result = cursor.fetchone()
        
        if result:
            saved_config = json.loads(result[0])
            WHATSAPP_CONFIG.update(saved_config)
            print("Loaded WhatsApp config from database")
        
        conn.close()
    except Exception as e:
        print(f"Error loading WhatsApp config from database: {e}")

# Initialize database
def init_db():
    """Initialize SQLite database for analytics and user data"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Analytics table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analytics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                event_type TEXT NOT NULL,
                user_ip TEXT,
                user_agent TEXT,
                data TEXT,
                session_id TEXT
            )
        ''')
        
        # User queries table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_queries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                age INTEGER,
                symptoms TEXT,
                chronic_conditions TEXT,
                language TEXT,
                location TEXT,
                detailed_health_info TEXT,
                ai_analysis TEXT,
                related_specialty TEXT,
                matched_doctors_count INTEGER,
                user_ip TEXT,
                session_id TEXT
            )
        ''')
        
        # Doctor clicks table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS doctor_clicks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                doctor_name TEXT,
                doctor_specialty TEXT,
                user_ip TEXT,
                session_id TEXT,
                query_id INTEGER,
                FOREIGN KEY (query_id) REFERENCES user_queries (id)
            )
        ''')
        
        # System config table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS system_config (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                config_key TEXT UNIQUE,
                config_value TEXT,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Admin users table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS admin_users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                password_hash TEXT NOT NULL,
                role TEXT DEFAULT 'admin',
                permissions TEXT DEFAULT '{}',
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_login DATETIME,
                is_active BOOLEAN DEFAULT 1,
                created_by INTEGER,
                totp_secret TEXT,
                totp_enabled BOOLEAN DEFAULT 0,
                backup_codes TEXT,
                FOREIGN KEY (created_by) REFERENCES admin_users (id)
            )
        ''')
        
        # Admin config table for storing configuration settings
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS admin_config (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                key TEXT UNIQUE NOT NULL,
                value TEXT,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create default admin user if not exists
        cursor.execute('SELECT COUNT(*) FROM admin_users WHERE username = ?', (ADMIN_USERNAME,))
        if cursor.fetchone()[0] == 0:
            cursor.execute('''
                INSERT INTO admin_users (username, password_hash, role, permissions)
                VALUES (?, ?, 'super_admin', '{"all": true}')
            ''', (ADMIN_USERNAME, ADMIN_PASSWORD_HASH))
            print(f"Created default admin user: {ADMIN_USERNAME}")
        
        conn.commit()
        conn.close()
        print("=== DATABASE INITIALIZED SUCCESSFULLY ===")
        print(f"Created tables: analytics, user_queries, doctor_clicks, system_config, admin_users, admin_config")
        print(f"Default admin user: {ADMIN_USERNAME}")
        
    except Exception as e:
        print(f"=== DATABASE INITIALIZATION ERROR ===")
        print(f"Error: {e}")
        print(f"Error type: {type(e).__name__}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        # Create a minimal fallback database
        try:
            conn = sqlite3.connect('admin_data.db')
            conn.close()
            print("=== CREATED MINIMAL DATABASE FILE ===")
        except Exception as fallback_error:
            print(f"=== FAILED TO CREATE DATABASE FILE ===")
            print(f"Fallback error: {fallback_error}")

# Initialize database on startup
print("=== STARTING DATABASE INITIALIZATION ===")
init_db()

# Load configurations from database
print("=== LOADING AI CONFIG FROM DATABASE ===")
load_ai_config_from_db()
print("=== LOADING WHATSAPP CONFIG FROM DATABASE ===")
load_whatsapp_config_from_db()
print("=== APP STARTUP COMPLETE ===")

# WhatsAppå®¢æˆ¶ç«¯å¯¦ä¾‹
whatsapp_client = None

def init_whatsapp_client():
    """åˆå§‹åŒ–WhatsAppå®¢æˆ¶ç«¯"""
    global whatsapp_client
    
    if not WHATSAPP_CONFIG['enabled'] or not WHATSAPP_AVAILABLE:
        whatsapp_client = None
        if not WHATSAPP_AVAILABLE:
            print("WhatsAppå®¢æˆ¶ç«¯ä¸å¯ç”¨ï¼špython-socketioæœªå®‰è£")
        return
    
    try:
        whatsapp_client = socketio.SimpleClient()
        print(f"WhatsApp Socket.IOå®¢æˆ¶ç«¯å·²åˆå§‹åŒ–")
    except Exception as e:
        print(f"WhatsAppå®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—: {e}")
        whatsapp_client = None

# Initialize WhatsApp client on startup
init_whatsapp_client()

def send_whatsapp_notification(message: str):
    """ç™¼é€WhatsAppé€šçŸ¥"""
    print(f"DEBUG: WhatsApp enabled: {WHATSAPP_CONFIG['enabled']}")
    print(f"DEBUG: WhatsApp client initialized: {whatsapp_client is not None}")
    print(f"DEBUG: Target number: {WHATSAPP_CONFIG['target_number']}")
    print(f"DEBUG: Socket URL: {WHATSAPP_CONFIG['socket_url']}")
    
    if not WHATSAPP_CONFIG['enabled']:
        print("WhatsAppé€šçŸ¥å·²è·³éï¼ˆæœªå•Ÿç”¨ï¼‰")
        return False
        
    if not whatsapp_client:
        print("WhatsAppé€šçŸ¥å·²è·³éï¼ˆå®¢æˆ¶ç«¯æœªåˆå§‹åŒ–ï¼‰")
        return False
    
    def send_async():
        connected = False
        try:
            # Check if already connected
            if not whatsapp_client.connected:
                print(f"DEBUG: Connecting to {WHATSAPP_CONFIG['socket_url']}")
                whatsapp_client.connect(WHATSAPP_CONFIG['socket_url'])
                connected = True
            else:
                print("DEBUG: Using existing connection")
            
            print(f"DEBUG: Sending message to {WHATSAPP_CONFIG['target_number']}")
            # Generate a unique message ID for deduplication
            import hashlib
            import time
            message_id = hashlib.md5(f"{WHATSAPP_CONFIG['target_number']}:{message}:{time.time()}".encode()).hexdigest()
            
            # Send message via Socket.IO and wait for response
            response = whatsapp_client.call('sendText', {
                'to': WHATSAPP_CONFIG['target_number'],
                'content': message,
                'messageId': message_id  # Include message ID for deduplication
            }, timeout=10)
            
            if response and response.get('success'):
                print(f"âœ… WhatsApp message sent successfully to {WHATSAPP_CONFIG['target_number']}")
                return True
            else:
                error_msg = response.get('error', 'Unknown error') if response else 'No response from server'
                print(f"âŒ WhatsApp send failed: {error_msg}")
                return False
                
        except Exception as e:
            print(f"âŒ WhatsApp send error: {str(e)}")
            # If there was an error, try to disconnect to clean up the connection
            try:
                if connected and whatsapp_client.connected:
                    whatsapp_client.disconnect()
            except:
                pass
            return False
    
    try:
        # Run in a new thread
        thread = threading.Thread(target=send_async)
        thread.daemon = True
        thread.start()
        return True
    except Exception as e:
        print(f"WhatsAppé€šçŸ¥éŒ¯èª¤: {e}")
        return False

def get_app_timezone():
    """Get configured timezone"""
    try:
        return pytz.timezone(TIMEZONE_CONFIG['timezone'])
    except:
        return pytz.timezone('Asia/Hong_Kong')

def get_current_time():
    """Get current time in Hong Kong timezone"""
    hk_tz = pytz.timezone('Asia/Hong_Kong')
    return datetime.now(hk_tz)

def detect_severe_symptoms_and_conditions(symptoms, chronic_conditions):
    """
    æª¢æ¸¬åš´é‡ç—‡ç‹€å’Œç—…å²ï¼Œè¿”å›æª¢æ¸¬çµæœ
    Detect severe symptoms and conditions, return detection results
    """
    severe_symptoms_found = []
    severe_conditions_found = []
    
    # å°‡è¼¸å…¥è½‰æ›ç‚ºå°å¯«ä»¥ä¾¿æ¯”è¼ƒ
    symptoms_lower = symptoms.lower() if symptoms else ""
    conditions_lower = chronic_conditions.lower() if chronic_conditions else ""
    
    # æª¢æ¸¬åš´é‡ç—‡ç‹€
    for severe_symptom in SEVERE_SYMPTOMS_CONFIG['severe_symptoms']:
        if severe_symptom.lower() in symptoms_lower:
            severe_symptoms_found.append(severe_symptom)
    
    # æª¢æ¸¬åš´é‡ç—…å²
    for severe_condition in SEVERE_SYMPTOMS_CONFIG['severe_conditions']:
        if severe_condition.lower() in conditions_lower:
            severe_conditions_found.append(severe_condition)
    
    # åˆ¤æ–·æ˜¯å¦éœ€è¦é¡¯ç¤ºè­¦å‘Š
    is_severe_case = len(severe_symptoms_found) > 0 or len(severe_conditions_found) > 0
    
    return {
        'is_severe': is_severe_case,
        'severe_symptoms': severe_symptoms_found,
        'severe_conditions': severe_conditions_found,
        'total_severe_items': len(severe_symptoms_found) + len(severe_conditions_found)
    }

def log_severe_case(user_query_id, age, gender, symptoms, chronic_conditions, 
                   severe_symptoms, severe_conditions, user_ip, session_id):
    """
    è¨˜éŒ„åš´é‡ç—…ä¾‹åˆ°æ•¸æ“šåº«
    Log severe case to database for admin monitoring
    """
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO severe_cases 
            (user_query_id, age, gender, symptoms, chronic_conditions, 
             severe_symptoms, severe_conditions, user_ip, session_id, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            user_query_id, age, gender, symptoms, chronic_conditions,
            json.dumps(severe_symptoms, ensure_ascii=False),
            json.dumps(severe_conditions, ensure_ascii=False),
            user_ip, session_id, get_current_time().isoformat()
        ))
        
        severe_case_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        # è¨˜éŒ„åˆ°æ—¥èªŒ
        logger.warning(f"Severe case detected and logged - ID: {severe_case_id}, "
                      f"Symptoms: {len(severe_symptoms)}, Conditions: {len(severe_conditions)}, "
                      f"Session: {session_id}")
        
        return severe_case_id
        
    except Exception as e:
        logger.error(f"Error logging severe case: {e}")
        return None

# 2FA Helper Functions
def generate_totp_secret():
    """Generate a new TOTP secret"""
    return pyotp.random_base32()

def generate_qr_code(username, secret, issuer="Doctor AI Admin"):
    """Generate QR code for TOTP setup"""
    totp_uri = pyotp.totp.TOTP(secret).provisioning_uri(
        name=username,
        issuer_name=issuer
    )
    
    qr = qrcode.QRCode(version=1, box_size=10, border=5)
    qr.add_data(totp_uri)
    qr.make(fit=True)
    
    img = qr.make_image(fill_color="black", back_color="white")
    img_buffer = io.BytesIO()
    img.save(img_buffer, format='PNG')
    img_buffer.seek(0)
    
    img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
    return f"data:image/png;base64,{img_base64}"

def verify_totp_token(secret, token):
    """Verify TOTP token"""
    try:
        totp = pyotp.TOTP(secret)
        # Clean the token - remove any spaces or dashes
        clean_token = str(token).replace('-', '').replace(' ', '').strip()
        
        # Generate current expected token for debugging
        current_token = totp.now()
        print(f"DEBUG - Input token: '{clean_token}', Expected: '{current_token}', Secret exists: {bool(secret)}")
        
        result = totp.verify(clean_token, valid_window=2)  # Increased window for time sync issues
        print(f"DEBUG - Token verification result: {result}")
        return result
    except Exception as e:
        print(f"DEBUG - Token verification error: {e}")
        return False

def generate_backup_codes():
    """Generate backup codes for 2FA"""
    codes = []
    for _ in range(10):
        code = ''.join([str(secrets.randbelow(10)) for _ in range(8)])
        codes.append(f"{code[:4]}-{code[4:]}")
    return codes

def format_timestamp(timestamp_str):
    """Format timestamp string to clean readable format"""
    try:
        # Parse the timestamp string
        if isinstance(timestamp_str, str):
            # Handle ISO format with timezone
            if '+' in timestamp_str or 'T' in timestamp_str:
                dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            else:
                dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
        else:
            dt = timestamp_str
        
        # Convert to Hong Kong timezone if needed
        if dt.tzinfo is None:
            hk_tz = pytz.timezone('Asia/Hong_Kong')
            dt = hk_tz.localize(dt)
        elif dt.tzinfo != pytz.timezone('Asia/Hong_Kong'):
            dt = dt.astimezone(pytz.timezone('Asia/Hong_Kong'))
        
        # Format as clean readable string
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    except Exception as e:
        logger.error(f"Error formatting timestamp {timestamp_str}: {e}")
        return str(timestamp_str)

def format_analysis_report_full(user_query_data: dict, doctor_data: dict) -> str:
    """æ ¼å¼åŒ–å®Œæ•´ç—‡ç‹€åˆ†æå ±å‘Šç‚ºHTMLé¡¯ç¤º"""
    timestamp = get_current_time().strftime('%Y-%m-%d %H:%M:%S')
    
    # Format gender display
    gender = user_query_data.get('gender', '')
    gender_display = f"ç”Ÿç†æ€§åˆ¥: {gender}" if gender else "ç”Ÿç†æ€§åˆ¥: æœªæä¾›"
    
    message = f"""ğŸ¥ AIç—‡ç‹€åˆ†æå ±å‘Š
ğŸ“… æ™‚é–“: {timestamp}

ğŸ‘¤ æ‚£è€…ä¿¡æ¯
å¹´é½¡: {user_query_data.get('age', 'N/A')}æ­²
{gender_display}
ç—‡ç‹€: {user_query_data.get('symptoms', 'N/A')}
èªè¨€: {user_query_data.get('language', 'N/A')}
åœ°å€: {user_query_data.get('location', 'N/A')}

ğŸ” AIç—‡ç‹€åˆ†æçµæœ
ç›¸é—œå°ˆç§‘: {user_query_data.get('related_specialty', 'N/A')}

ğŸ‘¨â€âš•ï¸ é¸æ“‡çš„é†«ç”Ÿ
é†«ç”Ÿå§“å: {doctor_data.get('doctor_name', 'N/A')}
å°ˆç§‘: {doctor_data.get('doctor_specialty', 'N/A')}

ğŸ“Š å®Œæ•´åˆ†æ
{user_query_data.get('ai_analysis', 'N/A')}

å…è²¬è²æ˜ï¼šæ­¤åˆ†æåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆé†«ç™‚å»ºè­°æˆ–è¨ºæ–·ï¼Œè«‹å‹™å¿…è«®è©¢åˆæ ¼é†«ç”Ÿã€‚

---
Doctor-AIé¦™æ¸¯é†«ç™‚é…å°ç³»çµ±"""
    
    return message

def format_whatsapp_message(doctor_data: dict, report_url: str) -> str:
    """æ ¼å¼åŒ–WhatsAppæ¶ˆæ¯ï¼ŒåŒ…å«ç—‡ç‹€åˆ†æå ±å‘Šéˆæ¥"""
    message = f"""AIç—‡ç‹€åˆ†æå ±å‘Š

æ‚¨å¥½ï¼æˆ‘é€šéAIç—‡ç‹€åˆ†æç³»çµ±ç²å¾—äº†æ‚¨çš„è³‡è¨Šã€‚

é†«ç”Ÿä¿¡æ¯
å§“å: {doctor_data.get('doctor_name', 'N/A')}
å°ˆç§‘: {doctor_data.get('doctor_specialty', 'N/A')}

å®Œæ•´ç—‡ç‹€åˆ†æå ±å‘Šè«‹æŸ¥çœ‹ï¼š
{report_url}

æœŸå¾…æ‚¨çš„å°ˆæ¥­æ„è¦‹ï¼Œè¬è¬ï¼

---
Doctor-AIé¦™æ¸¯é†«ç™‚é…å°ç³»çµ±"""
    
    return message

def get_real_ip():
    """Get the real client IP address, considering proxies and load balancers"""
    # Check for forwarded headers in order of preference
    if request.headers.get('X-Forwarded-For'):
        # X-Forwarded-For can contain multiple IPs, get the first one (original client)
        return request.headers.get('X-Forwarded-For').split(',')[0].strip()
    elif request.headers.get('X-Real-IP'):
        return request.headers.get('X-Real-IP')
    elif request.headers.get('CF-Connecting-IP'):  # Cloudflare
        return request.headers.get('CF-Connecting-IP')
    elif request.headers.get('X-Client-IP'):
        return request.headers.get('X-Client-IP')
    else:
        # Fallback to remote_addr
        return request.remote_addr

def log_analytics(event_type: str, data: dict, user_ip: str, user_agent: str, session_id: str = None):
    """Log analytics data to database"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Check if analytics table exists
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='analytics'")
        if not cursor.fetchone():
            print("Analytics table not found, reinitializing database...")
            conn.close()
            init_db()
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO analytics (event_type, user_ip, user_agent, data, session_id, timestamp)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (event_type, user_ip, user_agent, json.dumps(data), session_id, get_current_time().isoformat()))
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"Analytics logging error: {e}")
        # Try to reinitialize database if it's corrupted
        try:
            init_db()
        except:
            pass

def get_admin_user(username):
    """Get admin user from database"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, username, password_hash, role, permissions, is_active
            FROM admin_users 
            WHERE username = ? AND is_active = 1
        ''', (username,))
        user = cursor.fetchone()
        conn.close()
        return user
    except Exception as e:
        print(f"Error getting admin user: {e}")
        return None

def check_permission(permission):
    """Check if current admin user has specific permission"""
    if not session.get('admin_logged_in'):
        return False
    
    user_role = session.get('admin_role', '')
    user_permissions = session.get('admin_permissions', {})
    
    # Super admin has all permissions
    if user_role == 'super_admin' or user_permissions.get('all'):
        return True
    
    return user_permissions.get(permission, False)

def require_admin(f):
    """Decorator to require admin authentication"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('admin_logged_in'):
            return redirect(url_for('admin_login'))
        return f(*args, **kwargs)
    return decorated_function

def login_required(f):
    """Decorator to require admin authentication (alias for require_admin)"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('admin_logged_in'):
            return redirect(url_for('admin_login'))
        return f(*args, **kwargs)
    return decorated_function

def tab_permission_required(tab_name):
    """Decorator to check if user has permission for specific tab"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            if not session.get('admin_logged_in'):
                return redirect(url_for('admin_login'))
            
            # Super admin has all permissions
            if session.get('admin_role') == 'super_admin':
                return f(*args, **kwargs)
            
            # Check tab permissions - if not loaded, load them now
            tab_permissions = session.get('admin_tab_permissions')
            if tab_permissions is None:
                # Load permissions from database
                user_id = session.get('admin_user_id')
                if user_id:
                    try:
                        conn = sqlite3.connect('admin_data.db')
                        cursor = conn.cursor()
                        cursor.execute('SELECT tab_permissions FROM admin_users WHERE id = ?', (user_id,))
                        tab_perms = cursor.fetchone()
                        conn.close()
                        
                        if tab_perms and tab_perms[0]:
                            tab_permissions = json.loads(tab_perms[0])
                        else:
                            # Default permissions for all tabs
                            tab_permissions = {
                                "dashboard": True,
                                "analytics": True,
                                "config": True,
                                "doctors": True,
                                "users": True,
                                "bug_reports": True,
                                "severe_cases": True
                            }
                        session['admin_tab_permissions'] = tab_permissions
                    except Exception as e:
                        print(f"Error loading tab permissions: {e}")
                        # Default to all permissions on error
                        tab_permissions = {
                            "dashboard": True,
                            "analytics": True,
                            "config": True,
                            "doctors": True,
                            "users": True,
                            "bug_reports": True,
                            "severe_cases": True
                        }
                        session['admin_tab_permissions'] = tab_permissions
                else:
                    # No user ID, deny access
                    flash('æœƒè©±å·²éæœŸï¼Œè«‹é‡æ–°ç™»å…¥', 'error')
                    return redirect(url_for('admin_login'))
            
            if not tab_permissions.get(tab_name, False):
                flash('æ‚¨æ²’æœ‰æ¬Šé™è¨ªå•æ­¤é é¢', 'error')
                return redirect(url_for('admin_dashboard'))
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

def has_tab_permission(tab_name):
    """Helper function to check if current user has permission for a tab"""
    if not session.get('admin_logged_in'):
        return False
    
    # Super admin has all permissions
    if session.get('admin_role') == 'super_admin':
        return True
    
    tab_permissions = session.get('admin_tab_permissions', {})
    return tab_permissions.get(tab_name, False)

def get_admin_user_info():
    """Get current admin user information from session"""
    if not session.get('admin_logged_in'):
        return None
    
    return {
        'username': session.get('admin_username'),
        'user_id': session.get('admin_user_id'),
        'role': session.get('admin_role'),
        'is_super_admin': session.get('admin_role') == 'super_admin',
        'permissions': session.get('admin_permissions', {}),
        'tab_permissions': session.get('admin_tab_permissions', {})
    }

def require_permission(permission):
    """Decorator to require specific permission"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            if not session.get('admin_logged_in'):
                return redirect(url_for('admin_login'))
            if not check_permission(permission):
                flash('æ‚¨æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æ“ä½œ', 'error')
                return redirect(url_for('admin_dashboard'))
            return f(*args, **kwargs)
        return decorated_function
    return decorator

def generate_user_summary(age: int, gender: str, symptoms: str, chronic_conditions: str, detailed_health_info: dict) -> str:
    """ç”Ÿæˆç”¨æˆ¶è¼¸å…¥æ•¸æ“šæ‘˜è¦"""
    summary_parts = []
    
    # åŸºæœ¬ä¿¡æ¯
    summary_parts.append(f"å¹´é½¡ï¼š{age}æ­²")
    if gender:
        summary_parts.append(f"æ€§åˆ¥ï¼š{gender}")
    summary_parts.append(f"ä¸»è¦ç—‡ç‹€ï¼š{symptoms}")
    
    # é•·æœŸç—…å²
    if chronic_conditions:
        summary_parts.append(f"é•·æœŸç—…å²ï¼š{chronic_conditions}")
    
    # èº«é«”æŒ‡æ¨™
    if detailed_health_info.get('height') or detailed_health_info.get('weight'):
        height = detailed_health_info.get('height', '')
        weight = detailed_health_info.get('weight', '')
        if height and weight:
            bmi = round(float(weight) / ((float(height) / 100) ** 2), 1) if height and weight else None
            summary_parts.append(f"èº«é«˜é«”é‡ï¼š{height}cm / {weight}kg" + (f" (BMI: {bmi})" if bmi else ""))
        elif height:
            summary_parts.append(f"èº«é«˜ï¼š{height}cm")
        elif weight:
            summary_parts.append(f"é«”é‡ï¼š{weight}kg")
    
    # è—¥ç‰©ä¿¡æ¯
    if detailed_health_info.get('medications'):
        summary_parts.append(f"é•·æœŸè—¥ç‰©ï¼š{detailed_health_info['medications']}")
    
    # æ•æ„Ÿå²
    if detailed_health_info.get('allergies'):
        summary_parts.append(f"æ•æ„Ÿå²ï¼š{detailed_health_info['allergies']}")
    
    # æ‰‹è¡“å²
    if detailed_health_info.get('surgeries'):
        summary_parts.append(f"æ‰‹è¡“å²ï¼š{detailed_health_info['surgeries']}")
    
    # ç‰¹æ®Šæƒ…æ³
    special_conditions = []
    if detailed_health_info.get('bloodThinner'):
        special_conditions.append("æœ‰æœè–„è¡€è—¥")
    if detailed_health_info.get('recentVisit'):
        special_conditions.append("ä¸‰å€‹æœˆå…§æ›¾å°±è¨º")
    if detailed_health_info.get('cpapMachine'):
        special_conditions.append("ä½¿ç”¨å‘¼å¸æ©Ÿ")
    if detailed_health_info.get('looseTeeth'):
        special_conditions.append("æœ‰é¬†ç‰™å•é¡Œ")
    
    if special_conditions:
        summary_parts.append(f"ç‰¹æ®Šæƒ…æ³ï¼š{'ã€'.join(special_conditions)}")
    
    return '\n'.join(summary_parts)

def call_openrouter_api(prompt: str) -> str:
    """èª¿ç”¨OpenRouter APIé€²è¡ŒAIåˆ†æ"""
    try:
        if not AI_CONFIG['openrouter']['api_key']:
            return "AIæœå‹™é…ç½®ä¸å®Œæ•´ï¼Œè«‹è¯ç¹«ç³»çµ±ç®¡ç†å“¡"
            
        headers = {
            "Authorization": f"Bearer {AI_CONFIG['openrouter']['api_key']}",
            "Content-Type": "application/json",
            "HTTP-Referer": "http://localhost:5000",
            "X-Title": "AI Doctor Matching System"
        }
        
        data = {
            "model": AI_CONFIG['openrouter']['model'],
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": AI_CONFIG['openrouter']['max_tokens'],
            "temperature": 0.3,
            "top_p": 0.9
        }
        
        response = requests.post(
            AI_CONFIG['openrouter']['base_url'], 
            headers=headers, 
            json=data, 
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"
            
    except Exception as e:
        return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"

def call_openai_api(prompt: str) -> str:
    """èª¿ç”¨OpenAI APIé€²è¡ŒAIåˆ†æ"""
    try:
        if not AI_CONFIG['openai']['api_key']:
            return "AIæœå‹™é…ç½®ä¸å®Œæ•´ï¼Œè«‹è¯ç¹«ç³»çµ±ç®¡ç†å“¡"
            
        headers = {
            "Authorization": f"Bearer {AI_CONFIG['openai']['api_key']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": AI_CONFIG['openai']['model'],
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": AI_CONFIG['openai']['max_tokens'],
            "temperature": 0.3,
            "top_p": 0.9
        }
        
        response = requests.post(
            AI_CONFIG['openai']['base_url'], 
            headers=headers, 
            json=data, 
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"
            
    except Exception as e:
        return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"

def call_ollama_api(prompt: str) -> str:
    """èª¿ç”¨Ollama APIé€²è¡ŒAIåˆ†æ"""
    try:
        data = {
            "model": AI_CONFIG['ollama']['model'],
            "prompt": prompt,
            "stream": False
        }
        
        response = requests.post(AI_CONFIG['ollama']['base_url'], json=data, timeout=30)
        if response.status_code == 200:
            result = response.json()
            return result.get('response', 'AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦')
        else:
            return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"
    except requests.exceptions.ConnectionError:
        return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"
    except Exception as e:
        return "AIåˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"

def get_openai_models(api_key: str = None) -> list:
    """ç²å–OpenAIå¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        # Use provided API key or fall back to config
        key_to_use = api_key or AI_CONFIG['openai']['api_key']
        
        if not key_to_use:
            return ['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo']  # fallback
            
        headers = {
            "Authorization": f"Bearer {key_to_use}",
            "Content-Type": "application/json"
        }
        
        response = requests.get(
            'https://api.openai.com/v1/models',
            headers=headers,
            timeout=10
        )
        
        if response.status_code == 200:
            models_data = response.json()
            # Filter for chat models only
            chat_models = []
            for model in models_data.get('data', []):
                model_id = model.get('id', '')
                if any(prefix in model_id for prefix in ['gpt-4', 'gpt-3.5']):
                    chat_models.append(model_id)
            
            # Sort models with GPT-4 first
            chat_models.sort(key=lambda x: (not x.startswith('gpt-4'), x))
            return chat_models if chat_models else ['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo']
        else:
            return ['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo']  # fallback
            
    except Exception as e:
        print(f"Error fetching OpenAI models: {e}")
        return ['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo']  # fallback

def call_ai_api(prompt: str) -> str:
    """æ ¹æ“šé…ç½®èª¿ç”¨ç›¸æ‡‰çš„AI API"""
    provider = AI_CONFIG['provider'].lower()
    
    if provider == 'openrouter':
        return call_openrouter_api(prompt)
    elif provider == 'openai':
        return call_openai_api(prompt)
    elif provider == 'ollama':
        return call_ollama_api(prompt)
    else:
        return f"ä¸æ”¯æ´çš„AIæä¾›å•†: {provider}"

def get_available_specialties() -> list:
    """ç²å–è³‡æ–™åº«ä¸­æ‰€æœ‰å¯ç”¨çš„å°ˆç§‘"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        # Try different specialty columns with encoding handling
        cursor.execute("SELECT DISTINCT specialty FROM doctors WHERE specialty IS NOT NULL AND specialty != '' AND LENGTH(specialty) > 0")
        specialties = []
        for row in cursor.fetchall():
            try:
                if row[0] and isinstance(row[0], str) and len(row[0].strip()) > 0:
                    specialties.append(row[0].strip())
            except (UnicodeDecodeError, AttributeError):
                continue
        conn.close()
        
        # Remove duplicates and sort
        specialties = sorted(list(set(specialties)))
        
        if not specialties:
            # Fallback list
            specialties = ['å…§ç§‘', 'å¤–ç§‘', 'å°å…’ç§‘', 'å©¦ç”¢ç§‘', 'éª¨ç§‘', 'çš®è†šç§‘', 'çœ¼ç§‘', 'è€³é¼»å–‰ç§‘', 'ç²¾ç¥ç§‘', 'ç¥ç¶“ç§‘', 'å¿ƒè‡Ÿç§‘', 'æ€¥è¨ºç§‘']
        
        return specialties
    except Exception as e:
        print(f"Error fetching specialties: {e}")
        return ['å…§ç§‘', 'å¤–ç§‘', 'å°å…’ç§‘', 'å©¦ç”¢ç§‘', 'éª¨ç§‘', 'çš®è†šç§‘', 'çœ¼ç§‘', 'è€³é¼»å–‰ç§‘', 'ç²¾ç¥ç§‘', 'ç¥ç¶“ç§‘', 'å¿ƒè‡Ÿç§‘', 'æ€¥è¨ºç§‘']

def validate_symptoms_with_llm(symptoms: str, user_language: str = 'zh-TW') -> dict:
    """ä½¿ç”¨LLMé©—è­‰ç—‡ç‹€æè¿°æ˜¯å¦æœ‰æ•ˆ"""
    try:
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {'valid': True, 'message': 'ç—‡ç‹€é©—è­‰æœå‹™ä¸å¯ç”¨ï¼Œå°‡ç¹¼çºŒè™•ç†'}
        
        # Get translations for the prompt
        t = lambda key: get_translation(key, user_language)
        
        prompt = f"""
ä½ æ˜¯ä¸€å€‹é†«ç™‚ç—‡ç‹€é©—è­‰å°ˆå®¶ã€‚è«‹åˆ†æä»¥ä¸‹ç—‡ç‹€æè¿°ï¼Œåˆ¤æ–·æ˜¯å¦ç‚ºæœ‰æ•ˆçš„é†«ç™‚ç—‡ç‹€ã€‚

ç—‡ç‹€æè¿°ï¼š{symptoms}

è«‹è©•ä¼°ï¼š
1. é€™äº›æ˜¯å¦ç‚ºçœŸå¯¦çš„é†«ç™‚ç—‡ç‹€ï¼Ÿ
2. æè¿°æ˜¯å¦åˆç†å’Œå…·é«”ï¼Ÿ
3. æ˜¯å¦åŒ…å«ä¸ç›¸é—œæˆ–ç„¡æ„ç¾©çš„å…§å®¹ï¼Ÿ

ç„¡æ•ˆç—‡ç‹€çš„ä¾‹å­ï¼š
- æ¸¬è©¦ã€testã€123ã€éš¨ä¾¿å¯«çš„
- éé†«ç™‚ç›¸é—œçš„è©èªï¼ˆå¦‚ï¼šé–‹å¿ƒã€å·¥ä½œã€åƒé£¯ï¼‰
- æ˜é¡¯çš„åƒåœ¾æ–‡å­—æˆ–ç„¡æ„ç¾©å­—ç¬¦
- éæ–¼ç°¡å–®æˆ–ä¸å…·é«”çš„æè¿°ï¼ˆå¦‚ï¼šä¸èˆ’æœã€æœ‰å•é¡Œï¼‰

è«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼š
{{
    "valid": true/false,
    "confidence": 0.0-1.0,
    "issues": ["å•é¡Œåˆ—è¡¨"],
    "suggestions": ["æ”¹å–„å»ºè­°"]
}}
"""
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'gpt-3.5-turbo',
            'messages': [
                {'role': 'system', 'content': 'ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„é†«ç™‚ç—‡ç‹€é©—è­‰åŠ©æ‰‹ã€‚è«‹ä»”ç´°åˆ†æç—‡ç‹€æè¿°çš„æœ‰æ•ˆæ€§ã€‚'},
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': 500,
            'temperature': 0.3
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=data,
            timeout=15
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content'].strip()
            
            try:
                # Parse JSON response
                validation_result = json.loads(content)
                return {
                    'valid': validation_result.get('valid', True),
                    'confidence': validation_result.get('confidence', 0.5),
                    'issues': validation_result.get('issues', []),
                    'suggestions': validation_result.get('suggestions', []),
                    'message': 'ç—‡ç‹€é©—è­‰å®Œæˆ'
                }
            except json.JSONDecodeError:
                # Fallback if JSON parsing fails
                is_valid = 'true' in content.lower() and 'valid' in content.lower()
                return {
                    'valid': is_valid,
                    'confidence': 0.7,
                    'issues': [],
                    'suggestions': [],
                    'message': 'ç—‡ç‹€é©—è­‰å®Œæˆï¼ˆç°¡åŒ–çµæœï¼‰'
                }
        else:
            logger.error(f"Symptom validation API error: {response.status_code}")
            return {'valid': True, 'message': 'ç—‡ç‹€é©—è­‰æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œå°‡ç¹¼çºŒè™•ç†'}
            
    except Exception as e:
        logger.error(f"Error validating symptoms: {e}")
        return {'valid': True, 'message': 'ç—‡ç‹€é©—è­‰éç¨‹ä¸­å‡ºç¾éŒ¯èª¤ï¼Œå°‡ç¹¼çºŒè™•ç†'}

def analyze_symptoms(age: int, gender: str, symptoms: str, chronic_conditions: str = '', detailed_health_info: dict = None, user_language: str = 'zh-TW') -> dict:
    """ä½¿ç”¨AIåˆ†æç—‡ç‹€"""
    
    if detailed_health_info is None:
        detailed_health_info = {}
    
    # æ§‹å»ºè©³ç´°å¥åº·ä¿¡æ¯
    health_details = []
    if gender:
        health_details.append(f"æ€§åˆ¥ï¼š{gender}")
    if chronic_conditions.strip():
        health_details.append(f"é•·æœŸç—…å²ï¼š{chronic_conditions}")
    
    if detailed_health_info.get('height') or detailed_health_info.get('weight'):
        height = detailed_health_info.get('height', '')
        weight = detailed_health_info.get('weight', '')
        if height and weight:
            try:
                bmi = round(float(weight) / ((float(height) / 100) ** 2), 1)
                health_details.append(f"èº«é«˜é«”é‡ï¼š{height}cm / {weight}kg (BMI: {bmi})")
            except:
                health_details.append(f"èº«é«˜é«”é‡ï¼š{height}cm / {weight}kg")
        elif height:
            health_details.append(f"èº«é«˜ï¼š{height}cm")
        elif weight:
            health_details.append(f"é«”é‡ï¼š{weight}kg")
    
    if detailed_health_info.get('medications'):
        health_details.append(f"é•·æœŸè—¥ç‰©ï¼š{detailed_health_info['medications']}")
    
    if detailed_health_info.get('allergies'):
        health_details.append(f"æ•æ„Ÿå²ï¼š{detailed_health_info['allergies']}")
    
    if detailed_health_info.get('surgeries'):
        health_details.append(f"æ‰‹è¡“å²ï¼š{detailed_health_info['surgeries']}")
    
    special_conditions = []
    if detailed_health_info.get('bloodThinner'):
        special_conditions.append("æœ‰æœè–„è¡€è—¥")
    if detailed_health_info.get('recentVisit'):
        special_conditions.append("ä¸‰å€‹æœˆå…§æ›¾å°±è¨º")
    if detailed_health_info.get('cpapMachine'):
        special_conditions.append("ä½¿ç”¨å‘¼å¸æ©Ÿ")
    if detailed_health_info.get('looseTeeth'):
        special_conditions.append("æœ‰é¬†ç‰™å•é¡Œ")
    
    if special_conditions:
        health_details.append(f"ç‰¹æ®Šæƒ…æ³ï¼š{'ã€'.join(special_conditions)}")
    
    # Get translations for the user's language
    t = lambda key: get_translation(key, user_language)
    
    # Build health info with translated labels
    health_info = "\n    - ".join(health_details) if health_details else t('no_special_health_info')
    
    # Get available specialties from database
    available_specialties = get_available_specialties()
    specialty_list = "ã€".join(available_specialties)
    
    # Build AI analysis prompt in user's language with consistency instructions
    analysis_prompt = f"""
    {t('diagnosis_prompt_intro')}

    {t('patient_data')}
    - {t('age_label')}{age}{t('years_old')}
    - {t('main_symptoms')}{symptoms}
    - {health_info}

    {t('please_provide')}
    1. {t('possible_diagnosis')}
    2. {t('recommended_specialty')}
    3. {t('severity_assessment')}
    4. {t('emergency_needed')}
    5. {t('general_advice')}

    **{t('important_guidelines')}**
    - {t('mental_health_guideline')}
    - {t('trauma_guideline')}
    - {t('emergency_guideline')}
    - {t('specialty_guideline')}

    **ä¸€è‡´æ€§è¦æ±‚ (Consistency Requirements):**
    - å¿…é ˆåš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼Œä¸å¯åé›¢
    - åš´é‡ç¨‹åº¦åªèƒ½æ˜¯ï¼šè¼•å¾®ã€ä¸­ç­‰ã€åš´é‡ (ä¸‰é¸ä¸€)
    - ç·Šæ€¥ç¨‹åº¦åªèƒ½æ˜¯ï¼šæ˜¯ã€å¦ (äºŒé¸ä¸€)
    - å°ˆç§‘åç¨±å¿…é ˆå¾ä»¥ä¸‹å¯ç”¨å°ˆç§‘ä¸­é¸æ“‡ï¼š{specialty_list}
    - ä¸å¯æ¨è–¦è³‡æ–™åº«ä¸­ä¸å­˜åœ¨çš„å°ˆç§‘
    - å›ç­”å¿…é ˆç°¡æ½”æ˜ç¢ºï¼Œé¿å…æ¨¡ç³Šç”¨è©

    {t('response_language')}
    
    **åš´æ ¼æ ¼å¼è¦æ±‚ (Strict Format Requirements):**
    {t('diagnosis_format')}
    {t('specialty_format')}
    {t('severity_format')}
    {t('emergency_format')}
    {t('advice_format')}
    
    {t('disclaimer')}
    """
    
    # ç²å–AIåˆ†æ
    analysis_response = call_ai_api(analysis_prompt)
    
    # è§£æåˆ†æçµæœ
    recommended_specialties = extract_specialties_from_analysis(analysis_response)
    recommended_specialty = recommended_specialties[0] if recommended_specialties else 'å…§ç§‘'
    severity_level = extract_severity_from_analysis(analysis_response)
    emergency_needed = check_emergency_needed(analysis_response)
    
    # Debug logging
    print(f"DEBUG - AI Response: {analysis_response[:200]}...")
    print(f"DEBUG - Full AI Response for Emergency Check:")
    print("=" * 50)
    print(analysis_response)
    print("=" * 50)
    print(f"DEBUG - Extracted specialties: {recommended_specialties}")
    print(f"DEBUG - Primary specialty: {recommended_specialty}")
    print(f"DEBUG - Severity level: {severity_level}")
    print(f"DEBUG - Emergency needed: {emergency_needed}")
    
    # Additional emergency pattern debugging
    if 'ç·Šæ€¥ç¨‹åº¦' in analysis_response:
        print(f"DEBUG - Found 'ç·Šæ€¥ç¨‹åº¦' in response")
        if 'ç·Šæ€¥ç¨‹åº¦ï¼šæ˜¯' in analysis_response or 'ç·Šæ€¥ç¨‹åº¦: æ˜¯' in analysis_response:
            print(f"DEBUG - Found emergency format 'ç·Šæ€¥ç¨‹åº¦ï¼šæ˜¯'")
        elif 'ç·Šæ€¥ç¨‹åº¦ï¼šå¦' in analysis_response or 'ç·Šæ€¥ç¨‹åº¦: å¦' in analysis_response:
            print(f"DEBUG - Found non-emergency format 'ç·Šæ€¥ç¨‹åº¦ï¼šå¦'")
    else:
        print(f"DEBUG - No 'ç·Šæ€¥ç¨‹åº¦' format found in response")
    
    return {
        'analysis': analysis_response,
        'recommended_specialty': recommended_specialty,
        'recommended_specialties': recommended_specialties,
        'severity_level': severity_level,
        'emergency_needed': emergency_needed
    }

def analyze_symptoms_and_match(age: int, gender: str, symptoms: str, chronic_conditions: str, language: str, location: str, detailed_health_info: dict = None, location_details: dict = None) -> dict:
    """ä½¿ç”¨AIåˆ†æç—‡ç‹€ä¸¦é…å°é†«ç”Ÿ"""
    
    if detailed_health_info is None:
        detailed_health_info = {}
    
    # ç”Ÿæˆç”¨æˆ¶æ•¸æ“šæ‘˜è¦
    user_summary = generate_user_summary(age, gender, symptoms, chronic_conditions, detailed_health_info)
    
    # Get user's language from session or use the language parameter passed in
    user_language = session.get('language', language if language else 'zh-TW')
    
    # ç¬¬ä¸€æ­¥ï¼šé©—è­‰ç—‡ç‹€æœ‰æ•ˆæ€§
    symptom_validation = validate_symptoms_with_llm(symptoms, user_language)
    
    if not symptom_validation.get('valid', True):
        return {
            'diagnosis': 'ç—‡ç‹€é©—è­‰å¤±æ•—',
            'recommended_specialty': 'ç„¡',
            'doctors': [],
            'user_summary': user_summary,
            'emergency_needed': False,
            'severity_level': 'low',
            'validation_error': True,
            'validation_issues': symptom_validation.get('issues', []),
            'validation_suggestions': symptom_validation.get('suggestions', []),
            'validation_message': 'æ‚¨è¼¸å…¥çš„å…§å®¹ä¸æ˜¯æœ‰æ•ˆçš„é†«ç™‚ç—‡ç‹€ã€‚è«‹é‡æ–°è¼¸å…¥çœŸå¯¦çš„èº«é«”ä¸é©ç—‡ç‹€ï¼Œä¾‹å¦‚é ­ç—›ã€ç™¼ç‡’ã€å’³å—½ç­‰ã€‚',
            'validation_confidence': symptom_validation.get('confidence', 0.5)
        }
    
    # ç¬¬äºŒæ­¥ï¼šAIåˆ†æ (pass user language)
    diagnosis_result = analyze_symptoms(age, gender, symptoms, chronic_conditions, detailed_health_info, user_language)
    
    # ç¬¬äºŒæ­¥ï¼šæª¢æŸ¥æ˜¯å¦éœ€è¦ç·Šæ€¥é†«ç™‚è™•ç†
    print(f"DEBUG - Emergency check: emergency_needed={diagnosis_result.get('emergency_needed', False)}, severity_level={diagnosis_result.get('severity_level')}")
    
    if diagnosis_result.get('emergency_needed', False):
        print("DEBUG - Emergency case detected, routing to emergency doctors")
        # ç·Šæ€¥æƒ…æ³ï¼šå„ªå…ˆæ¨è–¦æ€¥è¨ºç§‘å’Œé†«é™¢
        emergency_doctors = filter_doctors('æ€¥è¨ºç§‘', language, location, symptoms, diagnosis_result['analysis'], location_details)
        # å¦‚æœæ²’æœ‰æ€¥è¨ºç§‘é†«ç”Ÿï¼Œæ¨è–¦å…§ç§‘é†«ç”Ÿä½†æ¨™è¨˜ç‚ºç·Šæ€¥
        if not emergency_doctors:
            emergency_doctors = filter_doctors('å…§ç§‘', language, location, symptoms, diagnosis_result['analysis'], location_details)
        
        # ç‚ºç·Šæ€¥é†«ç”Ÿæ·»åŠ ç·Šæ€¥æ¨™è¨˜
        for doctor in emergency_doctors:
            doctor['is_emergency'] = True
            doctor['emergency_message'] = get_translation('emergency_care_needed', user_language)
        
        matched_doctors = emergency_doctors
    else:
        print("DEBUG - Normal case, routing to specialty doctors")
        # ä¸€èˆ¬æƒ…æ³ï¼šæ ¹æ“šè¨ºæ–·çµæœæ¨è–¦å¤šå€‹ç›¸é—œå°ˆç§‘çš„é†«ç”Ÿ
        all_matched_doctors = []
        recommended_specialties = diagnosis_result.get('recommended_specialties', [diagnosis_result['recommended_specialty']])
        print(f"DEBUG - Will search for specialties: {recommended_specialties}")
        
        for specialty in recommended_specialties:
            specialty_doctors = filter_doctors(
                specialty, 
                language, 
                location, 
                symptoms, 
                diagnosis_result['analysis'],
                location_details
            )
            
            print(f"DEBUG - Found {len(specialty_doctors)} doctors for specialty: {specialty}")
            
            # ç‚ºæ¯å€‹é†«ç”Ÿæ·»åŠ å°ˆç§‘æ¨™è¨˜ï¼Œç”¨æ–¼æ’åº
            for doctor in specialty_doctors:
                doctor['matched_specialty'] = specialty
                doctor['is_primary_specialty'] = (specialty == diagnosis_result['recommended_specialty'])
            
            all_matched_doctors.extend(specialty_doctors)
        
        # å»é™¤é‡è¤‡é†«ç”Ÿä¸¦æŒ‰å„ªå…ˆç´šæ’åº
        seen_names = set()
        unique_doctors = []
        
        # é¦–å…ˆæ·»åŠ ä¸»è¦å°ˆç§‘çš„é†«ç”Ÿ
        for doctor in all_matched_doctors:
            if doctor.get('is_primary_specialty', False) and doctor['name'] not in seen_names:
                seen_names.add(doctor['name'])
                unique_doctors.append(doctor)
        
        # ç„¶å¾Œæ·»åŠ å…¶ä»–å°ˆç§‘çš„é†«ç”Ÿ
        for doctor in all_matched_doctors:
            if not doctor.get('is_primary_specialty', False) and doctor['name'] not in seen_names:
                seen_names.add(doctor['name'])
                unique_doctors.append(doctor)
        
        matched_doctors = unique_doctors[:15]  # å¢åŠ åˆ°15ä½é†«ç”Ÿä»¥åŒ…å«å¤šå€‹å°ˆç§‘
        
        # ç¢ºä¿éç·Šæ€¥æƒ…æ³ä¸‹ä¸è¨­ç½®ç·Šæ€¥æ¨™è¨˜
        for doctor in matched_doctors:
            doctor['is_emergency'] = False
    
    # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæ˜¯12æ­²ä»¥ä¸‹ï¼Œæ·»åŠ å…’ç§‘é†«ç”Ÿ
    if age <= 12:
        pediatric_doctors = filter_doctors('å…’ç§‘', language, location, symptoms, diagnosis_result['analysis'], location_details)
        # åˆä½µé†«ç”Ÿæ¸…å–®ï¼Œå»é™¤é‡è¤‡
        all_doctors = matched_doctors + pediatric_doctors
        seen_names = set()
        unique_doctors = []
        for doctor in all_doctors:
            if doctor['name'] not in seen_names:
                seen_names.add(doctor['name'])
                unique_doctors.append(doctor)
        matched_doctors = unique_doctors[:15]  # é™åˆ¶æœ€å¤š15ä½é†«ç”Ÿä»¥åŒ…å«å¤šå€‹å°ˆç§‘
    
    return {
        'user_summary': user_summary,
        'analysis': diagnosis_result['analysis'],
        'recommended_specialty': diagnosis_result['recommended_specialty'],
        'severity_level': diagnosis_result.get('severity_level', 'mild'),
        'emergency_needed': diagnosis_result.get('emergency_needed', False),
        'doctors': matched_doctors
    }

def extract_specialties_from_analysis(analysis_text: str) -> list:
    """å¾åˆ†æçµæœä¸­æå–æ¨è–¦çš„å°ˆç§‘"""
    if not analysis_text:
        return ['å…§ç§‘']
    
    # Get available specialties from database
    available_specialties = get_available_specialties()
    
    # Create dynamic mapping based on database specialties
    specialty_mapping = {}
    for specialty in available_specialties:
        # Create variations for each specialty
        variations = [specialty]
        
        # Add common English translations and variations
        if 'å…§ç§‘' in specialty:
            variations.extend(['internal medicine', 'general medicine', 'family medicine'])
        elif 'å¤–ç§‘' in specialty:
            variations.extend(['surgery', 'general surgery'])
        elif 'å°å…’ç§‘' in specialty or 'å…’ç§‘' in specialty:
            variations.extend(['pediatrics', 'pediatric'])
        elif 'å©¦ç”¢ç§‘' in specialty:
            variations.extend(['obstetrics', 'gynecology', 'ob/gyn', 'obgyn'])
        elif 'éª¨ç§‘' in specialty:
            variations.extend(['orthopedics', 'orthopedic'])
        elif 'çš®è†šç§‘' in specialty:
            variations.extend(['dermatology', 'dermatologic'])
        elif 'çœ¼ç§‘' in specialty:
            variations.extend(['ophthalmology', 'eye'])
        elif 'è€³é¼»å–‰' in specialty:
            variations.extend(['ent', 'otolaryngology'])
        elif 'ç²¾ç¥ç§‘' in specialty:
            variations.extend(['psychiatry', 'psychiatric', 'mental health'])
        elif 'ç¥ç¶“ç§‘' in specialty:
            variations.extend(['neurology', 'neurologic'])
        elif 'å¿ƒè‡Ÿç§‘' in specialty or 'å¿ƒè¡€ç®¡' in specialty:
            variations.extend(['cardiology', 'cardiac'])
        elif 'æ€¥è¨º' in specialty:
            variations.extend(['emergency', 'emergency medicine', 'er'])
        elif 'æ„ŸæŸ“' in specialty:
            variations.extend(['infectious disease', 'infection'])
        elif 'è…è‡Ÿç§‘' in specialty:
            variations.extend(['nephrology', 'kidney'])
        elif 'èƒƒè…¸ç§‘' in specialty or 'æ¶ˆåŒ–ç§‘' in specialty:
            variations.extend(['gastroenterology', 'digestive'])
        elif 'å‘¼å¸ç§‘' in specialty:
            variations.extend(['pulmonology', 'respiratory'])
        elif 'è¡€æ¶²ç§‘' in specialty:
            variations.extend(['hematology', 'blood'])
        elif 'è…«ç˜¤ç§‘' in specialty:
            variations.extend(['oncology', 'cancer'])
        elif 'é¢¨æ¿•ç§‘' in specialty:
            variations.extend(['rheumatology', 'rheumatic'])
        elif 'å…§åˆ†æ³Œ' in specialty:
            variations.extend(['endocrinology', 'hormone'])
        elif 'æ³Œå°¿ç§‘' in specialty:
            variations.extend(['urology', 'urologic'])
        elif 'æ”¾å°„ç§‘' in specialty:
            variations.extend(['radiology', 'imaging'])
        elif 'ç—…ç†ç§‘' in specialty:
            variations.extend(['pathology'])
        elif 'éº»é†‰ç§‘' in specialty:
            variations.extend(['anesthesiology'])
        elif 'å¾©å¥ç§‘' in specialty:
            variations.extend(['rehabilitation', 'physical medicine'])
        elif 'æ ¸é†«ç§‘' in specialty:
            variations.extend(['nuclear medicine'])
        elif 'æ•´å½¢å¤–ç§‘' in specialty:
            variations.extend(['plastic surgery'])
        elif 'ç¥ç¶“å¤–ç§‘' in specialty:
            variations.extend(['neurosurgery'])
        elif 'èƒ¸è…”å¤–ç§‘' in specialty:
            variations.extend(['thoracic surgery'])
        elif 'å¿ƒè‡Ÿå¤–ç§‘' in specialty:
            variations.extend(['cardiac surgery'])
        elif 'è¡€ç®¡å¤–ç§‘' in specialty:
            variations.extend(['vascular surgery'])
        elif 'å¤§è…¸ç›´è…¸å¤–ç§‘' in specialty:
            variations.extend(['colorectal surgery'])
        
        specialty_mapping[specialty] = {'variations': variations}
    
    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å°ˆç§‘è³‡è¨Š (æ”¯æ´ä¸­è‹±æ–‡)
    specialty_patterns = [
        r'æ¨è–¦å°ˆç§‘[ï¼š:]\s*([^\n\r]+)',
        r'å»ºè­°å°ˆç§‘[ï¼š:]\s*([^\n\r]+)', 
        r'å°ˆç§‘[ï¼š:]\s*([^\n\r]+)',
        r'ç§‘åˆ¥[ï¼š:]\s*([^\n\r]+)',
        r'Recommended specialty[ï¼š:]?\s*([^\n\r]+)',
        r'Specialty[ï¼š:]?\s*([^\n\r]+)',
        r'([^ã€‚\n\r]*(?:ç§‘|Specialist|Medicine|Surgery|ology|ics))\s*(?:é†«å¸«|å°ˆç§‘|doctor)?',
    ]
    
    found_specialties = set()
    
    # é¦–å…ˆå˜—è©¦å¾æ˜ç¢ºçš„å°ˆç§‘æ¨è–¦ä¸­æå–
    for pattern in specialty_patterns:
        matches = re.findall(pattern, analysis_text, re.IGNORECASE)
        if matches:
            recommended_specialty = matches[0].strip()
            print(f"DEBUG - Specialty pattern matched: '{pattern}' -> '{recommended_specialty}'")
            
            # æ¸…ç†æå–çš„å°ˆç§‘åç¨±
            recommended_specialty = re.sub(r'\s*(or|æˆ–)\s*.*$', '', recommended_specialty, flags=re.IGNORECASE).strip()
            
            # å°‹æ‰¾åŒ¹é…çš„æ¨™æº–å°ˆç§‘åç¨±
            for standard_specialty, specialty_info in specialty_mapping.items():
                for variation in specialty_info['variations']:
                    if variation.lower() in recommended_specialty.lower():
                        found_specialties.add(standard_specialty)
                        print(f"DEBUG - Primary specialty found: '{variation}' -> '{standard_specialty}'")
                        break
            break
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºçš„å°ˆç§‘æ¨è–¦ï¼Œæœç´¢é—œéµå­—
    if not found_specialties:
        print("DEBUG - No specialty pattern matched, searching for keywords")
        text_lower = analysis_text.lower()
        for standard_specialty, specialty_info in specialty_mapping.items():
            for variation in specialty_info['variations']:
                if variation.lower() in text_lower:
                    found_specialties.add(standard_specialty)
                    print(f"DEBUG - Keyword match found: '{variation}' -> '{standard_specialty}'")
    
    # å¦‚æœæ‰¾åˆ°äº†ä¸»è¦å°ˆç§‘ï¼Œæ·»åŠ ç›¸é—œå°ˆç§‘
    if found_specialties:
        primary_specialty = list(found_specialties)[0]  # å–ç¬¬ä¸€å€‹ä½œç‚ºä¸»è¦å°ˆç§‘
        related_specialties = specialty_mapping.get(primary_specialty, {}).get('related', [])
        
        print(f"DEBUG - Primary specialty: {primary_specialty}, Related: {related_specialties}")
        # æ·»åŠ æœ€å¤š2å€‹ç›¸é—œå°ˆç§‘ï¼Œé¿å…æ¨è–¦å¤ªå¤š
        for related in related_specialties[:2]:
            if related in specialty_mapping:  # ç¢ºä¿ç›¸é—œå°ˆç§‘å­˜åœ¨
                found_specialties.add(related)
                print(f"DEBUG - Added related specialty: {related}")
            else:
                print(f"DEBUG - Skipped invalid related specialty: {related}")
        
        result = list(found_specialties)
        print(f"DEBUG - Final specialties: {result}")
        return result
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•å°ˆç§‘ï¼Œè¿”å›å…§ç§‘ä½œç‚ºé»˜èª
    print("DEBUG - No specialty keywords found, defaulting to Internal Medicine")
    return ['å…§ç§‘']

def extract_specialty_from_diagnosis(diagnosis_text: str) -> str:
    """å¾è¨ºæ–·æ–‡æœ¬ä¸­æå–æ¨è–¦çš„å°ˆç§‘ï¼ˆå–®ä¸€å°ˆç§‘ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
    specialties = extract_specialties_from_analysis(diagnosis_text)
    return specialties[0] if specialties else 'å…§ç§‘'

def extract_specialty_from_ai_response(ai_response: str) -> str:
    """å¾AIå›æ‡‰ä¸­æå–æ¨è–¦çš„å°ˆç§‘ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
    return extract_specialty_from_diagnosis(ai_response)

def extract_severity_from_analysis(analysis_text: str) -> str:
    """å¾åˆ†æçµæœä¸­æå–åš´é‡ç¨‹åº¦"""
    if not analysis_text:
        return 'mild'
    
    text_lower = analysis_text.lower()
    
    # First check for explicit severity statements
    explicit_severity_patterns = [
        ('åš´é‡ç¨‹åº¦ï¼šè¼•å¾®', 'mild'),
        ('åš´é‡ç¨‹åº¦ï¼šä¸­ç­‰', 'moderate'), 
        ('åš´é‡ç¨‹åº¦ï¼šåš´é‡', 'severe'),
        ('severity: mild', 'mild'),
        ('severity: moderate', 'moderate'),
        ('severity: severe', 'severe')
    ]
    
    for pattern, severity in explicit_severity_patterns:
        if pattern in text_lower:
            print(f"DEBUG - Explicit severity found: '{pattern}' -> {severity}")
            return severity
    
    # Check for non-emergency indicators that should override severity keywords
    non_emergency_patterns = [
        'ä¸éœ€è¦ç·Šæ€¥å°±é†«', 'éç·Šæ€¥', 'ä¸ç·Šæ€¥', 'not emergency', 'no emergency needed',
        'ä¸éœ€è¦æ€¥è¨º', 'ç„¡éœ€ç·Šæ€¥', 'non-urgent', 'not urgent'
    ]
    
    is_non_emergency = False
    for pattern in non_emergency_patterns:
        if pattern in text_lower:
            is_non_emergency = True
            print(f"DEBUG - Non-emergency pattern found in severity check: '{pattern}'")
            break
    
    emergency_keywords = [
        'emergency', 'ç·Šæ€¥', 'æ€¥è¨º', 'urgent', 'åš´é‡', 'severe', 'critical', 'å±æ€¥',
        'life-threatening', 'å¨è„…ç”Ÿå‘½', 'immediate', 'ç«‹å³', 'high risk', 'é«˜é¢¨éšª'
    ]
    
    moderate_keywords = [
        'moderate', 'ä¸­ç­‰', 'ä¸­åº¦', 'medium', 'é©ä¸­', 'ä¸€èˆ¬åš´é‡'
    ]
    
    found_emergency = []
    for keyword in emergency_keywords:
        if keyword in text_lower:
            found_emergency.append(keyword)
    
    found_moderate = []
    for keyword in moderate_keywords:
        if keyword in text_lower:
            found_moderate.append(keyword)
    
    print(f"DEBUG - Severity check - Emergency keywords found: {found_emergency}")
    print(f"DEBUG - Severity check - Moderate keywords found: {found_moderate}")
    
    # If explicitly marked as non-emergency, don't return severe even if keywords found
    if is_non_emergency and found_emergency:
        print("DEBUG - Non-emergency override: downgrading from severe to moderate")
        return 'moderate'
    
    if found_emergency:
        return 'severe'
    
    if found_moderate:
        return 'moderate'
    
    return 'mild'

def check_emergency_needed(diagnosis_text: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦éœ€è¦ç·Šæ€¥å°±é†« - æ›´ä¿å®ˆçš„ç·Šæ€¥æª¢æ¸¬"""
    if not diagnosis_text:
        return False
    
    text_lower = diagnosis_text.lower()
    
    # First check for explicit non-emergency statements - these override everything
    non_emergency_patterns = [
        'ä¸éœ€è¦ç·Šæ€¥å°±é†«', 'éç·Šæ€¥', 'ä¸ç·Šæ€¥', 'not emergency', 'no emergency needed',
        'ä¸éœ€è¦æ€¥è¨º', 'ç„¡éœ€ç·Šæ€¥', 'non-urgent', 'not urgent',
        'ç·Šæ€¥ç¨‹åº¦ï¼šå¦', 'ç·Šæ€¥ç¨‹åº¦: å¦', 'emergency: no', 'emergency:no',
        'ä¸ç”¨ç·Šæ€¥', 'æ¯‹é ˆç·Šæ€¥', 'ç„¡é ˆç«‹å³', 'ä¸å¿…ç«‹å³'
    ]
    
    for pattern in non_emergency_patterns:
        if pattern in text_lower:
            print(f"DEBUG - Non-emergency pattern found: '{pattern}' - overriding emergency detection")
            return False
    
    # Primary emergency format indicators - most reliable
    primary_emergency_indicators = [
        'ç·Šæ€¥ç¨‹åº¦ï¼šæ˜¯', 'ç·Šæ€¥ç¨‹åº¦: æ˜¯', 'emergency: yes', 'emergency:yes'
    ]
    
    for indicator in primary_emergency_indicators:
        if indicator in text_lower:
            print(f"DEBUG - Primary emergency format found: '{indicator}'")
            return True
    
    # Strong emergency action indicators - require immediate action
    strong_emergency_indicators = [
        'call emergency', 'æ’¥æ‰“æ€¥æ•‘', 'go to emergency', 'å‰å¾€æ€¥è¨º',
        'emergency room', 'æ€¥è¨ºå®¤', 'hospital immediately', 'ç«‹å³ä½é™¢',
        'life-threatening', 'å¨è„…ç”Ÿå‘½', 'critical condition', 'å±æ€¥ç‹€æ³',
        '999', '911', '112', 'ambulance', 'æ•‘è­·è»Š',
        'immediately seek medical', 'urgent medical attention'
    ]
    
    found_strong = []
    for indicator in strong_emergency_indicators:
        if indicator in text_lower:
            found_strong.append(indicator)
    
    if found_strong:
        print(f"DEBUG - Strong emergency action indicators found: {found_strong}")
        return True
    
    # Critical medical conditions - only very specific life-threatening conditions
    critical_conditions = [
        'å¿ƒè‚Œæ¢—å¡', 'æ€¥æ€§å¿ƒè‚Œæ¢—å¡', 'ä¸­é¢¨', 'æ€¥æ€§ä¸­é¢¨', 'è…¦ä¸­é¢¨',
        'æ€¥æ€§è…¹ç—›', 'æ€¥æ€§èƒ¸ç—›', 'å‘¼å¸å›°é›£', 'æ„è­˜ä¸æ¸…', 'æ˜è¿·',
        'å¤§é‡å‡ºè¡€', 'åš´é‡å¤–å‚·', 'éª¨æŠ˜', 'æ€¥æ€§éæ•åæ‡‰'
    ]
    
    found_critical = []
    for condition in critical_conditions:
        if condition in text_lower:
            found_critical.append(condition)
    
    if found_critical:
        # Check if these conditions are mentioned in a hypothetical or conditional context
        conditional_phrases = [
            'å¦‚æœæ˜¯', 'è‹¥æ˜¯', 'å¯èƒ½æ˜¯', 'ç–‘ä¼¼', 'æ’é™¤', 'ä¸åƒæ˜¯', 'ä¸å¤ªå¯èƒ½',
            'å»ºè­°æ’é™¤', 'éœ€è¦æ’é™¤', 'è‹¥å‡ºç¾', 'å¦‚æœå‡ºç¾', 'å‡å¦‚', 'è¬ä¸€'
        ]
        
        is_conditional = False
        for phrase in conditional_phrases:
            if phrase in text_lower:
                is_conditional = True
                print(f"DEBUG - Critical condition '{found_critical}' mentioned in conditional context: '{phrase}'")
                break
        
        if not is_conditional:
            print(f"DEBUG - Critical medical conditions found (not conditional): {found_critical}")
            return True
        else:
            print(f"DEBUG - Critical conditions mentioned conditionally, not immediate emergency")
    
    # Emergency action phrases - but only if not conditional
    emergency_actions = [
        'éœ€è¦ç·Šæ€¥å°±é†«', 'å»ºè­°ç·Šæ€¥å°±é†«', 'ç«‹å³å°±é†«', 'é¦¬ä¸Šå°±é†«', 'æ€¥éœ€å°±é†«',
        'ç·Šæ€¥é†«ç™‚', 'ç·Šæ€¥è™•ç†'
    ]
    
    found_actions = []
    for action in emergency_actions:
        if action in text_lower:
            found_actions.append(action)
    
    if found_actions:
        # Check if these are conditional recommendations
        conditional_contexts = [
            'è‹¥ç—‡ç‹€æƒ¡åŒ–', 'å¦‚æœæƒ¡åŒ–', 'ç—‡ç‹€æŒçºŒ', 'æŒçºŒæˆ–æƒ¡åŒ–', 'å¦‚æœæ²’æœ‰æ”¹å–„',
            'è‹¥ç„¡æ”¹å–„', 'å¦‚æœåŠ é‡', 'ç—‡ç‹€åŠ é‡æ™‚', 'æƒ¡åŒ–æ™‚', 'è‹¥å‡ºç¾'
        ]
        
        is_conditional = False
        for context in conditional_contexts:
            if context in text_lower:
                is_conditional = True
                print(f"DEBUG - Emergency action '{found_actions}' in conditional context: '{context}'")
                break
        
        if not is_conditional:
            print(f"DEBUG - Direct emergency action recommendations found: {found_actions}")
            return True
        else:
            print(f"DEBUG - Emergency actions are conditional recommendations, not immediate emergency")
    
    print("DEBUG - No immediate emergency indicators found")
    return False

def safe_str_check(value, search_term):
    """å®‰å…¨çš„å­—ç¬¦ä¸²æª¢æŸ¥ï¼Œè™•ç†NaNå€¼"""
    if pd.isna(value) or value is None:
        return False
    return search_term in str(value)

def filter_doctors(recommended_specialty: str, language: str, location: str, symptoms: str, ai_analysis: str, location_details: dict = None) -> list:
    """æ ¹æ“šæ¢ä»¶ç¯©é¸é†«ç”Ÿ"""
    matched_doctors = []
    
    # Debug logging
    print(f"DEBUG - filter_doctors called with:")
    print(f"  location: {location}")
    print(f"  location_details: {location_details}")
    print(f"  recommended_specialty: {recommended_specialty}")
    
    total_processed = 0
    total_matched = 0
    
    for doctor in DOCTORS_DATA:
        total_processed += 1
        score = 0
        match_reasons = []
        
        # å°ˆç§‘åŒ¹é… (é™ä½åˆ†æ•¸ï¼Œå„ªå…ˆè€ƒæ…®åœ°å€)
        doctor_specialty = doctor.get('specialty', '')
        if doctor_specialty and not pd.isna(doctor_specialty):
            doctor_specialty = str(doctor_specialty)
            if safe_str_check(doctor_specialty, recommended_specialty):
                score += 25  # å¾50é™åˆ°25
                match_reasons.append(f"å°ˆç§‘åŒ¹é…ï¼š{doctor_specialty}")
            elif safe_str_check(doctor_specialty, 'æ™®é€šç§‘') or safe_str_check(doctor_specialty, 'å…§ç§‘'):
                score += 15  # å¾30é™åˆ°15
                match_reasons.append("å¯è™•ç†ä¸€èˆ¬ç—‡ç‹€")
        
        # èªè¨€åŒ¹é…
        doctor_languages = doctor.get('languages', '')
        if doctor_languages and not pd.isna(doctor_languages):
            doctor_languages = str(doctor_languages)
            if safe_str_check(doctor_languages, language):
                score += 30
                match_reasons.append(f"èªè¨€åŒ¹é…ï¼š{language}")
        
        # Get UI language from session for doctor prioritization
        ui_language = session.get('language', 'zh-TW')

        # Language-based doctor prioritization
        doctor_languages = doctor.get('languages', '')
        if doctor_languages and not pd.isna(doctor_languages):
            doctor_languages = str(doctor_languages)

            if ui_language == 'en':
                # For English UI, prioritize doctors who speak English
                if safe_str_check(doctor_languages, 'English') or safe_str_check(doctor_languages, 'è‹±æ–‡'):
                    score += 20
                    match_reasons.append("English-speaking doctor (English preference)")
            else:
                # For Chinese UI, prioritize doctors who speak Chinese
                if safe_str_check(doctor_languages, 'ä¸­æ–‡') or safe_str_check(doctor_languages, 'åœ‹èª') or safe_str_check(doctor_languages, 'ç²µèª'):
                    score += 10
                    match_reasons.append("Chinese-speaking doctor (Chinese preference)")
        # 3å±¤åœ°å€åŒ¹é…ç³»çµ±
        location_matched = False  # åˆå§‹åŒ–è®Šé‡
        
        # ç²å–3å±¤ä½ç½®ä¿¡æ¯ (ç§»åˆ°å¤–å±¤ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨)
        if location_details is None:
            location_details = {}
        
        user_region = location_details.get('region', '')
        user_district = location_details.get('district', '')
        user_area = location_details.get('area', '')
        
        # å®šç¾©å„å€çš„é—œéµè©åŒ¹é… (ç§»åˆ°å¤–å±¤ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨)
        district_keywords = {
                # é¦™æ¸¯å³¶
                'ä¸­è¥¿å€': ['ä¸­ç’°', 'ä¸Šç’°', 'è¥¿ç’°', 'é‡‘é˜', 'å …å°¼åœ°åŸ', 'çŸ³å¡˜å’€', 'è¥¿ç‡Ÿç›¤'],
                'æ±å€': ['éŠ…é‘¼ç£', 'å¤©å', 'ç‚®å°å±±', 'åŒ—è§’', 'é°‚é­šæ¶Œ', 'è¥¿ç£æ²³', 'ç­²ç®•ç£', 'æŸ´ç£', 'å°è¥¿ç£'],
                'å—å€': ['é¦™æ¸¯ä»”', 'é´¨è„·æ´²', 'é»ƒç«¹å‘', 'æ·±æ°´ç£', 'æ·ºæ°´ç£', 'èµ¤æŸ±', 'çŸ³æ¾³'],
                'ç£ä»”å€': ['ç£ä»”', 'è·‘é¦¬åœ°', 'å¤§å‘', 'æ¸£ç”¸å±±', 'å¯¶é¦¬å±±'],
                
                # ä¹é¾
                'ä¹é¾åŸå€': ['ä¹é¾åŸ', 'åœŸç“œç£', 'é¦¬é ­è§’', 'é¦¬é ­åœ', 'å•Ÿå¾·', 'ç´…ç£¡', 'ä½•æ–‡ç”°'],
                'è§€å¡˜å€': ['è§€å¡˜', 'ç‰›é ­è§’', 'ä¹é¾ç£', 'å½©è™¹', 'åªçŸ³', 'ç§€èŒ‚åª', 'è—ç”°', 'æ²¹å¡˜'],
                'æ·±æ°´åŸ—å€': ['æ·±æ°´åŸ—', 'é•·æ²™ç£', 'è”æè§’', 'ç¾å­š', 'çŸ³ç¡¤å°¾', 'åˆä¸€æ‘'],
                'é»ƒå¤§ä»™å€': ['é»ƒå¤§ä»™', 'æ–°è’²å´—', 'æ¨‚å¯Œ', 'æ©«é ­ç£¡', 'æ±é ­', 'ç«¹åœ’', 'æ…ˆé›²å±±', 'é‘½çŸ³å±±'],
                'æ²¹å°–æ—ºå€': ['æ²¹éº»åœ°', 'å°–æ²™å’€', 'æ—ºè§’', 'å¤§è§’å’€', 'å¤ªå­', 'ä½æ•¦'],
                
                # æ–°ç•Œ
                'é›¢å³¶å€': ['é•·æ´²', 'å—ä¸«å³¶', 'åªæ´²', 'å¤§å¶¼å±±', 'æ±æ¶Œ', 'æ„‰æ™¯ç£'],
                'è‘µé’å€': ['è‘µæ¶Œ', 'é’è¡£', 'è‘µèŠ³', 'è”æ™¯'],
                'åŒ—å€': ['ä¸Šæ°´', 'ç²‰å¶º', 'æ‰“é¼“å¶º', 'æ²™é ­è§’', 'é¹¿é ¸'],
                'è¥¿è²¢å€': ['è¥¿è²¢', 'å°‡è»æ¾³', 'å‘å£', 'èª¿æ™¯å¶º', 'å¯¶æ—', 'åº·ç››èŠ±åœ’'],
                'æ²™ç”°å€': ['æ²™ç”°', 'å¤§åœ', 'ç«ç‚­', 'é¦¬éå±±', 'çƒæºªæ²™'],
                'å¤§åŸ”å€': ['å¤§åŸ”', 'å¤ªå’Œ', 'å¤§åŸ”å¢Ÿ', 'æ—æ‘', 'æ±€è§’'],
                'èƒç£å€': ['èƒç£', 'æ¢¨æœ¨æ¨¹', 'è±¡å±±', 'åŸé–€'],
                'å±¯é–€å€': ['å±¯é–€', 'å‹æ„›', 'å®‰å®š', 'å±±æ™¯', 'å¤§èˆˆ', 'è‰¯æ™¯', 'å»ºç”Ÿ'],
                'å…ƒæœ—å€': ['å…ƒæœ—', 'å¤©æ°´åœ', 'æ´ªæ°´æ©‹', 'æµæµ®å±±', 'éŒ¦ç”°', 'å…«é„‰']
            }
        
        doctor_address = doctor.get('address', '')
        
        # Debug: Check if we're getting the right field name
        if len(matched_doctors) < 2:
            print(f"DEBUG - Available doctor fields: {list(doctor.keys())}")
            print(f"DEBUG - address value: '{doctor_address}'")
        
        if doctor_address and not pd.isna(doctor_address):
            doctor_address = str(doctor_address)
            
            # Limit debug output to first 5 doctors to avoid spam
            if len(matched_doctors) < 5:
                print(f"DEBUG - Doctor: {doctor.get('name_zh', 'Unknown')}, Address: {doctor_address[:100]}...")
                print(f"DEBUG - User location: Region={user_region}, District={user_district}, Area={user_area}")
                print(f"DEBUG - Checking area match: '{user_area}' in '{doctor_address}' = {safe_str_check(doctor_address, user_area) if user_area else False}")
                if user_district in district_keywords:
                    keywords = district_keywords[user_district]
                    print(f"DEBUG - District keywords for {user_district}: {keywords}")
                    for keyword in keywords:
                        if safe_str_check(doctor_address, keyword):
                            print(f"DEBUG - Found district keyword match: '{keyword}' in address")
            
            # ç¬¬1å±¤ï¼šç²¾ç¢ºåœ°å€åŒ¹é… (å¤§å¹…æé«˜åˆ†æ•¸)
            if user_area and safe_str_check(doctor_address, user_area):
                score += 60  # å¾35æé«˜åˆ°60
                match_reasons.append(f"ç²¾ç¢ºä½ç½®åŒ¹é…ï¼š{user_area}")
                location_matched = True
                print(f"DEBUG - Exact area match: {user_area}")
            
            # ç¬¬2å±¤ï¼šåœ°å€åŒ¹é… (æé«˜åˆ†æ•¸)
            elif user_district and user_district in district_keywords:
                keywords = district_keywords[user_district]
                print(f"DEBUG - Checking district {user_district} keywords: {keywords}")
                for keyword in keywords:
                    if safe_str_check(doctor_address, keyword):
                        score += 45  # å¾25æé«˜åˆ°45
                        print(f"DEBUG - District keyword match: {keyword}")
                        match_reasons.append(f"åœ°å€åŒ¹é…ï¼š{user_district}")
                        location_matched = True
                        break
            
            # ç¬¬3å±¤ï¼šå¤§å€åŒ¹é… (æé«˜åˆ†æ•¸)
            if not location_matched and user_region:
                # é¦™æ¸¯å³¶å¤§å€ - æ“´å±•é—œéµè©
                if user_region == 'é¦™æ¸¯å³¶' and any(safe_str_check(doctor_address, keyword) for keyword in ['é¦™æ¸¯', 'ä¸­ç’°', 'ç£ä»”', 'éŠ…é‘¼ç£', 'ä¸Šç’°', 'è¥¿ç’°', 'å¤©å', 'åŒ—è§’', 'é°‚é­šæ¶Œ', 'æŸ´ç£', 'ç­²ç®•ç£', 'é¦™æ¸¯ä»”']):
                    score += 30  # å¾15æé«˜åˆ°30
                    match_reasons.append("å¤§å€åŒ¹é…ï¼šé¦™æ¸¯å³¶")
                    location_matched = True
                
                # ä¹é¾å¤§å€ - æ“´å±•é—œéµè©
                elif user_region == 'ä¹é¾' and any(safe_str_check(doctor_address, keyword) for keyword in ['ä¹é¾', 'æ—ºè§’', 'å°–æ²™å’€', 'æ²¹éº»åœ°', 'ä½æ•¦', 'æ·±æ°´åŸ—', 'è§€å¡˜', 'é»ƒå¤§ä»™', 'åœŸç“œç£', 'ç´…ç£¡', 'è—ç”°', 'å½©è™¹', 'ç‰›é ­è§’']):
                    score += 30  # å¾15æé«˜åˆ°30
                    match_reasons.append("å¤§å€åŒ¹é…ï¼šä¹é¾")
                    location_matched = True
                
                # æ–°ç•Œå¤§å€ - æ“´å±•é—œéµè©
                elif user_region == 'æ–°ç•Œ' and any(safe_str_check(doctor_address, keyword) for keyword in ['æ–°ç•Œ', 'æ²™ç”°', 'å¤§åŸ”', 'å…ƒæœ—', 'å±¯é–€', 'èƒç£', 'å°‡è»æ¾³', 'ç²‰å¶º', 'ä¸Šæ°´', 'è‘µæ¶Œ', 'é’è¡£', 'é¦¬éå±±', 'å¤©æ°´åœ']):
                    score += 30  # å¾15æé«˜åˆ°30
                    match_reasons.append("å¤§å€åŒ¹é…ï¼šæ–°ç•Œ")
                    location_matched = True
            
            # å‘å¾Œå…¼å®¹ï¼šå¦‚æœæ²’æœ‰location_detailsï¼Œä½¿ç”¨èˆŠçš„locationåŒ¹é…
            if not location_matched and not user_region and location:
                if location in district_keywords:
                    keywords = district_keywords[location]
                    for keyword in keywords:
                        if safe_str_check(doctor_address, keyword):
                            score += 40  # å¾25æé«˜åˆ°40
                            match_reasons.append(f"åœ°å€åŒ¹é…ï¼š{location}")
                            location_matched = True
                            break
            
            # å¦‚æœä»ç„¶æ²’æœ‰åŒ¹é…åˆ°ä½ç½®ï¼Œå˜—è©¦ä½¿ç”¨locationå­—ç¬¦ä¸²ç›´æ¥åŒ¹é…
            if not location_matched and location:
                if safe_str_check(doctor_address, location):
                    score += 25  # å¾20æé«˜åˆ°25
                    match_reasons.append(f"ä½ç½®é—œéµè©åŒ¹é…ï¼š{location}")
                    location_matched = True
        
        # åŠ å…¥å„ªå…ˆç´šåˆ¥åˆ°åŒ¹é…åˆ†æ•¸
        priority_flag = doctor.get('priority_flag', 0)
        if priority_flag and not pd.isna(priority_flag):
            priority_bonus = int(priority_flag) * 10  # æ¯ç´šå„ªå…ˆç´šåŠ 10åˆ†
            score += priority_bonus
            if priority_bonus > 0:
                match_reasons.append(f"å„ªå…ˆé†«ç”Ÿ (ç´šåˆ¥ {priority_flag})")
        
        # å„ªå…ˆä¿ç•™æœ‰åœ°å€åŒ¹é…çš„é†«ç”Ÿï¼Œä½†ä¹Ÿå…è¨±é«˜åˆ†é†«ç”Ÿ
        if location_matched or score >= 30:
            total_matched += 1
            # æ¸…ç†é†«ç”Ÿæ•¸æ“šï¼Œç¢ºä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å­—ç¬¦ä¸²
            doctor_copy = {}
            for key, value in doctor.items():
                if pd.isna(value) or value is None:
                    doctor_copy[key] = ''
                else:
                    doctor_copy[key] = str(value)
            
            doctor_copy['match_score'] = score
            doctor_copy['match_reasons'] = match_reasons
            doctor_copy['ai_analysis'] = ai_analysis
            
            # æ·»åŠ åœ°ç†ç›¸é—œæ€§æ’åºæ¬Šé‡ (é‡æ–°è¨ˆç®—ä»¥ç¢ºä¿æº–ç¢ºæ€§)
            location_priority = 0
            
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“åœ¨location matchingä¸­åŒ¹é…åˆ°ä½ç½®
            if location_matched:
                # æ ¹æ“šå·²æœ‰çš„location matchingçµæœè¨­ç½®å„ªå…ˆç´š
                if user_area and safe_str_check(doctor_address, user_area):
                    location_priority = 4  # æœ€é«˜å„ªå…ˆç´šï¼šç²¾ç¢ºåœ°å€åŒ¹é…
                elif user_district and user_district in district_keywords:
                    keywords = district_keywords[user_district]
                    for keyword in keywords:
                        if safe_str_check(doctor_address, keyword):
                            location_priority = 3  # ç¬¬äºŒå„ªå…ˆç´šï¼šåœ°å€åŒ¹é…
                            break
                elif user_region:
                    # å¤§å€åŒ¹é…
                    if ((user_region == 'é¦™æ¸¯å³¶' and any(safe_str_check(doctor_address, keyword) for keyword in ['é¦™æ¸¯', 'ä¸­ç’°', 'ç£ä»”', 'éŠ…é‘¼ç£', 'ä¸Šç’°', 'è¥¿ç’°', 'å¤©å', 'åŒ—è§’', 'é°‚é­šæ¶Œ', 'æŸ´ç£', 'ç­²ç®•ç£', 'é¦™æ¸¯ä»”'])) or
                        (user_region == 'ä¹é¾' and any(safe_str_check(doctor_address, keyword) for keyword in ['ä¹é¾', 'æ—ºè§’', 'å°–æ²™å’€', 'æ²¹éº»åœ°', 'ä½æ•¦', 'æ·±æ°´åŸ—', 'è§€å¡˜', 'é»ƒå¤§ä»™', 'åœŸç“œç£', 'ç´…ç£¡', 'è—ç”°', 'å½©è™¹', 'ç‰›é ­è§’'])) or
                        (user_region == 'æ–°ç•Œ' and any(safe_str_check(doctor_address, keyword) for keyword in ['æ–°ç•Œ', 'æ²™ç”°', 'å¤§åŸ”', 'å…ƒæœ—', 'å±¯é–€', 'èƒç£', 'å°‡è»æ¾³', 'ç²‰å¶º', 'ä¸Šæ°´', 'è‘µæ¶Œ', 'é’è¡£', 'é¦¬éå±±', 'å¤©æ°´åœ']))):
                        location_priority = 2  # ç¬¬ä¸‰å„ªå…ˆç´šï¼šå¤§å€åŒ¹é…
                elif location and safe_str_check(doctor_address, location):
                    location_priority = 1  # æœ€ä½å„ªå…ˆç´šï¼šé—œéµè©åŒ¹é…
            
            # Debug: é¡¯ç¤ºlocation priorityè¨ˆç®—
            if len(matched_doctors) < 3:
                print(f"DEBUG - Doctor {doctor.get('name_zh', 'Unknown')}: location_matched={location_matched}, location_priority={location_priority}")
                print(f"DEBUG - Doctor address: '{doctor_address}'")
                print(f"DEBUG - User location: area='{user_area}', district='{user_district}', region='{user_region}'")
            
            doctor_copy['location_priority'] = location_priority
            matched_doctors.append(doctor_copy)
    
    print(f"DEBUG - Processed {total_processed} doctors, matched {total_matched} doctors")
    
    # æŒ‰åœ°ç†ç›¸é—œæ€§å„ªå…ˆæ’åºï¼Œç„¶å¾ŒæŒ‰åŒ¹é…åˆ†æ•¸æ’åº
    matched_doctors.sort(key=lambda x: (x['location_priority'], x['match_score']), reverse=True)
    
    # Debug: é¡¯ç¤ºå‰5å€‹é†«ç”Ÿçš„åœ°ç†å„ªå…ˆç´šå’Œåˆ†æ•¸
    print(f"DEBUG - Top 5 doctors after sorting:")
    for i, doctor in enumerate(matched_doctors[:5]):
        print(f"  {i+1}. {doctor.get('name_zh', 'Unknown')} - Priority: {doctor.get('location_priority', 0)}, Score: {doctor.get('match_score', 0)}, Address: {doctor.get('clinic_addresses', '')[:50]}...")
    
    # ç¸½æ˜¯æ·»åŠ è©²åœ°å€çš„æ™®é€šç§‘/å…§ç§‘é†«ç”Ÿä½œç‚ºé¸é …ï¼Œè®“ç”¨æˆ¶æœ‰æ›´å¤šé¸æ“‡
    print(f"DEBUG - Adding regional GP/internist options. Current matches: {len(matched_doctors)}")
    fallback_doctors = get_regional_gp_fallback(location_details, location, recommended_specialty)
    
    # é¿å…é‡è¤‡æ·»åŠ å·²å­˜åœ¨çš„é†«ç”Ÿ
    existing_names = {doctor.get('name_zh', '') for doctor in matched_doctors}
    for fallback_doctor in fallback_doctors:
        if fallback_doctor.get('name_zh', '') not in existing_names:
            matched_doctors.append(fallback_doctor)
    
    # é‡æ–°æ’åº (åœ°ç†ç›¸é—œæ€§å„ªå…ˆ)
    matched_doctors.sort(key=lambda x: (x.get('location_priority', 0), x['match_score']), reverse=True)
    
    # è¿”å›å‰50åä¾›åˆ†é ä½¿ç”¨
    return matched_doctors[:50]

def get_regional_gp_fallback(location_details: dict, location: str, original_specialty: str) -> list:
    """ç²å–è©²åœ°å€çš„æ™®é€šç§‘/å…§ç§‘é†«ç”Ÿä½œç‚ºå¾Œå‚™æ¨è–¦"""
    fallback_doctors = []
    
    if location_details is None:
        location_details = {}
    
    user_region = location_details.get('region', '')
    user_district = location_details.get('district', '')
    user_area = location_details.get('area', '')
    
    print(f"DEBUG - Looking for GP/internist fallback in region: {user_region}, district: {user_district}")
    
    # å®šç¾©å„å€çš„é—œéµè©åŒ¹é…
    district_keywords = {
        # é¦™æ¸¯å³¶
        'ä¸­è¥¿å€': ['ä¸­ç’°', 'ä¸Šç’°', 'è¥¿ç’°', 'é‡‘é˜', 'å …å°¼åœ°åŸ', 'çŸ³å¡˜å’€', 'è¥¿ç‡Ÿç›¤'],
        'æ±å€': ['éŠ…é‘¼ç£', 'å¤©å', 'ç‚®å°å±±', 'åŒ—è§’', 'é°‚é­šæ¶Œ', 'è¥¿ç£æ²³', 'ç­²ç®•ç£', 'æŸ´ç£', 'å°è¥¿ç£'],
        'å—å€': ['é¦™æ¸¯ä»”', 'é´¨è„·æ´²', 'é»ƒç«¹å‘', 'æ·±æ°´ç£', 'æ·ºæ°´ç£', 'èµ¤æŸ±', 'çŸ³æ¾³'],
        'ç£ä»”å€': ['ç£ä»”', 'è·‘é¦¬åœ°', 'å¤§å‘', 'æ¸£ç”¸å±±', 'å¯¶é¦¬å±±'],
        
        # ä¹é¾
        'ä¹é¾åŸå€': ['ä¹é¾åŸ', 'åœŸç“œç£', 'é¦¬é ­è§’', 'é¦¬é ­åœ', 'å•Ÿå¾·', 'ç´…ç£¡', 'ä½•æ–‡ç”°'],
        'è§€å¡˜å€': ['è§€å¡˜', 'ç‰›é ­è§’', 'ä¹é¾ç£', 'å½©è™¹', 'åªçŸ³', 'ç§€èŒ‚åª', 'è—ç”°', 'æ²¹å¡˜'],
        'æ·±æ°´åŸ—å€': ['æ·±æ°´åŸ—', 'é•·æ²™ç£', 'è”æè§’', 'ç¾å­š', 'çŸ³ç¡¤å°¾', 'åˆä¸€æ‘'],
        'é»ƒå¤§ä»™å€': ['é»ƒå¤§ä»™', 'æ–°è’²å´—', 'æ¨‚å¯Œ', 'æ©«é ­ç£¡', 'æ±é ­', 'ç«¹åœ’', 'æ…ˆé›²å±±', 'é‘½çŸ³å±±'],
        'æ²¹å°–æ—ºå€': ['æ²¹éº»åœ°', 'å°–æ²™å’€', 'æ—ºè§’', 'å¤§è§’å’€', 'å¤ªå­', 'ä½æ•¦'],
        
        # æ–°ç•Œ
        'é›¢å³¶å€': ['é•·æ´²', 'å—ä¸«å³¶', 'åªæ´²', 'å¤§å¶¼å±±', 'æ±æ¶Œ', 'æ„‰æ™¯ç£'],
        'è‘µé’å€': ['è‘µæ¶Œ', 'é’è¡£', 'è‘µèŠ³', 'è”æ™¯'],
        'åŒ—å€': ['ä¸Šæ°´', 'ç²‰å¶º', 'æ‰“é¼“å¶º', 'æ²™é ­è§’', 'é¹¿é ¸'],
        'è¥¿è²¢å€': ['è¥¿è²¢', 'å°‡è»æ¾³', 'å‘å£', 'èª¿æ™¯å¶º', 'å¯¶æ—', 'åº·ç››èŠ±åœ’'],
        'æ²™ç”°å€': ['æ²™ç”°', 'å¤§åœ', 'ç«ç‚­', 'é¦¬éå±±', 'çƒæºªæ²™'],
        'å¤§åŸ”å€': ['å¤§åŸ”', 'å¤ªå’Œ', 'å¤§åŸ”å¢Ÿ', 'æ—æ‘', 'æ±€è§’'],
        'èƒç£å€': ['èƒç£', 'æ¢¨æœ¨æ¨¹', 'è±¡å±±', 'åŸé–€'],
        'å±¯é–€å€': ['å±¯é–€', 'å‹æ„›', 'å®‰å®š', 'å±±æ™¯', 'å¤§èˆˆ', 'è‰¯æ™¯', 'å»ºç”Ÿ'],
        'å…ƒæœ—å€': ['å…ƒæœ—', 'å¤©æ°´åœ', 'æ´ªæ°´æ©‹', 'æµæµ®å±±', 'éŒ¦ç”°', 'å…«é„‰']
    }
    
    for doctor in DOCTORS_DATA:
        doctor_specialty = doctor.get('specialty', '')
        if not doctor_specialty or pd.isna(doctor_specialty):
            continue
            
        doctor_specialty = str(doctor_specialty)
        
        # æŸ¥æ‰¾æ™®é€šç§‘ã€å…§ç§‘ã€å®¶åº­é†«å­¸ç§‘é†«ç”Ÿ
        if not (safe_str_check(doctor_specialty, 'æ™®é€šç§‘') or safe_str_check(doctor_specialty, 'å…§ç§‘') or 
                safe_str_check(doctor_specialty, 'å®¶åº­é†«å­¸') or safe_str_check(doctor_specialty, 'å…¨ç§‘') or
                safe_str_check(doctor_specialty, 'General Practitioner') or safe_str_check(doctor_specialty, 'Internal Medicine') or
                safe_str_check(doctor_specialty, 'Family Medicine')):
            continue
        
        doctor_address = doctor.get('address', '')
        if not doctor_address or pd.isna(doctor_address):
            continue
            
        doctor_address = str(doctor_address)
        score = 25  # åŸºç¤åˆ†æ•¸è¼ƒä½ï¼Œå› ç‚ºæ˜¯å¾Œå‚™é¸é …
        match_reasons = [f"åœ°å€å¾Œå‚™æ¨è–¦ï¼š{doctor_specialty}"]
        location_matched = False
        
        # åœ°å€åŒ¹é…é‚è¼¯ï¼ˆèˆ‡ä¸»è¦å‡½æ•¸ç›¸åŒï¼‰
        if user_area and safe_str_check(doctor_address, user_area):
            score += 30
            match_reasons.append(f"ç²¾ç¢ºä½ç½®åŒ¹é…ï¼š{user_area}")
            location_matched = True
        elif user_district and user_district in district_keywords:
            keywords = district_keywords[user_district]
            for keyword in keywords:
                if safe_str_check(doctor_address, keyword):
                    score += 20
                    match_reasons.append(f"åœ°å€åŒ¹é…ï¼š{user_district}")
                    location_matched = True
                    break
        
        # å¤§å€åŒ¹é…
        if not location_matched and user_region:
            if user_region == 'é¦™æ¸¯å³¶' and any(safe_str_check(doctor_address, keyword) for keyword in ['é¦™æ¸¯', 'ä¸­ç’°', 'ç£ä»”', 'éŠ…é‘¼ç£', 'ä¸Šç’°', 'è¥¿ç’°', 'å¤©å', 'åŒ—è§’', 'é°‚é­šæ¶Œ', 'æŸ´ç£', 'ç­²ç®•ç£', 'é¦™æ¸¯ä»”']):
                score += 10
                match_reasons.append("å¤§å€åŒ¹é…ï¼šé¦™æ¸¯å³¶")
                location_matched = True
            elif user_region == 'ä¹é¾' and any(safe_str_check(doctor_address, keyword) for keyword in ['ä¹é¾', 'æ—ºè§’', 'å°–æ²™å’€', 'æ²¹éº»åœ°', 'ä½æ•¦', 'æ·±æ°´åŸ—', 'è§€å¡˜', 'é»ƒå¤§ä»™', 'åœŸç“œç£', 'ç´…ç£¡', 'è—ç”°', 'å½©è™¹', 'ç‰›é ­è§’']):
                score += 10
                match_reasons.append("å¤§å€åŒ¹é…ï¼šä¹é¾")
                location_matched = True
            elif user_region == 'æ–°ç•Œ' and any(safe_str_check(doctor_address, keyword) for keyword in ['æ–°ç•Œ', 'æ²™ç”°', 'å¤§åŸ”', 'å…ƒæœ—', 'å±¯é–€', 'èƒç£', 'å°‡è»æ¾³', 'ç²‰å¶º', 'ä¸Šæ°´', 'è‘µæ¶Œ', 'é’è¡£', 'é¦¬éå±±', 'å¤©æ°´åœ']):
                score += 10
                match_reasons.append("å¤§å€åŒ¹é…ï¼šæ–°ç•Œ")
                location_matched = True
        
        # å‘å¾Œå…¼å®¹ï¼šå¦‚æœæ²’æœ‰location_detailsï¼Œä½¿ç”¨èˆŠçš„locationåŒ¹é…
        if not location_matched and not user_region and location:
            if location in district_keywords:
                keywords = district_keywords[location]
                for keyword in keywords:
                    if safe_str_check(doctor_address, keyword):
                        score += 15
                        match_reasons.append(f"åœ°å€åŒ¹é…ï¼š{location}")
                        location_matched = True
                        break
            elif safe_str_check(doctor_address, location):
                score += 10
                match_reasons.append(f"ä½ç½®é—œéµè©åŒ¹é…ï¼š{location}")
                location_matched = True
        
        # é™ä½é–€æª»ï¼Œå…è¨±æ›´å¤šGP/å…§ç§‘é†«ç”Ÿé€²å…¥å¾Œå‚™åˆ—è¡¨
        if location_matched or score >= 20:
            doctor_copy = {}
            for key, value in doctor.items():
                if pd.isna(value) or value is None:
                    doctor_copy[key] = ''
                else:
                    doctor_copy[key] = str(value)
            
            doctor_copy['match_score'] = score
            doctor_copy['match_reasons'] = match_reasons
            doctor_copy['ai_analysis'] = f"åœ°å€{doctor_specialty}æ¨è–¦ - å¯è™•ç†å¤šç¨®å¸¸è¦‹ç—‡ç‹€ï¼Œä¹Ÿå¯æä¾›è½‰ä»‹æœå‹™"
            doctor_copy['location_priority'] = 1 if location_matched else 0  # æ·»åŠ åœ°ç†å„ªå…ˆç´š
            fallback_doctors.append(doctor_copy)
    
    # æŒ‰åˆ†æ•¸æ’åºï¼Œè¿”å›å‰10å€‹
    fallback_doctors.sort(key=lambda x: x['match_score'], reverse=True)
    print(f"DEBUG - Found {len(fallback_doctors)} GP/internist fallback doctors")
    return fallback_doctors[:10]

@app.route('/')
def index():
    """ä¸»é """
    # Get user's preferred language from session or default to zh-TW
    current_lang = session.get('language', 'zh-TW')
    
    # Log page visit
    log_analytics('page_visit', {'page': 'index', 'language': current_lang}, 
                 get_real_ip(), request.user_agent.string, session.get('session_id'))
    return render_template('index.html', current_lang=current_lang, translations=TRANSLATIONS.get(current_lang, TRANSLATIONS['zh-TW']))

@app.route('/check_severe_symptoms', methods=['POST'])
def check_severe_symptoms():
    """æª¢æŸ¥æ˜¯å¦æœ‰åš´é‡ç—‡ç‹€æˆ–ç—…å²ï¼Œè¿”å›è­¦å‘Šä¿¡æ¯"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400
            
        symptoms = data.get('symptoms', '')
        chronic_conditions = data.get('chronicConditions', '')
        
        # æª¢æ¸¬åš´é‡ç—‡ç‹€å’Œç—…å²
        detection_result = detect_severe_symptoms_and_conditions(symptoms, chronic_conditions)
        
        if detection_result['is_severe']:
            # æ§‹å»ºè­¦å‘Šæ¶ˆæ¯
            warning_message = {
                'title': 'âš ï¸ é‡è¦é†«ç™‚æé†’',
                'message': 'æ ¹æ“šæ‚¨æä¾›çš„ç—‡ç‹€å’Œç—…å²ï¼Œä»¥ä¸‹æ˜¯é‡è¦æé†’ï¼š',
                'recommendations': [
                    'ğŸš¨ è€ƒæ…®å‰å¾€æœ€è¿‘çš„æ€¥è¨ºå®¤æˆ–é†«é™¢',
                    'ğŸ“ å¯æ’¥æ‰“999ç·Šæ€¥æœå‹™ç†±ç·š',
                    'ğŸ¥ å»ºè­°å°‹æ±‚å°ˆæ¥­é†«ç™‚äººå“¡çš„å”åŠ©',
                    'â° å¦‚ç—‡ç‹€åš´é‡ï¼Œè«‹å‹¿å»¶é²å°±é†«'
                ],
                'disclaimer': 'æ­¤ç³»çµ±åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆé†«ç™‚å»ºè­°æˆ–è¨ºæ–·ã€‚å°æ–¼åš´é‡æˆ–ç·Šæ€¥çš„é†«ç™‚ç‹€æ³ï¼Œè«‹è«®è©¢å°ˆæ¥­é†«ç™‚äººå“¡ã€‚',
                'severe_items': {
                    'symptoms': detection_result['severe_symptoms'],
                    'conditions': detection_result['severe_conditions']
                }
            }
            
            return jsonify({
                'is_severe': True,
                'warning': warning_message
            })
        else:
            return jsonify({
                'is_severe': False,
                'warning': None
            })
            
    except Exception as e:
        logger.error(f"Error checking severe symptoms: {e}")
        return jsonify({'error': 'æª¢æŸ¥éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.route('/find_doctor', methods=['POST'])
def find_doctor():
    """è™•ç†é†«ç”Ÿæœç´¢è«‹æ±‚"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400
        
        # Debug logging
        logger.info(f"Received find_doctor request with data keys: {list(data.keys())}")
        logger.info(f"Raw data values: age={data.get('age')}, symptoms='{data.get('symptoms')}', language='{data.get('language')}', location='{data.get('location')}'")
            
        try:
            age = int(data.get('age', 0))
        except (ValueError, TypeError) as e:
            logger.error(f"Invalid age value: {data.get('age')}, error: {e}")
            return jsonify({'error': 'å¹´é½¡å¿…é ˆæ˜¯æœ‰æ•ˆæ•¸å­—'}), 400
        gender = data.get('gender', '')
        symptoms = data.get('symptoms', '')
        chronic_conditions = data.get('chronicConditions', '')
        language = data.get('language', '')
        location = data.get('location', '')
        location_details = data.get('locationDetails', {})
        detailed_health_info = data.get('detailedHealthInfo', {})
        ui_language = data.get('uiLanguage', 'zh-TW')  # Get UI language for diagnosis
        
        # Debug parsed values
        logger.info(f"Parsed values: age={age}, symptoms='{symptoms}', language='{language}', location='{location}'")
        
        # é©—è­‰è¼¸å…¥ - gender is optional for backward compatibility
        if not symptoms or not language or not location or age <= 0:
            missing_fields = []
            if age <= 0: missing_fields.append('å¹´é½¡')
            if not symptoms: missing_fields.append('ç—‡ç‹€')
            if not language: missing_fields.append('èªè¨€')
            if not location: missing_fields.append('åœ°å€')
            
            error_msg = f'è«‹å¡«å¯«æ‰€æœ‰å¿…è¦è³‡æ–™: {", ".join(missing_fields)}'
            logger.warning(f"Validation failed: {error_msg}")
            return jsonify({'error': error_msg}), 400
        
        # Set session language for diagnosis
        session['language'] = ui_language
        
        # ä½¿ç”¨AIåˆ†æç—‡ç‹€ä¸¦é…å°é†«ç”Ÿ (å‚³élocation_details)
        # Handle backward compatibility - pass empty string if gender is None
        gender_safe = gender or ''
        result = analyze_symptoms_and_match(age, gender_safe, symptoms, chronic_conditions, language, location, detailed_health_info, location_details)
        
        # Log user query to database
        session_id = session.get('session_id', secrets.token_hex(16))
        session['session_id'] = session_id
        
        try:
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO user_queries 
                (age, gender, symptoms, chronic_conditions, language, location, detailed_health_info, 
                 ai_analysis, related_specialty, matched_doctors_count, user_ip, session_id, analysis_report, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (age, gender_safe, symptoms, chronic_conditions, language, location, 
                  json.dumps(detailed_health_info), result['analysis'], 
                  result['recommended_specialty'], len(result['doctors']), 
                  get_real_ip(), session_id, 
                  format_analysis_report_full({
                      'age': age, 'gender': gender_safe, 'symptoms': symptoms, 
                      'chronic_conditions': chronic_conditions, 'language': language, 
                      'location': location, 'ai_analysis': result['analysis'], 
                      'related_specialty': result['recommended_specialty']
                  }, {}), 
                  get_current_time().isoformat()))
            query_id = cursor.lastrowid
            session['last_query_id'] = query_id
            conn.commit()
            conn.close()
            
            # Check for severe symptoms and log if found
            detection_result = detect_severe_symptoms_and_conditions(symptoms, chronic_conditions)
            if detection_result['is_severe']:
                severe_case_id = log_severe_case(
                    query_id, age, gender_safe, symptoms, chronic_conditions,
                    detection_result['severe_symptoms'], detection_result['severe_conditions'],
                    get_real_ip(), session_id
                )
                session['severe_case_id'] = severe_case_id
                
        except Exception as e:
            print(f"Database logging error: {e}")
        
        # Log analytics
        log_analytics('doctor_search', {
            'age': age, 'symptoms': symptoms, 'language': language, 'location': location,
            'doctors_found': len(result['doctors']), 'specialty': result['recommended_specialty']
        }, get_real_ip(), request.user_agent.string, session_id)
        
        return jsonify({
            'success': True,
            'user_summary': result['user_summary'],
            'analysis': result['analysis'],
            'recommended_specialty': result['recommended_specialty'],
            'doctors': result['doctors'],
            'total': len(result['doctors'])
        })
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {error_details}")
        print(f"è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"éŒ¯èª¤è©³æƒ…: {error_details}")
        return jsonify({'error': f'æœå‹™å™¨å…§éƒ¨éŒ¯èª¤: {str(e)}'}), 500

@app.route('/health')
def health_check():
    """å¥åº·æª¢æŸ¥"""
    provider = AI_CONFIG['provider']
    ai_status = 'unknown'
    
    # æ¸¬è©¦AIæœå‹™ç‹€æ…‹
    try:
        test_response = call_ai_api("Hello")
        if "éŒ¯èª¤" not in test_response and "ä¸å¯ç”¨" not in test_response:
            ai_status = 'healthy'
        else:
            ai_status = 'error'
    except:
        ai_status = 'error'
    
    return jsonify({
        'status': 'healthy',
        'doctors_loaded': len(DOCTORS_DATA),
        'ai_provider': provider,
        'ai_status': ai_status,
        'ai_config': {
            'provider': provider,
            'model': AI_CONFIG[provider]['model'] if provider in AI_CONFIG else 'unknown'
        }
    })

@app.route('/ai-config')
def get_ai_config():
    """ç²å–AIé…ç½®ä¿¡æ¯"""
    provider = AI_CONFIG['provider']
    config_info = {
        'current_provider': provider,
        'available_providers': ['ollama', 'openrouter'],
        'current_model': AI_CONFIG[provider]['model'] if provider in AI_CONFIG else 'unknown'
    }
    
    if provider == 'openrouter':
        config_info['api_key_set'] = bool(AI_CONFIG['openrouter']['api_key'])
        config_info['max_tokens'] = AI_CONFIG['openrouter']['max_tokens']
    
    return jsonify(config_info)

# Admin Routes
@app.route('/admin/login', methods=['GET', 'POST'])
def admin_login():
    """Admin login page"""
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        totp_token = request.form.get('totp_token')
        remember_me = request.form.get('remember_me')
        
        print(f"DEBUG - Form data: username='{username}', password='{password}', totp_token='{totp_token}'")
        
        # Handle 2FA verification from session
        if password == 'verified' and totp_token and session.get('pending_2fa_user') == username:
            print(f"DEBUG - Processing 2FA verification for user: {username}")
            user_data = session.get('pending_2fa_user_data')
            print(f"DEBUG - Session user_data: {user_data}")
            if user_data:
                # Get 2FA data
                conn = sqlite3.connect('admin_data.db')
                cursor = conn.cursor()
                cursor.execute('SELECT totp_enabled, totp_secret, backup_codes FROM admin_users WHERE username = ?', (username,))
                totp_data = cursor.fetchone()
                conn.close()
                
                if totp_data and totp_data[0] and totp_data[1]:
                    secret = totp_data[1]
                    backup_codes = json.loads(totp_data[2]) if totp_data[2] else []
                    
                    print(f"DEBUG - Verifying token '{totp_token}' with secret")
                    token_valid = False
                    used_backup = False
                    
                    if verify_totp_token(secret, totp_token):
                        token_valid = True
                        print(f"DEBUG - TOTP token valid")
                    elif totp_token in backup_codes:
                        token_valid = True
                        used_backup = True
                        print(f"DEBUG - Backup code valid")
                        # Remove used backup code
                        backup_codes.remove(totp_token)
                        conn = sqlite3.connect('admin_data.db')
                        cursor = conn.cursor()
                        cursor.execute('UPDATE admin_users SET backup_codes = ? WHERE username = ?', 
                                     (json.dumps(backup_codes), username))
                        conn.commit()
                        conn.close()
                    else:
                        print(f"DEBUG - Token verification failed")
                    
                    if token_valid:
                        # Complete login
                        session.pop('pending_2fa_user', None)
                        session.pop('pending_2fa_user_data', None)
                        session['admin_logged_in'] = True
                        session['admin_username'] = username
                        session['admin_user_id'] = user_data[0]
                        session['admin_role'] = user_data[3]
                        session['admin_permissions'] = json.loads(user_data[4]) if user_data[4] else {}
                        
                        # Load tab permissions for 2FA users
                        conn = sqlite3.connect('admin_data.db')
                        cursor = conn.cursor()
                        cursor.execute('SELECT tab_permissions FROM admin_users WHERE id = ?', (user_data[0],))
                        tab_perms = cursor.fetchone()
                        conn.close()
                        
                        if tab_perms and tab_perms[0]:
                            session['admin_tab_permissions'] = json.loads(tab_perms[0])
                        else:
                            session['admin_tab_permissions'] = {
                                "dashboard": True,
                                "analytics": True,
                                "config": True,
                                "doctors": True,
                                "users": True,
                                "bug_reports": True,
                                "severe_cases": True
                            }
                        
                        # Handle remember me for 2FA
                        if remember_me:
                            session.permanent = True
                            app.permanent_session_lifetime = timedelta(days=30)
                        else:
                            session.permanent = False
                        
                        session.modified = True
                        
                        if used_backup:
                            flash(f'ä½¿ç”¨å‚™ç”¨ä»£ç¢¼ç™»å…¥æˆåŠŸã€‚å‰©é¤˜å‚™ç”¨ä»£ç¢¼: {len(backup_codes)}', 'warning')
                        
                        log_analytics('admin_login', {
                            'username': username, 
                            'role': user_data[3], 
                            '2fa_used': True,
                            'remember_me': bool(remember_me)
                        }, get_real_ip(), request.user_agent.string)
                        flash('ç™»å…¥æˆåŠŸ', 'success')
                        return redirect(url_for('admin_dashboard'))
                    else:
                        session.pop('pending_2fa_user', None)
                        session.pop('pending_2fa_user_data', None)
                        log_analytics('admin_login_2fa_failed', {'username': username}, 
                                     get_real_ip(), request.user_agent.string)
                        flash('é›™é‡èªè­‰ç¢¼éŒ¯èª¤', 'error')
                        return render_template('admin/login-2fa.html', username=username)
            else:
                print(f"DEBUG - No user_data in session, redirecting to login")
                return render_template('admin/login.html')
        
        # Check database first, then fallback to environment variables
        user = get_admin_user(username)
        password_hash = hashlib.sha256(password.encode()).hexdigest()
        
        if user and user[2] == password_hash:
            # Check if 2FA is enabled for this user
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            cursor.execute('SELECT totp_enabled, totp_secret, backup_codes FROM admin_users WHERE username = ?', (username,))
            totp_data = cursor.fetchone()
            conn.close()
            
            if totp_data and totp_data[0]:  # 2FA enabled
                if not totp_token:
                    # First step: password correct, now need 2FA
                    session['pending_2fa_user'] = username
                    session['pending_2fa_user_data'] = user
                    return render_template('admin/login-2fa.html', username=username)
                
                # Verify 2FA token
                secret = totp_data[1]
                backup_codes = json.loads(totp_data[2]) if totp_data[2] else []
                
                token_valid = False
                used_backup = False
                
                # Check TOTP token first
                if verify_totp_token(secret, totp_token):
                    token_valid = True
                # Check backup codes
                elif totp_token in backup_codes:
                    token_valid = True
                    used_backup = True
                    # Remove used backup code
                    backup_codes.remove(totp_token)
                    conn = sqlite3.connect('admin_data.db')
                    cursor = conn.cursor()
                    cursor.execute('UPDATE admin_users SET backup_codes = ? WHERE username = ?', 
                                 (json.dumps(backup_codes), username))
                    conn.commit()
                    conn.close()
                
                if not token_valid:
                    session.pop('pending_2fa_user', None)
                    session.pop('pending_2fa_user_data', None)
                    log_analytics('admin_login_2fa_failed', {'username': username}, 
                                 get_real_ip(), request.user_agent.string)
                    flash('é›™é‡èªè­‰ç¢¼éŒ¯èª¤', 'error')
                    return render_template('admin/login-2fa.html', username=username)
                
                if used_backup:
                    flash(f'ä½¿ç”¨å‚™ç”¨ä»£ç¢¼ç™»å…¥æˆåŠŸã€‚å‰©é¤˜å‚™ç”¨ä»£ç¢¼: {len(backup_codes)}', 'warning')
            
            # Complete login
            session.pop('pending_2fa_user', None)
            session.pop('pending_2fa_user_data', None)
            session['admin_logged_in'] = True
            session['admin_username'] = username
            session['admin_user_id'] = user[0]
            session['admin_role'] = user[3]
            session['admin_permissions'] = json.loads(user[4]) if user[4] else {}
            
            # Load tab permissions (new column)
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            cursor.execute('SELECT tab_permissions FROM admin_users WHERE id = ?', (user[0],))
            tab_perms = cursor.fetchone()
            conn.close()
            
            if tab_perms and tab_perms[0]:
                session['admin_tab_permissions'] = json.loads(tab_perms[0])
            else:
                # Default permissions for all tabs
                session['admin_tab_permissions'] = {
                    "dashboard": True,
                    "analytics": True,
                    "config": True,
                    "doctors": True,
                    "users": True,
                    "bug_reports": True,
                    "severe_cases": True
                }
            
            # Handle remember me functionality
            if remember_me:
                # Set session to be permanent (30 days)
                session.permanent = True
                app.permanent_session_lifetime = timedelta(days=30)
            else:
                # Session expires when browser closes
                session.permanent = False
            
            # Ensure session is saved
            session.modified = True
            
            # Update last login
            try:
                conn = sqlite3.connect('admin_data.db')
                cursor = conn.cursor()
                cursor.execute('UPDATE admin_users SET last_login = CURRENT_TIMESTAMP WHERE id = ?', (user[0],))
                conn.commit()
                conn.close()
            except Exception as e:
                print(f"Error updating last login: {e}")
            
            log_analytics('admin_login', {
                'username': username, 
                'role': user[3], 
                '2fa_used': totp_data and totp_data[0],
                'remember_me': bool(remember_me)
            }, get_real_ip(), request.user_agent.string)
            flash('ç™»å…¥æˆåŠŸ', 'success')
            return redirect(url_for('admin_dashboard'))
            
        elif (username == ADMIN_USERNAME and password_hash == ADMIN_PASSWORD_HASH):
            print(f"DEBUG - Super admin login attempt, username: {username}")
            # Super admin fallback - check 2FA
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            cursor.execute('SELECT totp_enabled, totp_secret, backup_codes FROM admin_users WHERE username = ?', (ADMIN_USERNAME,))
            totp_data = cursor.fetchone()
            conn.close()
            
            print(f"DEBUG - TOTP data: enabled={totp_data[0] if totp_data else None}, secret_exists={bool(totp_data[1]) if totp_data else None}")
            print(f"DEBUG - Full totp_data: {totp_data}")
            
            if totp_data and totp_data[0] and totp_data[1]:  # 2FA enabled AND secret exists
                print(f"DEBUG - 2FA is enabled, token received: '{totp_token}'")
                if not totp_token:
                    # Create fake user data for super admin
                    super_admin_data = (1, ADMIN_USERNAME, ADMIN_PASSWORD_HASH, 'super_admin', '{}', None, None, True, None)
                    session['pending_2fa_user'] = username
                    session['pending_2fa_user_data'] = super_admin_data
                    return render_template('admin/login-2fa.html', username=username)
                
                # Verify 2FA token
                secret = totp_data[1]
                backup_codes = json.loads(totp_data[2]) if totp_data[2] else []
                
                print(f"DEBUG - About to verify token with secret length: {len(secret) if secret else 0}")
                token_valid = False
                used_backup = False
                
                if verify_totp_token(secret, totp_token):
                    token_valid = True
                elif totp_token in backup_codes:
                    token_valid = True
                    used_backup = True
                    backup_codes.remove(totp_token)
                    conn = sqlite3.connect('admin_data.db')
                    cursor = conn.cursor()
                    cursor.execute('UPDATE admin_users SET backup_codes = ? WHERE username = ?', 
                                 (json.dumps(backup_codes), ADMIN_USERNAME))
                    conn.commit()
                    conn.close()
                
                if not token_valid:
                    session.pop('pending_2fa_user', None)
                    log_analytics('admin_login_2fa_failed', {'username': username}, 
                                 get_real_ip(), request.user_agent.string)
                    flash('é›™é‡èªè­‰ç¢¼éŒ¯èª¤', 'error')
                    return render_template('admin/login-2fa.html', username=username)
                
                if used_backup:
                    flash(f'ä½¿ç”¨å‚™ç”¨ä»£ç¢¼ç™»å…¥æˆåŠŸã€‚å‰©é¤˜å‚™ç”¨ä»£ç¢¼: {len(backup_codes)}', 'warning')
            
            # Complete super admin login
            session.pop('pending_2fa_user', None)
            session['admin_logged_in'] = True
            session['admin_username'] = username
            session['admin_role'] = 'super_admin'
            session['admin_permissions'] = {'all': True}
            session['admin_tab_permissions'] = {
                "dashboard": True,
                "analytics": True,
                "config": True,
                "doctors": True,
                "users": True,
                "bug_reports": True,
                "severe_cases": True
            }
            
            # Handle remember me functionality for super admin
            if remember_me:
                session.permanent = True
                app.permanent_session_lifetime = timedelta(days=30)
            else:
                session.permanent = False
            
            # Ensure session is saved
            session.modified = True
            
            log_analytics('admin_login', {
                'username': username, 
                'role': 'super_admin', 
                '2fa_used': totp_data and totp_data[0],
                'remember_me': bool(remember_me)
            }, get_real_ip(), request.user_agent.string)
            flash('ç™»å…¥æˆåŠŸ', 'success')
            return redirect(url_for('admin_dashboard'))
        else:
            log_analytics('admin_login_failed', {'username': username}, 
                         get_real_ip(), request.user_agent.string)
            flash('ç”¨æˆ¶åæˆ–å¯†ç¢¼éŒ¯èª¤', 'error')
    
    return render_template('admin/login.html')

@app.route('/admin/logout')
@require_admin
def admin_logout():
    """Admin logout"""
    log_analytics('admin_logout', {'username': session.get('admin_username')}, 
                 get_real_ip(), request.user_agent.string)
    session.clear()
    flash('å·²æˆåŠŸç™»å‡º', 'success')
    return redirect(url_for('admin_login'))

@app.route('/admin')
@app.route('/admin/dashboard')
@require_admin
def admin_dashboard():
    """Admin dashboard"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get basic stats
        cursor.execute('SELECT COUNT(*) FROM user_queries')
        total_queries = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM doctor_clicks')
        total_clicks = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(DISTINCT user_ip) FROM user_queries')
        unique_users = cursor.fetchone()[0]
        
        # Get recent queries
        cursor.execute('''
            SELECT timestamp, age, symptoms, language, location, related_specialty
            FROM user_queries 
            ORDER BY timestamp DESC 
            LIMIT 10
        ''')
        raw_recent_queries = cursor.fetchall()
        
        # Format timestamps for recent queries
        recent_queries = []
        for query in raw_recent_queries:
            formatted_query = list(query)
            formatted_query[0] = format_timestamp(query[0])  # Format timestamp
            recent_queries.append(tuple(formatted_query))
        
        # Get popular specialties
        cursor.execute('''
            SELECT related_specialty, COUNT(*) as count
            FROM user_queries 
            WHERE related_specialty IS NOT NULL
            GROUP BY related_specialty 
            ORDER BY count DESC 
            LIMIT 5
        ''')
        popular_specialties = cursor.fetchall()
        
        # Get daily stats for the last 7 days
        cursor.execute('''
            SELECT DATE(timestamp) as date, COUNT(*) as queries
            FROM user_queries 
            WHERE timestamp >= date('now', '-7 days')
            GROUP BY DATE(timestamp)
            ORDER BY date
        ''')
        daily_stats = cursor.fetchall()
        
        conn.close()
        
        return render_template('admin/dashboard.html', 
                             total_queries=total_queries,
                             total_clicks=total_clicks,
                             unique_users=unique_users,
                             recent_queries=recent_queries,
                             popular_specialties=popular_specialties,
                             daily_stats=daily_stats)
    except Exception as e:
        print(f"Dashboard error: {e}")
        flash('è¼‰å…¥å„€è¡¨æ¿æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return render_template('admin/dashboard.html')

def get_event_display_info(event_type: str) -> dict:
    """Convert event type to display-friendly name and color"""
    event_mapping = {
        'page_visit': {'name': 'é é¢è¨ªå•', 'color': 'primary'},
        'doctor_search': {'name': 'é†«ç”Ÿæœå°‹', 'color': 'success'},
        'doctor_click': {'name': 'é†«ç”Ÿé»æ“Š', 'color': 'info'},
        'admin_login': {'name': 'ç®¡ç†å“¡ç™»å…¥', 'color': 'info'},
        'admin_logout': {'name': 'ç®¡ç†å“¡ç™»å‡º', 'color': 'secondary'},
        'admin_login_failed': {'name': 'ç™»å…¥å¤±æ•—', 'color': 'danger'},
        'config_update': {'name': 'é…ç½®æ›´æ–°', 'color': 'warning'},
        'password_change': {'name': 'å¯†ç¢¼æ›´æ”¹', 'color': 'info'},
        'admin_user_created': {'name': 'æ–°å¢ç®¡ç†å“¡', 'color': 'success'},
        'database_export': {'name': 'æ•¸æ“šåº«åŒ¯å‡º', 'color': 'primary'},
        'database_import': {'name': 'æ•¸æ“šåº«åŒ¯å…¥', 'color': 'warning'},
        'analytics_export': {'name': 'åˆ†ææ•¸æ“šåŒ¯å‡º', 'color': 'primary'},
        'doctor_update': {'name': 'é†«ç”Ÿè³‡æ–™æ›´æ–°', 'color': 'warning'},
        'doctor_add': {'name': 'æ–°å¢é†«ç”Ÿ', 'color': 'success'},
        'doctor_delete': {'name': 'åˆªé™¤é†«ç”Ÿ', 'color': 'danger'},
        'bug_report_submitted': {'name': 'å•é¡Œå›å ±', 'color': 'danger'}
    }
    return event_mapping.get(event_type, {'name': event_type, 'color': 'secondary'})

@app.route('/admin/analytics')
@tab_permission_required('analytics')
def admin_analytics():
    """Analytics page"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get analytics data with detailed events
        cursor.execute('''
            SELECT event_type, COUNT(*) as count
            FROM analytics 
            GROUP BY event_type 
            ORDER BY count DESC
        ''')
        raw_event_stats = cursor.fetchall()
        
        # Convert to display-friendly format with color info
        event_stats = [(get_event_display_info(event_type), count) 
                      for event_type, count in raw_event_stats]
        
        # Get detailed recent events for expandable view
        cursor.execute('''
            SELECT event_type, data, timestamp, user_ip, user_agent
            FROM analytics 
            ORDER BY timestamp DESC
            LIMIT 100
        ''')
        recent_events = cursor.fetchall()
        
        # Format recent events with display info
        detailed_events = []
        for event_type, data, timestamp, user_ip, user_agent in recent_events:
            event_info = get_event_display_info(event_type)
            try:
                parsed_data = json.loads(data) if data else {}
            except (json.JSONDecodeError, TypeError):
                parsed_data = {}
            
            detailed_events.append({
                'type': event_type,
                'display_name': event_info['name'],
                'color': event_info['color'],
                'data': parsed_data,
                'timestamp': format_timestamp(timestamp),
                'user_ip': user_ip,
                'user_agent': user_agent
            })
        
        # Get user queries with details
        cursor.execute('''
            SELECT id, timestamp, age, gender, symptoms, language, location, 
                   related_specialty, matched_doctors_count, user_ip
            FROM user_queries 
            ORDER BY timestamp DESC 
            LIMIT 50
        ''')
        raw_queries = cursor.fetchall()
        
        # Format timestamps for user queries
        user_queries = []
        for query in raw_queries:
            formatted_query = list(query)
            formatted_query[1] = format_timestamp(query[1])  # Format timestamp
            user_queries.append(tuple(formatted_query))
        
        # Get gender statistics for dashboard
        cursor.execute('''
            SELECT gender, COUNT(*) as count
            FROM user_queries 
            WHERE gender IS NOT NULL AND gender != ''
            GROUP BY gender 
            ORDER BY count DESC
        ''')
        gender_stats = cursor.fetchall()
        
        # Get location statistics for dashboard
        cursor.execute('''
            SELECT location, COUNT(*) as count
            FROM user_queries 
            WHERE location IS NOT NULL AND location != ''
            GROUP BY location 
            ORDER BY count DESC
            LIMIT 10
        ''')
        location_stats = cursor.fetchall()
        
        # Get doctor clicks
        cursor.execute('''
            SELECT dc.timestamp, dc.doctor_name, dc.doctor_specialty, 
                   uq.symptoms, dc.user_ip
            FROM doctor_clicks dc
            LEFT JOIN user_queries uq ON dc.query_id = uq.id
            ORDER BY dc.timestamp DESC 
            LIMIT 50
        ''')
        raw_clicks = cursor.fetchall()
        
        # Format timestamps for doctor clicks
        doctor_clicks = []
        for click in raw_clicks:
            formatted_click = list(click)
            formatted_click[0] = format_timestamp(click[0])  # Format timestamp
            doctor_clicks.append(tuple(formatted_click))
        
        conn.close()
        
        return render_template('admin/analytics.html', 
                             event_stats=event_stats,
                             queries=user_queries,
                             detailed_events=detailed_events,
                             total_queries=len(raw_queries),
                             total_events=sum(count for _, count in raw_event_stats),
                             gender_stats=gender_stats,
                             location_stats=location_stats,
                             doctor_clicks=doctor_clicks)
    except Exception as e:
        print(f"Analytics error: {e}")
        flash('è¼‰å…¥åˆ†ææ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return render_template('admin/analytics.html', 
                             event_stats=[],
                             queries=[],
                             detailed_events=[],
                             total_queries=0,
                             total_events=0,
                             gender_stats=[],
                             location_stats=[],
                             doctor_clicks=[])

@app.route('/admin/severe-cases')
@tab_permission_required('severe_cases')
def admin_severe_cases():
    """Severe cases monitoring page"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get severe cases with user query details
        cursor.execute('''
            SELECT sc.id, sc.age, sc.gender, sc.symptoms, sc.chronic_conditions,
                   sc.severe_symptoms, sc.severe_conditions, sc.user_ip, 
                   sc.timestamp, sc.user_acknowledged, sc.admin_reviewed, sc.admin_notes,
                   uq.ai_analysis, uq.related_specialty, uq.matched_doctors_count
            FROM severe_cases sc
            LEFT JOIN user_queries uq ON sc.user_query_id = uq.id
            ORDER BY sc.timestamp DESC
            LIMIT 100
        ''')
        severe_cases = cursor.fetchall()
        
        # Get statistics
        cursor.execute('SELECT COUNT(*) FROM severe_cases')
        total_cases = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM severe_cases WHERE admin_reviewed = 1')
        reviewed_cases = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM severe_cases WHERE user_acknowledged = 1')
        acknowledged_cases = cursor.fetchone()[0]
        
        # Get recent cases (last 24 hours)
        cursor.execute('''
            SELECT COUNT(*) FROM severe_cases 
            WHERE datetime(timestamp) > datetime('now', '-1 day')
        ''')
        recent_cases = cursor.fetchone()[0]
        
        # Get top severe symptoms
        cursor.execute('''
            SELECT severe_symptoms, COUNT(*) as count
            FROM severe_cases
            WHERE severe_symptoms != '[]'
            GROUP BY severe_symptoms
            ORDER BY count DESC
            LIMIT 10
        ''')
        top_symptoms = cursor.fetchall()
        
        # Get top severe conditions
        cursor.execute('''
            SELECT severe_conditions, COUNT(*) as count
            FROM severe_cases
            WHERE severe_conditions != '[]'
            GROUP BY severe_conditions
            ORDER BY count DESC
            LIMIT 10
        ''')
        top_conditions = cursor.fetchall()
        
        conn.close()
        
        # Process the data for display
        processed_cases = []
        for case in severe_cases:
            try:
                severe_symptoms = json.loads(case[5]) if case[5] else []
                severe_conditions = json.loads(case[6]) if case[6] else []
            except:
                severe_symptoms = []
                severe_conditions = []
            
            processed_cases.append({
                'id': case[0],
                'age': case[1],
                'gender': case[2],
                'symptoms': case[3],
                'chronic_conditions': case[4],
                'severe_symptoms': severe_symptoms,
                'severe_conditions': severe_conditions,
                'user_ip': case[7],
                'timestamp': case[8],
                'user_acknowledged': case[9],
                'admin_reviewed': case[10],
                'admin_notes': case[11],
                'ai_analysis': case[12],
                'related_specialty': case[13],
                'matched_doctors_count': case[14]
            })
        
        stats = {
            'total_cases': total_cases,
            'reviewed_cases': reviewed_cases,
            'acknowledged_cases': acknowledged_cases,
            'recent_cases': recent_cases,
            'review_rate': round((reviewed_cases / total_cases * 100) if total_cases > 0 else 0, 1)
        }
        
        return render_template('admin/severe-cases.html', 
                             severe_cases=processed_cases,
                             stats=stats,
                             top_symptoms=top_symptoms,
                             top_conditions=top_conditions)
                             
    except Exception as e:
        logger.error(f"Severe cases page error: {e}")
        flash('è¼‰å…¥åš´é‡ç—…ä¾‹æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return render_template('admin/severe-cases.html', 
                             severe_cases=[],
                             stats={'total_cases': 0, 'reviewed_cases': 0, 'acknowledged_cases': 0, 'recent_cases': 0, 'review_rate': 0},
                             top_symptoms=[],
                             top_conditions=[])

@app.route('/admin/severe-cases/<int:case_id>/review', methods=['POST'])
@tab_permission_required('severe_cases')
def review_severe_case(case_id):
    """Mark severe case as reviewed and add admin notes"""
    try:
        data = request.get_json()
        admin_notes = data.get('notes', '')
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE severe_cases 
            SET admin_reviewed = 1, admin_notes = ?
            WHERE id = ?
        ''', (admin_notes, case_id))
        
        conn.commit()
        conn.close()
        
        logger.info(f"Severe case {case_id} reviewed by admin with notes: {admin_notes[:100]}...")
        
        return jsonify({'success': True, 'message': 'ç—…ä¾‹å·²æ¨™è¨˜ç‚ºå·²å¯©æ ¸'})
        
    except Exception as e:
        logger.error(f"Error reviewing severe case {case_id}: {e}")
        return jsonify({'success': False, 'error': 'å¯©æ ¸ç—…ä¾‹æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.route('/admin/profile')
@require_admin
def admin_profile():
    """Admin profile/account settings page - accessible to all admin users"""
    return render_template('admin/profile.html')

@app.route('/admin/profile/update', methods=['POST'])
@require_admin
def update_admin_profile():
    """Update admin user profile information"""
    try:
        display_name = request.form.get('display_name', '').strip()
        email = request.form.get('email', '').strip()
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Update profile information
        cursor.execute('''
            UPDATE admin_users 
            SET display_name = ?, email = ?
            WHERE username = ?
        ''', (display_name if display_name else None, 
              email if email else None, 
              session.get('admin_username')))
        
        conn.commit()
        conn.close()
        
        flash('å€‹äººè³‡æ–™å·²æ›´æ–°', 'success')
        
    except Exception as e:
        print(f"Profile update error: {e}")
        flash('æ›´æ–°å€‹äººè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
    
    return redirect(url_for('admin_profile'))

@app.route('/admin/profile/change-password', methods=['POST'])
@require_admin
def change_admin_password():
    """Change admin user password"""
    try:
        current_password = request.form.get('current_password')
        new_password = request.form.get('new_password')
        confirm_password = request.form.get('confirm_password')
        
        if not all([current_password, new_password, confirm_password]):
            flash('è«‹å¡«å¯«æ‰€æœ‰å¯†ç¢¼æ¬„ä½', 'error')
            return redirect(url_for('admin_profile'))
        
        if new_password != confirm_password:
            flash('æ–°å¯†ç¢¼èˆ‡ç¢ºèªå¯†ç¢¼ä¸ç¬¦', 'error')
            return redirect(url_for('admin_profile'))
        
        if len(new_password) < 8:
            flash('å¯†ç¢¼é•·åº¦è‡³å°‘éœ€è¦8å€‹å­—ç¬¦', 'error')
            return redirect(url_for('admin_profile'))
        
        # Verify current password
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('SELECT password_hash FROM admin_users WHERE username = ?', 
                      (session.get('admin_username'),))
        result = cursor.fetchone()
        
        if not result:
            flash('ç”¨æˆ¶ä¸å­˜åœ¨', 'error')
            conn.close()
            return redirect(url_for('admin_profile'))
        
        current_hash = hashlib.sha256(current_password.encode()).hexdigest()
        if current_hash != result[0]:
            flash('ç›®å‰å¯†ç¢¼éŒ¯èª¤', 'error')
            conn.close()
            return redirect(url_for('admin_profile'))
        
        # Update password
        new_hash = hashlib.sha256(new_password.encode()).hexdigest()
        cursor.execute('UPDATE admin_users SET password_hash = ? WHERE username = ?',
                      (new_hash, session.get('admin_username')))
        
        conn.commit()
        conn.close()
        
        flash('å¯†ç¢¼å·²æˆåŠŸä¿®æ”¹', 'success')
        
    except Exception as e:
        logger.error(f"Password change error: {e}")
        flash('å¯†ç¢¼ä¿®æ”¹å¤±æ•—', 'error')
    
    return redirect(url_for('admin_config'))

@app.route('/admin/config')
@require_admin
@tab_permission_required('config')
def admin_config():
    """Admin configuration page"""
    try:
        # Get admin user info
        admin_user = get_admin_user_info()
        if not admin_user:
            flash('ç®¡ç†å“¡è³‡è¨Šç²å–å¤±æ•—', 'error')
            return redirect(url_for('admin_login'))
        
        # Get all admin users for super admin
        all_admin_users = []
        if admin_user.get('is_super_admin'):
            try:
                conn = sqlite3.connect('admin_data.db')
                cursor = conn.cursor()
                cursor.execute("SELECT id, username, role, totp_enabled FROM admin_users ORDER BY username")
                all_admin_users = cursor.fetchall()
                conn.close()
            except Exception as e:
                logger.error(f"Failed to fetch admin users: {e}")
                flash('ç²å–ç®¡ç†å“¡åˆ—è¡¨å¤±æ•—', 'error')
        
        # Get AI configuration (placeholder for now)
        ai_config = {
            'provider': 'openai',
            'openai': {'api_key': '', 'model': 'gpt-4o'},
            'openrouter': {'api_key': '', 'model': 'anthropic/claude-3.5-sonnet'},
            'ollama': {'model': 'llama3.1:8b', 'base_url': 'http://localhost:11434/api/generate'}
        }
        
        # Get timezone configuration (placeholder for now)
        timezone_config = {'timezone': 'Asia/Hong_Kong'}
        
        # Get WhatsApp configuration (placeholder for now)
        whatsapp_config = {
            'target_number': '85294974070',
            'socket_url': 'http://localhost:3000',
            'api_key': ''
        }
        
        # Get 2FA status for super admin
        admin_2fa_status = False
        if admin_user.get('username') == 'admin':
            try:
                conn = sqlite3.connect('admin_data.db')
                cursor = conn.cursor()
                cursor.execute("SELECT totp_enabled FROM admin_users WHERE username = ?", ('admin',))
                result = cursor.fetchone()
                admin_2fa_status = result[0] if result else False
                conn.close()
            except Exception as e:
                logger.error(f"Failed to get 2FA status: {e}")
        
        return render_template('admin/config.html', 
                             admin_user=admin_user,
                             all_admin_users=all_admin_users,
                             ai_config=ai_config,
                             timezone_config=timezone_config,
                             whatsapp_config=whatsapp_config,
                             admin_2fa_status=admin_2fa_status)
    except Exception as e:
        logger.error(f"Admin config error: {e}")
        flash('é…ç½®é é¢è¼‰å…¥å¤±æ•—', 'error')
        return redirect(url_for('admin_dashboard'))

@app.route('/admin/api/console-logs')
@require_admin
def get_console_logs():
    """Get console logs for super admin only"""
    try:
        admin_user = get_admin_user_info()
        if not admin_user or not admin_user.get('is_super_admin'):
            return jsonify({'error': 'Unauthorized - Super admin access required'}), 403
        
        # Get recent logs from buffer
        logs = list(console_log_buffer)
        
        # Format logs for frontend
        formatted_logs = []
        for log in logs[-100:]:  # Get last 100 logs
            formatted_logs.append({
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(log['timestamp'])),
                'level': log['level'],
                'message': log['message'],
                'logger': log['logger']
            })
        
        return jsonify({'logs': formatted_logs})
        
    except Exception as e:
        logger.error(f"Console logs API error: {e}")
        return jsonify({'error': 'Failed to fetch logs'}), 500

@app.route('/admin/api/console-logs/stream')
@require_admin
def stream_console_logs():
    """Stream console logs via Server-Sent Events for super admin only"""
    try:
        admin_user = get_admin_user_info()
        if not admin_user or not admin_user.get('is_super_admin'):
            return jsonify({'error': 'Unauthorized - Super admin access required'}), 403
        
        def generate():
            last_count = len(console_log_buffer)
            while True:
                current_count = len(console_log_buffer)
                if current_count > last_count:
                    # New logs available
                    new_logs = list(console_log_buffer)[last_count:]
                    for log in new_logs:
                        formatted_log = {
                            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(log['timestamp'])),
                            'level': log['level'],
                            'message': log['message'],
                            'logger': log['logger']
                        }
                        yield f"data: {json.dumps(formatted_log)}\n\n"
                    last_count = current_count
                time.sleep(1)  # Check for new logs every second
        
        return Response(generate(), mimetype='text/plain')
        
    except Exception as e:
        logger.error(f"Console logs stream error: {e}")
        return jsonify({'error': 'Failed to stream logs'}), 500

@app.route('/admin/update-timezone', methods=['POST'])
@login_required
def update_timezone_config():
    """Update timezone configuration"""
    try:
        timezone = request.form.get('timezone', 'Asia/Hong_Kong')
        
        # Validate timezone
        try:
            pytz.timezone(timezone)
        except:
            flash('ç„¡æ•ˆçš„æ™‚å€è¨­å®š', 'error')
            return redirect(url_for('admin_config'))
        
        # Update environment variable
        env_path = Path('.env')
        if env_path.exists():
            set_key(env_path, 'APP_TIMEZONE', timezone)
        else:
            with open('.env', 'w') as f:
                f.write(f'APP_TIMEZONE={timezone}\n')
        
        # Update runtime config
        TIMEZONE_CONFIG['timezone'] = timezone
        
        flash(f'æ™‚å€å·²æ›´æ–°ç‚º {timezone}', 'success')
        
    except Exception as e:
        print(f"Timezone update error: {e}")
        flash('æ›´æ–°æ™‚å€è¨­å®šæ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
    
    return redirect(url_for('admin_config'))

@app.route('/admin/api/openai-models')
@require_admin
def get_openai_models_api():
    """API endpoint to fetch OpenAI models"""
    # Get API key from query parameter or use current config
    api_key = request.args.get('api_key')
    models = get_openai_models(api_key)
    return jsonify({'models': models})

@app.route('/admin/api/database-stats')
@require_admin
def get_database_stats():
    """API endpoint to get database statistics"""
    try:
        # Get doctors count from loaded data
        doctors_count = len(DOCTORS_DATA) if DOCTORS_DATA else 0
        
        # Get analytics data from admin_data.db
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get today's queries
        today = get_current_time().strftime('%Y-%m-%d')
        try:
            cursor.execute('SELECT COUNT(*) FROM user_queries WHERE DATE(timestamp) = ?', (today,))
            queries_today = cursor.fetchone()[0]
        except:
            queries_today = 0
        
        # Get total queries
        try:
            cursor.execute('SELECT COUNT(*) FROM user_queries')
            total_queries = cursor.fetchone()[0]
        except:
            total_queries = 0
        
        conn.close()
        
        return jsonify({
            'success': True,
            'stats': {
                'doctors_count': doctors_count,
                'queries_today': queries_today,
                'total_queries': total_queries
            }
        })
    except Exception as e:
        print(f"Database stats error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/admin/api/users')
@require_admin
def get_admin_users_api():
    """API endpoint to get admin users list"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Check if admin_users table exists
        cursor.execute('''
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='admin_users'
        ''')
        
        if not cursor.fetchone():
            conn.close()
            return jsonify({
                'success': True,
                'users': []
            })
        
        # Check if all columns exist
        cursor.execute('PRAGMA table_info(admin_users)')
        columns = [col[1] for col in cursor.fetchall()]
        
        # Build query based on available columns
        base_columns = ['id', 'username', 'role']
        optional_columns = ['email', 'display_name', 'is_active', 'created_at']
        
        select_columns = base_columns.copy()
        for col in optional_columns:
            if col in columns:
                select_columns.append(col)
        
        query = f"SELECT {', '.join(select_columns)} FROM admin_users ORDER BY id DESC"
        cursor.execute(query)
        
        users = []
        for row in cursor.fetchall():
            print(f"DEBUG /admin/api/users - Row: {row}")  # Debug logging
            print(f"DEBUG /admin/api/users - Columns: {select_columns}")  # Debug logging
            
            # Find the correct index for created_at
            created_at_index = select_columns.index('created_at') if 'created_at' in select_columns else -1
            
            user = {
                'id': row[0],
                'username': row[1],
                'role': row[2] if len(row) > 2 else 'admin',
                'email': row[3] if len(row) > 3 and 'email' in select_columns else None,
                'display_name': row[4] if len(row) > 4 and 'display_name' in select_columns else None,
                'is_active': bool(row[5]) if len(row) > 5 and 'is_active' in select_columns else True,
                'created_at': row[created_at_index] if created_at_index != -1 and len(row) > created_at_index else None
            }
            print(f"DEBUG /admin/api/users - User object: {user}")  # Debug logging
            users.append(user)
        
        conn.close()
        
        return jsonify({
            'success': True,
            'users': users
        })
    except Exception as e:
        print(f"Get admin users error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

def update_env_file(key: str, value: str) -> None:
    """Update or add a key-value pair in the .env file."""
    env_path = Path('.env')
    
    # If .env doesn't exist, create it
    if not env_path.exists():
        env_path.touch()
    
    # Read current content
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        logger.error(f"Error reading .env file: {e}")
        return
    
    # Update or add the key
    key_exists = False
    for i, line in enumerate(lines):
        if line.strip().startswith(f'{key}='):
            lines[i] = f"{key}={value}\n"
            key_exists = True
            break
    
    if not key_exists:
        lines.append(f"{key}={value}\n")
    
    # Write back to file
    try:
        with open(env_path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        logger.info(f"Updated {key} in .env file")
    except Exception as e:
        logger.error(f"Error writing to .env file: {e}")

@app.route('/admin/update_ai_config', methods=['POST'])
@require_admin
def update_ai_config():
    try:
        # Update AI_CONFIG based on form data
        provider = request.form.get('provider', 'ollama')
        AI_CONFIG['provider'] = provider
        
        # Update provider-specific config
        if provider == 'openrouter':
            AI_CONFIG['openrouter'].update({
                'api_key': request.form.get('openrouter_api_key', ''),
                'model': request.form.get('openrouter_model', 'anthropic/claude-3.5-sonnet'),
                'max_tokens': int(request.form.get('openrouter_max_tokens', '4000'))
            })
            # Update .env file
            update_env_file('AI_PROVIDER', 'openrouter')
            update_env_file('OPENROUTER_API_KEY', AI_CONFIG['openrouter']['api_key'])
            update_env_file('OPENROUTER_MODEL', AI_CONFIG['openrouter']['model'])
            update_env_file('OPENROUTER_MAX_TOKENS', str(AI_CONFIG['openrouter']['max_tokens']))
            
        elif provider == 'openai':
            AI_CONFIG['openai'].update({
                'api_key': request.form.get('openai_api_key', ''),
                'model': request.form.get('openai_model', 'gpt-4'),
                'max_tokens': int(request.form.get('openai_max_tokens', '4000'))
            })
            # Update .env file
            update_env_file('AI_PROVIDER', 'openai')
            update_env_file('OPENAI_API_KEY', AI_CONFIG['openai']['api_key'])
            
        elif provider == 'ollama':
            AI_CONFIG['ollama'].update({
                'model': request.form.get('ollama_model', 'llama3.1:8b'),
                'base_url': request.form.get('ollama_base_url', 'http://localhost:11434/api/generate')
            })
            # Update .env file
            update_env_file('AI_PROVIDER', 'ollama')
            update_env_file('OLLAMA_MODEL', AI_CONFIG['ollama']['model'])
            update_env_file('OLLAMA_BASE_URL', AI_CONFIG['ollama']['base_url'])
        
        # Save to database
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO system_config (config_key, config_value)
            VALUES ('ai_config', ?)
        ''', (json.dumps(AI_CONFIG),))
        conn.commit()
        conn.close()
        
        # Reload environment variables
        load_dotenv(override=True)
        
        log_analytics('config_update', {'type': 'ai_config', 'provider': provider}, 
                     get_real_ip(), request.user_agent.string)
        
        flash('AIé…ç½®å·²æ›´æ–°', 'success')
    except Exception as e:
        logger.error(f"AI config update error: {e}")
        flash(f'æ›´æ–°AIé…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}', 'error')
    
    return redirect(url_for('admin_config'))

@app.route('/admin/setup-2fa', methods=['GET', 'POST'])
@require_admin
def setup_2fa():
    """Setup 2FA for super admin"""
    if request.method == 'GET':
        # Only allow super admin to setup 2FA
        if session.get('admin_username') != ADMIN_USERNAME:
            flash('åªæœ‰è¶…ç´šç®¡ç†å“¡å¯ä»¥è¨­ç½®é›™é‡èªè­‰', 'error')
            return redirect(url_for('admin_config'))
        
        # Check if 2FA is already enabled
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        cursor.execute('SELECT totp_enabled FROM admin_users WHERE username = ?', (ADMIN_USERNAME,))
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0]:
            flash('é›™é‡èªè­‰å·²å•Ÿç”¨', 'info')
            return redirect(url_for('admin_config'))
        
        # Generate new secret and QR code
        secret = generate_totp_secret()
        qr_code = generate_qr_code(ADMIN_USERNAME, secret)
        
        # Store secret in session temporarily
        session['temp_totp_secret'] = secret
        
        return render_template('admin/setup-2fa.html', 
                             qr_code=qr_code, 
                             secret=secret,
                             username=ADMIN_USERNAME)
    
    elif request.method == 'POST':
        token = request.form.get('token')
        secret = session.get('temp_totp_secret')
        
        if not secret or not token:
            flash('ç„¡æ•ˆçš„è«‹æ±‚', 'error')
            return redirect(url_for('setup_2fa'))
        
        # Verify the token
        if verify_totp_token(secret, token):
            # Generate backup codes
            backup_codes = generate_backup_codes()
            
            # Save to database
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            cursor.execute('''
                UPDATE admin_users 
                SET totp_secret = ?, totp_enabled = 1, backup_codes = ?
                WHERE username = ?
            ''', (secret, json.dumps(backup_codes), ADMIN_USERNAME))
            conn.commit()
            conn.close()
            
            # Clear temp secret
            session.pop('temp_totp_secret', None)
            
            # Log the setup
            log_analytics('2fa_setup', {'username': ADMIN_USERNAME}, 
                         get_real_ip(), request.user_agent.string)
            
            flash('é›™é‡èªè­‰è¨­ç½®æˆåŠŸï¼è«‹ä¿å­˜å‚™ç”¨ä»£ç¢¼', 'success')
            return render_template('admin/2fa-backup-codes.html', 
                                 backup_codes=backup_codes)
        else:
            flash('é©—è­‰ç¢¼éŒ¯èª¤ï¼Œè«‹é‡è©¦', 'error')
            return redirect(url_for('setup_2fa'))

@app.route('/admin/disable-2fa', methods=['POST'])
@require_admin
def disable_2fa():
    """Disable 2FA for super admin"""
    if session.get('admin_username') != ADMIN_USERNAME:
        flash('åªæœ‰è¶…ç´šç®¡ç†å“¡å¯ä»¥åœç”¨é›™é‡èªè­‰', 'error')
        return redirect(url_for('admin_config'))
    
    password = request.form.get('password')
    if not password:
        flash('è«‹è¼¸å…¥å¯†ç¢¼ç¢ºèª', 'error')
        return redirect(url_for('admin_config'))
    
    # Verify password
    password_hash = hashlib.sha256(password.encode()).hexdigest()
    if password_hash != ADMIN_PASSWORD_HASH:
        flash('å¯†ç¢¼éŒ¯èª¤', 'error')
        return redirect(url_for('admin_config'))
    
    # Disable 2FA
    conn = sqlite3.connect('admin_data.db')
    cursor = conn.cursor()
    cursor.execute('''
        UPDATE admin_users 
        SET totp_secret = NULL, totp_enabled = 0, backup_codes = NULL
        WHERE username = ?
    ''', (ADMIN_USERNAME,))
    conn.commit()
    conn.close()
    
    # Log the disable
    log_analytics('2fa_disabled', {'username': ADMIN_USERNAME}, 
                 get_real_ip(), request.user_agent.string)
    
    flash('é›™é‡èªè­‰å·²åœç”¨', 'success')
    return redirect(url_for('admin_config'))

@app.route('/admin/config/password', methods=['POST'])
@require_admin
def change_admin_password_legacy():
    """Change admin password (legacy endpoint)"""
    try:
        current_password = request.form.get('current_password')
        new_password = request.form.get('new_password')
        confirm_password = request.form.get('confirm_password')
        
        if not all([current_password, new_password, confirm_password]):
            flash('è«‹å¡«å¯«æ‰€æœ‰å¯†ç¢¼æ¬„ä½', 'error')
            return redirect(url_for('admin_config'))
        
        if new_password != confirm_password:
            flash('æ–°å¯†ç¢¼èˆ‡ç¢ºèªå¯†ç¢¼ä¸ç¬¦', 'error')
            return redirect(url_for('admin_config'))
        
        if len(new_password) < 6:
            flash('æ–°å¯†ç¢¼é•·åº¦è‡³å°‘6å€‹å­—ç¬¦', 'error')
            return redirect(url_for('admin_config'))
        
        # Verify current password
        current_hash = hashlib.sha256(current_password.encode()).hexdigest()
        user_id = session.get('admin_user_id')
        username = session.get('admin_username')
        
        if user_id:
            # Database user
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            cursor.execute('SELECT password_hash FROM admin_users WHERE id = ?', (user_id,))
            stored_hash = cursor.fetchone()
            
            if not stored_hash or stored_hash[0] != current_hash:
                flash('ç•¶å‰å¯†ç¢¼éŒ¯èª¤', 'error')
                conn.close()
                return redirect(url_for('admin_config'))
            
            # Update password
            new_hash = hashlib.sha256(new_password.encode()).hexdigest()
            cursor.execute('UPDATE admin_users SET password_hash = ? WHERE id = ?', (new_hash, user_id))
            conn.commit()
            conn.close()
        else:
            # Environment user - can't change password
            flash('ç’°å¢ƒè®Šæ•¸ç”¨æˆ¶ç„¡æ³•æ›´æ”¹å¯†ç¢¼', 'error')
            return redirect(url_for('admin_config'))
        
        log_analytics('password_change', {'username': username}, 
                     get_real_ip(), request.user_agent.string)
        flash('å¯†ç¢¼æ›´æ–°æˆåŠŸ', 'success')
        
    except Exception as e:
        print(f"Password change error: {e}")
        flash('æ›´æ”¹å¯†ç¢¼æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
    
    return redirect(url_for('admin_config'))

@app.route('/admin/config/users', methods=['POST'])
@require_permission('user_management')
def create_admin_user():
    """Create new admin user"""
    try:
        username = request.form.get('username')
        password = request.form.get('password')
        role = request.form.get('role', 'admin')
        permissions = request.form.getlist('permissions')
        
        if not all([username, password]):
            flash('è«‹å¡«å¯«ç”¨æˆ¶åå’Œå¯†ç¢¼', 'error')
            return redirect(url_for('admin_config'))
        
        if len(password) < 6:
            flash('å¯†ç¢¼é•·åº¦è‡³å°‘6å€‹å­—ç¬¦', 'error')
            return redirect(url_for('admin_config'))
        
        # Build permissions object
        perm_obj = {}
        for perm in permissions:
            perm_obj[perm] = True
        
        password_hash = hashlib.sha256(password.encode()).hexdigest()
        created_by = session.get('admin_user_id')
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Set default tab permissions for new user
        default_tab_permissions = {
            "dashboard": True,
            "analytics": True,
            "config": True,
            "doctors": True,
            "users": True,
            "bug_reports": True,
            "severe_cases": True
        }
        
        try:
            cursor.execute('''
                INSERT INTO admin_users (username, password_hash, role, permissions, created_by, tab_permissions)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (username, password_hash, role, json.dumps(perm_obj), created_by, json.dumps(default_tab_permissions)))
            conn.commit()
            
            log_analytics('admin_user_created', {
                'username': username, 'role': role, 'created_by': session.get('admin_username')
            }, get_real_ip(), request.user_agent.string)
            
            flash(f'ç®¡ç†å“¡ç”¨æˆ¶ {username} å‰µå»ºæˆåŠŸ', 'success')
        except sqlite3.IntegrityError:
            flash('ç”¨æˆ¶åå·²å­˜åœ¨', 'error')
        
        conn.close()
        
    except Exception as e:
        print(f"User creation error: {e}")
        flash('å‰µå»ºç”¨æˆ¶æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
    
    return redirect(url_for('admin_config'))

@app.route('/admin/api/admin-users')
@require_permission('user_management')
def get_admin_users():
    """Get list of admin users"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, username, role, is_active, created_at, last_login 
            FROM admin_users 
            ORDER BY created_at DESC
        ''')
        
        users = []
        for row in cursor.fetchall():
            users.append({
                'id': row[0],
                'username': row[1],
                'role': row[2],
                'is_active': bool(row[3]),
                'created_at': row[4],
                'last_login': row[5]
            })
        
        conn.close()
        return jsonify({'users': users})
        
    except Exception as e:
        print(f"Error fetching admin users: {e}")
        return jsonify({'error': 'Failed to fetch users'}), 500

@app.route('/admin/api/user-permissions')
@require_admin
def get_user_permissions():
    """Get user tab permissions for management"""
    if session.get('admin_role') != 'super_admin':
        return jsonify({'error': 'Only super admin can manage permissions'}), 403
    
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, username, role, tab_permissions, created_at, is_active
            FROM admin_users 
            ORDER BY username
        ''')
        
        users = []
        for row in cursor.fetchall():
            print(f"DEBUG - Row data: {row}")  # Debug logging
            tab_perms = json.loads(row[3]) if row[3] else {
                "dashboard": True,
                "analytics": True,
                "config": True,
                "doctors": True,
                "users": True,
                "bug_reports": True,
                "severe_cases": True
            }
            
            user_data = {
                'id': row[0],
                'username': row[1],
                'role': row[2],
                'tab_permissions': tab_perms,
                'created_at': row[4],
                'is_active': bool(row[5])
            }
            print(f"DEBUG - User data: {user_data}")  # Debug logging
            users.append(user_data)
        
        conn.close()
        return jsonify({'users': users})
        
    except Exception as e:
        print(f"Error fetching user permissions: {e}")
        return jsonify({'error': 'Failed to fetch permissions'}), 500

@app.route('/admin/api/user-permissions/update', methods=['POST'])
@require_admin
def update_user_permissions():
    """Update user tab permissions"""
    if session.get('admin_role') != 'super_admin':
        return jsonify({'error': 'Only super admin can manage permissions'}), 403
    
    try:
        data = request.get_json()
        user_id = data.get('user_id')
        permission = data.get('permission')
        enabled = data.get('enabled')
        
        if not all([user_id, permission]):
            return jsonify({'error': 'Missing required parameters'}), 400
        
        # Valid permissions
        valid_permissions = ['dashboard', 'analytics', 'config', 'doctors', 'users', 'bug_reports', 'severe_cases']
        if permission not in valid_permissions:
            return jsonify({'error': 'Invalid permission'}), 400
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get current permissions
        cursor.execute('SELECT tab_permissions FROM admin_users WHERE id = ?', (user_id,))
        result = cursor.fetchone()
        
        if not result:
            return jsonify({'error': 'User not found'}), 404
        
        current_perms = json.loads(result[0]) if result[0] else {}
        current_perms[permission] = enabled
        
        # Update permissions
        cursor.execute('''
            UPDATE admin_users 
            SET tab_permissions = ? 
            WHERE id = ?
        ''', (json.dumps(current_perms), user_id))
        
        conn.commit()
        conn.close()
        
        # Log the permission change
        log_analytics('admin_permission_update', {
            'target_user_id': user_id,
            'permission': permission,
            'enabled': enabled,
            'updated_by': session.get('admin_username')
        }, get_real_ip(), request.user_agent.string)
        
        return jsonify({'success': True, 'message': 'Permission updated successfully'})
        
    except Exception as e:
        print(f"Error updating user permissions: {e}")
        return jsonify({'error': 'Failed to update permissions'}), 500

@app.route('/admin/api/specialties')
@require_admin
def get_specialties_api():
    """Get available medical specialties for admin interface"""
    try:
        specialties = get_available_specialties()
        return jsonify({'specialties': specialties})
    except Exception as e:
        print(f"Error fetching specialties: {e}")
        return jsonify({'error': 'Failed to fetch specialties'}), 500

@app.route('/admin/config/users/<int:user_id>/toggle', methods=['POST'])
@require_permission('user_management')
def toggle_admin_user(user_id):
    """Toggle admin user active status"""
    try:
        if user_id == session.get('admin_user_id'):
            return jsonify({'success': False, 'error': 'ä¸èƒ½åœç”¨è‡ªå·±çš„å¸³æˆ¶'}), 400
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get current status first
        cursor.execute('SELECT is_active FROM admin_users WHERE id = ?', (user_id,))
        result = cursor.fetchone()
        if not result:
            return jsonify({'success': False, 'error': 'ç”¨æˆ¶ä¸å­˜åœ¨'}), 404
        
        current_status = result[0]
        new_status = 0 if current_status else 1
        
        cursor.execute('UPDATE admin_users SET is_active = ? WHERE id = ?', (new_status, user_id))
        conn.commit()
        conn.close()
        
        action = 'å•Ÿç”¨' if new_status else 'åœç”¨'
        return jsonify({'success': True, 'message': f'ç”¨æˆ¶å·²{action}'})
        
    except Exception as e:
        print(f"Error toggling user: {e}")
        return jsonify({'success': False, 'error': 'æ›´æ–°ç”¨æˆ¶ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.route('/admin/config/users/<int:user_id>/delete', methods=['DELETE'])
@require_permission('user_management')
def delete_admin_user(user_id):
    """Delete admin user permanently"""
    try:
        if user_id == session.get('admin_user_id'):
            return jsonify({'success': False, 'error': 'ä¸èƒ½åˆªé™¤è‡ªå·±çš„å¸³æˆ¶'}), 400
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Check if user exists and get username for logging
        cursor.execute('SELECT username FROM admin_users WHERE id = ?', (user_id,))
        result = cursor.fetchone()
        if not result:
            return jsonify({'success': False, 'error': 'ç”¨æˆ¶ä¸å­˜åœ¨'}), 404
        
        username = result[0]
        
        # Delete the user
        cursor.execute('DELETE FROM admin_users WHERE id = ?', (user_id,))
        
        if cursor.rowcount == 0:
            return jsonify({'success': False, 'error': 'åˆªé™¤å¤±æ•—'}), 500
        
        conn.commit()
        conn.close()
        
        # Log the deletion
        log_analytics('admin_user_delete', {
            'deleted_user_id': user_id,
            'deleted_username': username,
            'deleted_by': session.get('admin_username')
        }, get_real_ip(), request.user_agent.string)
        
        return jsonify({'success': True, 'message': f'ç”¨æˆ¶ {username} å·²åˆªé™¤'})
        
    except Exception as e:
        print(f"Error deleting user: {e}")
        return jsonify({'success': False, 'error': 'åˆªé™¤ç”¨æˆ¶æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.route('/admin/database/export-doctors')
@require_permission('config')
def export_doctors_database():
    """Export doctors database as CSV"""
    try:
        import io
        from flask import make_response
        
        # Create CSV content
        output = io.StringIO()
        if DOCTORS_DATA:
            # Get all column names from the first doctor record
            fieldnames = list(DOCTORS_DATA[0].keys())
            
            # Write header
            output.write(','.join(f'"{field}"' for field in fieldnames) + '\n')
            
            # Write data rows
            for doctor in DOCTORS_DATA:
                row = []
                for field in fieldnames:
                    value = doctor.get(field, '')
                    # Escape quotes and handle None values
                    if value is None:
                        value = ''
                    value = str(value).replace('"', '""')
                    row.append(f'"{value}"')
                output.write(','.join(row) + '\n')
        
        # Create response with UTF-8 BOM for better Excel compatibility
        csv_content = '\ufeff' + output.getvalue()  # Add UTF-8 BOM
        response = make_response(csv_content.encode('utf-8'))
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename=doctors_database_{get_current_time().strftime("%Y%m%d_%H%M%S")}.csv'
        
        log_analytics('database_export', {'type': 'doctors', 'count': len(DOCTORS_DATA)}, 
                     get_real_ip(), request.user_agent.string)
        
        return response
        
    except Exception as e:
        print(f"Export error: {e}")
        flash('å°å‡ºé†«ç”Ÿæ•¸æ“šåº«æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return redirect(url_for('admin_config'))

@app.route('/admin/database/import-doctors', methods=['POST'])
@require_permission('config')
def import_doctors_database():
    """Import doctors database from CSV"""
    try:
        if 'doctors_file' not in request.files:
            flash('è«‹é¸æ“‡è¦ä¸Šå‚³çš„CSVæ–‡ä»¶', 'error')
            return redirect(url_for('admin_config'))
        
        file = request.files['doctors_file']
        if file.filename == '':
            flash('è«‹é¸æ“‡è¦ä¸Šå‚³çš„CSVæ–‡ä»¶', 'error')
            return redirect(url_for('admin_config'))
        
        if not file.filename.lower().endswith('.csv'):
            flash('è«‹ä¸Šå‚³CSVæ ¼å¼çš„æ–‡ä»¶', 'error')
            return redirect(url_for('admin_config'))
        
        # Read and parse CSV
        import io
        import csv
        
        # Read file content
        file_content = file.read().decode('utf-8-sig')  # Handle BOM
        csv_reader = csv.DictReader(io.StringIO(file_content))
        
        new_doctors_data = []
        row_count = 0
        error_rows = []
        
        for row_num, row in enumerate(csv_reader, start=2):  # Start from 2 (after header)
            row_count += 1
            try:
                # Clean and validate row data
                cleaned_row = {}
                for key, value in row.items():
                    if key:  # Skip empty column names
                        cleaned_row[key.strip()] = value.strip() if value else ''
                
                # Basic validation - ensure we have essential fields
                if not cleaned_row.get('name', '').strip():
                    error_rows.append(f"ç¬¬{row_num}è¡Œ: ç¼ºå°‘é†«ç”Ÿå§“å")
                    continue
                
                new_doctors_data.append(cleaned_row)
                
            except Exception as e:
                error_rows.append(f"ç¬¬{row_num}è¡Œ: æ•¸æ“šæ ¼å¼éŒ¯èª¤ - {str(e)}")
        
        if error_rows:
            error_msg = "å°å…¥éç¨‹ä¸­ç™¼ç¾éŒ¯èª¤:\n" + "\n".join(error_rows[:10])  # Show first 10 errors
            if len(error_rows) > 10:
                error_msg += f"\n... é‚„æœ‰ {len(error_rows) - 10} å€‹éŒ¯èª¤"
            flash(error_msg, 'error')
            return redirect(url_for('admin_config'))
        
        if not new_doctors_data:
            flash('CSVæ–‡ä»¶ä¸­æ²’æœ‰æœ‰æ•ˆçš„é†«ç”Ÿæ•¸æ“š', 'error')
            return redirect(url_for('admin_config'))
        
        # Backup current data
        backup_action = request.form.get('backup_action', 'replace')
        
        if backup_action == 'replace':
            # Replace all data
            global DOCTORS_DATA
            DOCTORS_DATA = new_doctors_data
            flash(f'æˆåŠŸå°å…¥ {len(new_doctors_data)} ä½é†«ç”Ÿæ•¸æ“šï¼ˆå·²æ›¿æ›åŸæœ‰æ•¸æ“šï¼‰', 'success')
        elif backup_action == 'append':
            # Append to existing data
            DOCTORS_DATA.extend(new_doctors_data)
            flash(f'æˆåŠŸè¿½åŠ  {len(new_doctors_data)} ä½é†«ç”Ÿæ•¸æ“šï¼ˆç¸½è¨ˆ {len(DOCTORS_DATA)} ä½ï¼‰', 'success')
        
        # Save to file (optional - update the CSV file)
        try:
            csv_path = os.path.join('assets', 'finddoc_doctors_detailed 2.csv')
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as csvfile:
                if DOCTORS_DATA:
                    fieldnames = list(DOCTORS_DATA[0].keys())
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(DOCTORS_DATA)
        except Exception as e:
            print(f"Warning: Could not save to CSV file: {e}")
        
        log_analytics('database_import', {
            'type': 'doctors', 
            'imported_count': len(new_doctors_data),
            'total_count': len(DOCTORS_DATA),
            'action': backup_action
        }, get_real_ip(), request.user_agent.string)
        
    except Exception as e:
        print(f"Import error: {e}")
        flash(f'å°å…¥é†«ç”Ÿæ•¸æ“šåº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}', 'error')
    
    return redirect(url_for('admin_config'))

@app.route('/admin/database/stats')
@require_admin
def get_database_stats_page():
    """Get database statistics"""
    try:
        stats = {
            'doctors_count': len(DOCTORS_DATA) if DOCTORS_DATA else 0,
            'doctors_fields': list(DOCTORS_DATA[0].keys()) if DOCTORS_DATA else [],
            'sample_doctor': DOCTORS_DATA[0] if DOCTORS_DATA else None,
            'user_queries_count': 0,
            'doctor_clicks_count': 0,
            'analytics_events_count': 0,
            'admin_users_count': 0
        }
        
        # Get analytics data count with table existence checks
        try:
            conn = sqlite3.connect('admin_data.db')
            cursor = conn.cursor()
            
            # Check if tables exist before querying
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            existing_tables = [row[0] for row in cursor.fetchall()]
            
            if 'user_queries' in existing_tables:
                cursor.execute('SELECT COUNT(*) FROM user_queries')
                stats['user_queries_count'] = cursor.fetchone()[0]
            
            if 'doctor_clicks' in existing_tables:
                cursor.execute('SELECT COUNT(*) FROM doctor_clicks')
                stats['doctor_clicks_count'] = cursor.fetchone()[0]
            
            if 'analytics' in existing_tables:
                cursor.execute('SELECT COUNT(*) FROM analytics')
                stats['analytics_events_count'] = cursor.fetchone()[0]
            
            if 'admin_users' in existing_tables:
                cursor.execute('SELECT COUNT(*) FROM admin_users')
                stats['admin_users_count'] = cursor.fetchone()[0]
            
            conn.close()
            
        except Exception as db_error:
            print(f"=== DATABASE QUERY ERROR IN STATS ===")
            print(f"Error: {db_error}")
            print(f"Error type: {type(db_error).__name__}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            # Try to reinitialize database
            try:
                print("=== ATTEMPTING DATABASE REINITIALIZATION ===")
                init_db()
                print("=== DATABASE REINITIALIZED AFTER ERROR ===")
            except Exception as init_error:
                print(f"=== FAILED TO REINITIALIZE DATABASE ===")
                print(f"Init error: {init_error}")
        
        return jsonify(stats)
        
    except Exception as e:
        print(f"Database stats error: {e}")
        return jsonify({
            'doctors_count': len(DOCTORS_DATA) if DOCTORS_DATA else 0,
            'user_queries_count': 0,
            'doctor_clicks_count': 0,
            'analytics_events_count': 0,
            'admin_users_count': 0,
            'error': 'Database temporarily unavailable'
        }), 200

@app.route('/admin/database/export-analytics', methods=['GET', 'POST'])
@require_permission('analytics')
def export_analytics_database():
    """Export analytics data as CSV with selective options"""
    try:
        import io
        from flask import make_response
        
        # Get form data for selective export
        export_types = request.form.getlist('export_types') if request.method == 'POST' else ['analytics', 'queries', 'clicks']
        date_range = request.form.get('date_range', 'all') if request.method == 'POST' else 'all'
        start_date = request.form.get('start_date') if request.method == 'POST' else None
        end_date = request.form.get('end_date') if request.method == 'POST' else None
        
        # Build date filter condition
        date_filter = ""
        date_params = []
        
        if date_range == 'today':
            date_filter = "WHERE DATE(timestamp) = DATE('now')"
        elif date_range == 'week':
            date_filter = "WHERE timestamp >= datetime('now', '-7 days')"
        elif date_range == 'month':
            date_filter = "WHERE timestamp >= datetime('now', '-30 days')"
        elif date_range == 'custom' and start_date and end_date:
            date_filter = "WHERE DATE(timestamp) BETWEEN ? AND ?"
            date_params = [start_date, end_date]
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Initialize data containers
        analytics_data = []
        user_queries_data = []
        doctor_clicks_data = []
        
        # Get analytics data if requested
        if 'analytics' in export_types:
            query = f'''
                SELECT 
                    a.timestamp,
                    a.event_type,
                    a.user_ip,
                    a.user_agent,
                    a.data,
                    a.session_id
                FROM analytics a
                {date_filter}
                ORDER BY a.timestamp DESC
            '''
            cursor.execute(query, date_params)
            analytics_data = cursor.fetchall()
        
        # Get user queries data if requested
        if 'queries' in export_types:
            query = f'''
                SELECT 
                    uq.timestamp,
                    uq.age,
                    uq.symptoms,
                    uq.chronic_conditions,
                    uq.language,
                    uq.location,
                    uq.detailed_health_info,
                    uq.ai_analysis,
                    uq.related_specialty,
                    uq.matched_doctors_count,
                    uq.user_ip,
                    uq.session_id
                FROM user_queries uq
                {date_filter}
                ORDER BY uq.timestamp DESC
            '''
            cursor.execute(query, date_params)
            user_queries_data = cursor.fetchall()
        
        # Get doctor clicks data if requested
        if 'clicks' in export_types:
            query = f'''
                SELECT 
                    dc.timestamp,
                    dc.doctor_name,
                    dc.doctor_specialty,
                    dc.user_ip,
                    dc.session_id,
                    dc.query_id
                FROM doctor_clicks dc
                {date_filter}
                ORDER BY dc.timestamp DESC
            '''
            cursor.execute(query, date_params)
            doctor_clicks_data = cursor.fetchall()
        
        conn.close()
        
        # Create CSV content
        output = io.StringIO()
        
        # Export analytics events if requested
        if 'analytics' in export_types and analytics_data:
            output.write("=== ANALYTICS EVENTS ===\n")
            output.write("Timestamp,Event Type,User IP,User Agent,Data,Session ID\n")
            for row in analytics_data:
                escaped_row = []
                for field in row:
                    if field is None:
                        field = ''
                    field_str = str(field).replace('"', '""')
                    escaped_row.append(f'"{field_str}"')
                output.write(','.join(escaped_row) + '\n')
            output.write("\n")
        
        # Export user queries if requested
        if 'queries' in export_types and user_queries_data:
            output.write("=== USER QUERIES ===\n")
            output.write("Timestamp,Age,Symptoms,Chronic Conditions,Language,Location,Detailed Health Info,AI Diagnosis,Recommended Specialty,Matched Doctors Count,User IP,Session ID\n")
            for row in user_queries_data:
                escaped_row = []
                for field in row:
                    if field is None:
                        field = ''
                    field_str = str(field).replace('"', '""')
                    escaped_row.append(f'"{field_str}"')
                output.write(','.join(escaped_row) + '\n')
            output.write("\n")
        
        # Export doctor clicks if requested
        if 'clicks' in export_types and doctor_clicks_data:
            output.write("=== DOCTOR CLICKS ===\n")
            output.write("Timestamp,Doctor Name,Doctor Specialty,User IP,Session ID,Query ID\n")
            for row in doctor_clicks_data:
                escaped_row = []
                for field in row:
                    if field is None:
                        field = ''
                    field_str = str(field).replace('"', '""')
                    escaped_row.append(f'"{field_str}"')
                output.write(','.join(escaped_row) + '\n')
        
        # Check if any data was exported
        if not output.getvalue().strip():
            flash('æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ•¸æ“š', 'warning')
            return redirect(url_for('admin_analytics'))
        
        # Create filename with export details
        filename_parts = []
        if 'analytics' in export_types:
            filename_parts.append('events')
        if 'queries' in export_types:
            filename_parts.append('queries')
        if 'clicks' in export_types:
            filename_parts.append('clicks')
        
        filename = f"analytics_{'_'.join(filename_parts)}_{date_range}_{get_current_time().strftime('%Y%m%d_%H%M%S')}.csv"
        
        # Create response with UTF-8 BOM for better Excel compatibility
        csv_content = '\ufeff' + output.getvalue()  # Add UTF-8 BOM
        response = make_response(csv_content.encode('utf-8'))
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename={filename}'
        
        log_analytics('analytics_export', {
            'export_types': export_types,
            'date_range': date_range,
            'analytics_count': len(analytics_data),
            'queries_count': len(user_queries_data),
            'clicks_count': len(doctor_clicks_data)
        }, get_real_ip(), request.user_agent.string)
        
        return response
        
    except Exception as e:
        print(f"Analytics export error: {e}")
        flash('å°å‡ºåˆ†ææ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return redirect(url_for('admin_analytics'))

@app.route('/admin/doctors')
@tab_permission_required('doctors')
def admin_doctors():
    """é†«ç”Ÿè³‡æ–™åº«ç®¡ç†é é¢"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # ç²å–çµ±è¨ˆè³‡æ–™
        cursor.execute("SELECT COUNT(*) FROM doctors")
        total_doctors = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT COALESCE(specialty_zh, specialty_en, specialty)) FROM doctors WHERE COALESCE(specialty_zh, specialty_en, specialty) IS NOT NULL")
        total_specialties = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM doctors WHERE (languages_zh LIKE '%ä¸­æ–‡%' OR languages_zh LIKE '%English%' OR languages_en LIKE '%ä¸­æ–‡%' OR languages_en LIKE '%English%')")
        bilingual_doctors = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM doctors WHERE contact_numbers IS NOT NULL AND contact_numbers != ''")
        with_contact = cursor.fetchone()[0]
        
        # ç²å–æ‰€æœ‰å°ˆç§‘åˆ—è¡¨
        cursor.execute("SELECT DISTINCT COALESCE(specialty_zh, specialty_en, specialty) as specialty FROM doctors WHERE specialty IS NOT NULL ORDER BY specialty")
        specialties = [row[0] for row in cursor.fetchall() if row[0]]
        
        conn.close()
        
        return render_template('admin/doctors.html',
                             doctors=[],  # Empty list - will load via AJAX
                             total_doctors=total_doctors,
                             total_specialties=total_specialties,
                             bilingual_doctors=bilingual_doctors,
                             with_contact=with_contact,
                             specialties=specialties)
                             
    except Exception as e:
        print(f"Error in admin_doctors: {e}")
        flash('è¼‰å…¥é†«ç”Ÿè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return redirect(url_for('admin_dashboard'))

@app.route('/admin/doctors/paginated')
@tab_permission_required('doctors')
def admin_doctors_paginated():
    """DataTables AJAX endpoint for paginated doctor data"""
    try:
        # Get DataTables parameters
        draw = request.args.get('draw', type=int, default=1)
        start = request.args.get('start', type=int, default=0)
        length = request.args.get('length', type=int, default=25)
        search_value = request.args.get('search[value]', default='')
        
        # Get sorting parameters
        order_column = request.args.get('order[0][column]', type=int, default=0)
        order_dir = request.args.get('order[0][dir]', default='asc')
        
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # Column mapping for sorting
        columns = ['name', 'specialty', 'qualifications', 'contact_numbers', 'clinic_addresses', 'priority_flag']
        sort_column = columns[order_column] if order_column < len(columns) else 'name'
        
        # Base query
        base_query = """
            SELECT id, 
                   COALESCE(name_zh, name_en, name) as name,
                   COALESCE(specialty_zh, specialty_en, specialty) as specialty,
                   COALESCE(qualifications_zh, qualifications_en, qualifications) as qualifications,
                   contact_numbers,
                   clinic_addresses,
                   priority_flag
            FROM doctors
        """
        
        # Add search filter if provided
        where_clause = ""
        params = []
        if search_value:
            where_clause = """
                WHERE (COALESCE(name_zh, name_en, name) LIKE ? 
                   OR COALESCE(specialty_zh, specialty_en, specialty) LIKE ?
                   OR contact_numbers LIKE ?
                   OR clinic_addresses LIKE ?)
            """
            search_param = f'%{search_value}%'
            params = [search_param, search_param, search_param, search_param]
        
        # Get total count (without search)
        cursor.execute("SELECT COUNT(*) FROM doctors")
        records_total = cursor.fetchone()[0]
        
        # Get filtered count (with search)
        if search_value:
            cursor.execute(f"SELECT COUNT(*) FROM doctors {where_clause}", params)
            records_filtered = cursor.fetchone()[0]
        else:
            records_filtered = records_total
        
        # Get paginated data with sorting
        order_clause = f"ORDER BY {sort_column} {order_dir.upper()}"
        query = f"{base_query} {where_clause} {order_clause} LIMIT ? OFFSET ?"
        params.extend([length, start])
        
        cursor.execute(query, params)
        columns = [description[0] for description in cursor.description]
        
        data = []
        for row in cursor.fetchall():
            doctor_dict = dict(zip(columns, row))
            data.append(doctor_dict)
        
        conn.close()
        
        return jsonify({
            'draw': draw,
            'recordsTotal': records_total,
            'recordsFiltered': records_filtered,
            'data': data
        })
        
    except Exception as e:
        print(f"Error in admin_doctors_paginated: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/admin/doctors/<int:doctor_id>', methods=['GET'])
@require_permission('config')
def get_doctor_details(doctor_id):
    """ç²å–é†«ç”Ÿè©³ç´°è³‡æ–™ (AJAX)"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM doctors WHERE id = ?", (doctor_id,))
        row = cursor.fetchone()
        
        if row:
            columns = [description[0] for description in cursor.description]
            doctor_data = dict(zip(columns, row))
            conn.close()
            return jsonify(doctor_data)
        else:
            conn.close()
            return jsonify({'error': 'Doctor not found'}), 404
            
    except Exception as e:
        print(f"Error getting doctor details: {e}")
        return jsonify({'error': 'Database error'}), 500

@app.route('/admin/specialties')
@require_permission('config')
def get_specialties():
    """Get all unique specialties from database"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # Get unique Chinese specialties
        cursor.execute('''
            SELECT DISTINCT specialty_zh 
            FROM doctors 
            WHERE specialty_zh IS NOT NULL AND specialty_zh != ''
            ORDER BY specialty_zh
        ''')
        chinese_specialties = [row[0] for row in cursor.fetchall()]
        
        # Get unique English specialties
        cursor.execute('''
            SELECT DISTINCT specialty_en 
            FROM doctors 
            WHERE specialty_en IS NOT NULL AND specialty_en != ''
            ORDER BY specialty_en
        ''')
        english_specialties = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        
        return jsonify({
            'chinese': chinese_specialties,
            'english': english_specialties
        })
    except Exception as e:
        print(f"Error fetching specialties: {e}")
        return jsonify({'error': 'Failed to fetch specialties'}), 500

@app.route('/admin/doctors/data')
@require_permission('config')
def get_doctors_data():
    """Get all doctors data for specialty mapping"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT specialty_zh, specialty_en 
            FROM doctors 
            WHERE specialty_zh IS NOT NULL AND specialty_en IS NOT NULL 
            AND specialty_zh != '' AND specialty_en != ''
        ''')
        
        doctors = []
        for row in cursor.fetchall():
            doctors.append({
                'specialty_zh': row[0],
                'specialty_en': row[1]
            })
        
        conn.close()
        return jsonify(doctors)
        
    except Exception as e:
        print(f"Error fetching doctors data: {e}")
        return jsonify({'error': 'Failed to fetch doctors data'}), 500

@app.route('/admin/doctors/<int:doctor_id>/update', methods=['POST'])
@require_permission('config')
def update_doctor(doctor_id):
    """æ›´æ–°é†«ç”Ÿè³‡æ–™"""
    try:
        data = request.get_json()
        
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # Update doctor record
        cursor.execute('''
            UPDATE doctors SET
                name_zh = ?, specialty_zh = ?, qualifications_zh = ?, languages_zh = ?,
                name_en = ?, specialty_en = ?, qualifications_en = ?, languages_en = ?,
                contact_numbers = ?, email = ?, clinic_addresses = ?,
                consultation_hours = ?, consultation_fee = ?, profile_url = ?,
                registration_number = ?, priority_flag = ?,
                name = ?, specialty = ?, qualifications = ?, languages = ?,
                phone = ?, address = ?
            WHERE id = ?
        ''', (
            data.get('name_zh'), data.get('specialty_zh'), data.get('qualifications_zh'), data.get('languages_zh'),
            data.get('name_en'), data.get('specialty_en'), data.get('qualifications_en'), data.get('languages_en'),
            data.get('contact_numbers'), data.get('email'), data.get('clinic_addresses'),
            data.get('consultation_hours'), data.get('consultation_fee'), data.get('profile_url'),
            data.get('registration_number'), data.get('priority_flag', 0),
            # Legacy columns - use Chinese first, then English
            data.get('name_zh') or data.get('name_en'),
            data.get('specialty_zh') or data.get('specialty_en'),
            data.get('qualifications_zh') or data.get('qualifications_en'),
            data.get('languages_zh') or data.get('languages_en'),
            data.get('contact_numbers'),
            data.get('clinic_addresses'),
            doctor_id
        ))
        
        if cursor.rowcount == 0:
            conn.close()
            return jsonify({'success': False, 'error': 'Doctor not found'}), 404
        
        conn.commit()
        conn.close()
        
        # Log the update
        log_analytics('doctor_update', {
            'doctor_id': doctor_id,
            'updated_fields': list(data.keys())
        }, get_real_ip(), request.user_agent.string)
        
        return jsonify({'success': True, 'message': 'Doctor updated successfully'})
        
    except Exception as e:
        print(f"Error updating doctor: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/admin/doctors/add', methods=['POST'])
@require_permission('config')
def add_doctor():
    """æ–°å¢é†«ç”Ÿ"""
    try:
        data = request.get_json()
        
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # Insert new doctor record
        cursor.execute('''
            INSERT INTO doctors (
                name_zh, specialty_zh, qualifications_zh, languages_zh,
                name_en, specialty_en, qualifications_en, languages_en,
                contact_numbers, email, clinic_addresses,
                consultation_hours, consultation_fee, profile_url,
                registration_number, priority_flag,
                name, specialty, qualifications, languages,
                phone, address
            ) VALUES (
                ?, ?, ?, ?,
                ?, ?, ?, ?,
                ?, ?, ?,
                ?, ?, ?,
                ?, ?,
                ?, ?, ?, ?,
                ?, ?
            )
        ''', (
            data.get('name_zh'), data.get('specialty_zh'), data.get('qualifications_zh'), data.get('languages_zh'),
            data.get('name_en'), data.get('specialty_en'), data.get('qualifications_en'), data.get('languages_en'),
            data.get('contact_numbers'), data.get('email'), data.get('clinic_addresses'),
            data.get('consultation_hours'), data.get('consultation_fee'), data.get('profile_url'),
            data.get('registration_number'), data.get('priority_flag', 0),
            # Legacy columns - use Chinese first, then English
            data.get('name_zh') or data.get('name_en'),
            data.get('specialty_zh') or data.get('specialty_en'),
            data.get('qualifications_zh') or data.get('qualifications_en'),
            data.get('languages_zh') or data.get('languages_en'),
            data.get('contact_numbers'),
            data.get('clinic_addresses')
        ))
        
        new_doctor_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        # Log the addition
        log_analytics('doctor_add', {
            'doctor_id': new_doctor_id,
            'name': data.get('name_zh') or data.get('name_en')
        }, get_real_ip(), request.user_agent.string)
        
        return jsonify({'success': True, 'message': 'Doctor added successfully', 'doctor_id': new_doctor_id})
        
    except Exception as e:
        print(f"Error adding doctor: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/admin/doctors/<int:doctor_id>/delete', methods=['DELETE'])
@require_permission('config')
def delete_doctor(doctor_id):
    """åˆªé™¤é†«ç”Ÿ"""
    try:
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        
        # Get doctor info for logging
        cursor.execute("SELECT name_zh, name_en FROM doctors WHERE id = ?", (doctor_id,))
        doctor = cursor.fetchone()
        
        if not doctor:
            conn.close()
            return jsonify({'success': False, 'error': 'Doctor not found'}), 404
        
        # Delete doctor record
        cursor.execute("DELETE FROM doctors WHERE id = ?", (doctor_id,))
        
        if cursor.rowcount == 0:
            conn.close()
            return jsonify({'success': False, 'error': 'Doctor not found'}), 404
        
        conn.commit()
        conn.close()
        
        # Log the deletion
        log_analytics('doctor_delete', {
            'doctor_id': doctor_id,
            'name': doctor[0] or doctor[1]
        }, get_real_ip(), request.user_agent.string)
        
        return jsonify({'success': True, 'message': 'Doctor deleted successfully'})
        
    except Exception as e:
        print(f"Error deleting doctor: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/admin/users')
@tab_permission_required('users')
def admin_users():
    """User management page"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get user statistics
        cursor.execute('''
            SELECT user_ip, COUNT(*) as query_count, 
                   MIN(timestamp) as first_visit,
                   MAX(timestamp) as last_visit
            FROM user_queries 
            GROUP BY user_ip 
            ORDER BY query_count DESC
        ''')
        user_stats = cursor.fetchall()
        
        conn.close()
        
        return render_template('admin/users.html', user_stats=user_stats)
    except Exception as e:
        print(f"Users page error: {e}")
        flash('è¼‰å…¥ç”¨æˆ¶æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return render_template('admin/users.html')

@app.route('/admin/api/user-details/<user_ip>')
@require_admin
def get_user_details(user_ip):
    """API endpoint to get detailed user information"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get user query statistics
        cursor.execute('''
            SELECT COUNT(*) as total_queries,
                   COUNT(DISTINCT DATE(timestamp)) as active_days,
                   GROUP_CONCAT(DISTINCT recommended_specialty) as specialties
            FROM user_queries 
            WHERE user_ip = ?
        ''', (user_ip,))
        stats = cursor.fetchone()
        
        # Get most common specialty
        cursor.execute('''
            SELECT recommended_specialty, COUNT(*) as count
            FROM user_queries 
            WHERE user_ip = ? AND recommended_specialty IS NOT NULL
            GROUP BY recommended_specialty 
            ORDER BY count DESC 
            LIMIT 1
        ''', (user_ip,))
        top_specialty = cursor.fetchone()
        
        # Get recent queries
        cursor.execute('''
            SELECT timestamp, symptoms, recommended_specialty
            FROM user_queries 
            WHERE user_ip = ?
            ORDER BY timestamp DESC 
            LIMIT 5
        ''', (user_ip,))
        raw_recent_queries = cursor.fetchall()
        
        # Format timestamps for recent queries
        recent_queries = []
        for query in raw_recent_queries:
            formatted_query = list(query)
            formatted_query[0] = format_timestamp(query[0])  # Format timestamp
            recent_queries.append(tuple(formatted_query))
        
        conn.close()
        
        return jsonify({
            'total_queries': stats[0] if stats else 0,
            'active_days': stats[1] if stats else 0,
            'top_specialty': top_specialty[0] if top_specialty else 'ç„¡',
            'recent_queries': [
                {
                    'timestamp': query[0],
                    'symptoms': query[1][:50] + '...' if len(query[1]) > 50 else query[1],
                    'specialty': query[2]
                } for query in recent_queries
            ]
        })
    except Exception as e:
        print(f"User details error: {e}")
        return jsonify({'error': 'Failed to fetch user details'}), 500

@app.route('/admin/api/user-reports/<user_ip>')
@require_admin
def get_user_reports(user_ip):
    """API endpoint to get user diagnosis reports"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Get all user queries with diagnosis reports
        cursor.execute('''
            SELECT id, timestamp, age, gender, symptoms, chronic_conditions, 
                   related_specialty, ai_analysis, language, location, 
                   analysis_report
            FROM user_queries 
            WHERE user_ip = ?
            ORDER BY timestamp DESC
        ''', (user_ip,))
        queries = cursor.fetchall()
        
        conn.close()
        
        reports = []
        for query in queries:
            reports.append({
                'id': query[0],
                'timestamp': query[1],
                'age': query[2],
                'gender': query[3],
                'symptoms': query[4],
                'chronic_conditions': query[5],
                'specialty': query[6],
                'emergency_level': 'Yes' if check_emergency_needed(query[7]) else 'No',  # Use emergency detection instead of severity
                'language': query[8],
                'location': query[9],
                'analysis_report': query[10]
            })
        
        return jsonify({
            'reports': reports
        })
    except Exception as e:
        print(f"User reports error: {e}")
        return jsonify({'error': 'Failed to fetch user reports'}), 500

@app.route('/report/<report_id>')
def view_report(report_id):
    """Display diagnosis report"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT report_data, created_at, doctor_name, doctor_specialty 
            FROM analysis_reports 
            WHERE id = ?
        ''', (report_id,))
        
        report_row = cursor.fetchone()
        conn.close()
        
        if not report_row:
            return "å ±å‘Šæœªæ‰¾åˆ°", 404
            
        report_data, created_at, doctor_name, doctor_specialty = report_row
        
        # Convert newlines to HTML breaks for display
        report_html = report_data.replace('\n', '<br>')
        
        return f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>AIé†«ç™‚è¨ºæ–·å ±å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.6; }}
                .report {{ background: #f9f9f9; padding: 20px; border-radius: 10px; white-space: pre-line; }}
                .header {{ text-align: center; color: #2c3e50; margin-bottom: 20px; }}
                .footer {{ text-align: center; margin-top: 20px; color: #7f8c8d; font-size: 0.9em; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ¥ AIç—‡ç‹€åˆ†æå ±å‘Š</h1>
            </div>
            <div class="report">
                {report_html}
            </div>
            <div class="footer">
                <p>æ­¤å ±å‘Šç”Ÿæˆæ–¼: {created_at}</p>
                <p><small>å…è²¬è²æ˜ï¼šæ­¤åˆ†æåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆé†«ç™‚å»ºè­°æˆ–è¨ºæ–·ï¼Œè«‹å‹™å¿…è«®è©¢åˆæ ¼é†«ç”Ÿã€‚</small></p>
            </div>
        </body>
        </html>
        """
        
    except Exception as e:
        print(f"Report display error: {e}")
        return "å ±å‘Šé¡¯ç¤ºéŒ¯èª¤", 500

@app.route('/get_whatsapp_url', methods=['POST'])
def get_whatsapp_url():
    """Generate WhatsApp URL with diagnosis report"""
    try:
        data = request.get_json()
        doctor_name = data.get('doctor_name')
        doctor_specialty = data.get('doctor_specialty')
        
        # Get session info
        session_id = session.get('session_id')
        query_id = session.get('last_query_id')
        
        # Your designated WhatsApp number (replace with your actual number)
        whatsapp_number = os.getenv('WHATSAPP_TARGET_NUMBER', '85294974070')
        
        # Log to database
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO doctor_clicks (doctor_name, doctor_specialty, user_ip, session_id, query_id)
            VALUES (?, ?, ?, ?, ?)
        ''', (doctor_name, doctor_specialty, get_real_ip(), session_id, query_id))
        conn.commit()
        
        # Get user query data for diagnosis report
        whatsapp_url = f"https://wa.me/{whatsapp_number}"
        
        if query_id:
            cursor.execute('''
                SELECT age, gender, symptoms, chronic_conditions, language, location, 
                       detailed_health_info, ai_analysis, related_specialty
                FROM user_queries WHERE id = ?
            ''', (query_id,))
            user_query_row = cursor.fetchone()
            
            if user_query_row:
                user_query_data = {
                    'age': user_query_row[0],
                    'gender': user_query_row[1],
                    'symptoms': user_query_row[2],
                    'chronic_conditions': user_query_row[3],
                    'language': user_query_row[4],
                    'location': user_query_row[5],
                    'detailed_health_info': user_query_row[6],
                    'ai_analysis': user_query_row[7],
                    'related_specialty': user_query_row[8]
                }
                
                doctor_data = {
                    'doctor_name': doctor_name,
                    'doctor_specialty': doctor_specialty
                }
                
                # Generate unique report ID and store report
                import uuid
                report_id = str(uuid.uuid4())
                
                # Store the full diagnosis report in database
                try:
                    cursor.execute('''
                        INSERT OR REPLACE INTO analysis_reports (id, query_id, doctor_name, doctor_specialty, report_data, created_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (report_id, query_id, doctor_name, doctor_specialty, 
                         format_analysis_report_full(user_query_data, doctor_data), 
                         get_current_time().isoformat()))
                except sqlite3.OperationalError as e:
                    print(f"Database error: {e}")
                    # Create table if it doesn't exist
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS analysis_reports (
                            id TEXT PRIMARY KEY, 
                            query_id INTEGER, 
                            doctor_name TEXT, 
                            doctor_specialty TEXT, 
                            report_data TEXT, 
                            created_at TEXT
                        )
                    ''')
                    cursor.execute('''
                        INSERT OR REPLACE INTO analysis_reports (id, query_id, doctor_name, doctor_specialty, report_data, created_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (report_id, query_id, doctor_name, doctor_specialty, 
                         format_analysis_report_full(user_query_data, doctor_data), 
                         get_current_time().isoformat()))
                conn.commit()
                
                # Generate report URL
                report_url = f"{request.scheme}://{request.host}/report/{report_id}"
                
                # Generate WhatsApp message with report link
                message = format_whatsapp_message(doctor_data, report_url)
                print(f"DEBUG: Generated message length: {len(message)}")
                
                # URL encode the message for WhatsApp web - use quote instead of quote_plus for better emoji handling
                from urllib.parse import quote
                encoded_message = quote(message, safe='')
                whatsapp_url = f"https://wa.me/{whatsapp_number}?text={encoded_message}"
                print(f"DEBUG: Final URL length: {len(whatsapp_url)}")
        
        conn.close()
        
        # Log analytics
        log_analytics('doctor_click', {
            'doctor_name': doctor_name, 'doctor_specialty': doctor_specialty
        }, get_real_ip(), request.user_agent.string, session_id)
        
        return jsonify({'success': True, 'whatsapp_url': whatsapp_url})
    except Exception as e:
        print(f"WhatsApp URL generation error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'Failed to generate WhatsApp URL: {str(e)}'}), 500

def track_click():
    """Legacy endpoint - now redirects to get_whatsapp_url"""
    return get_whatsapp_url()

@app.route('/admin/api/whatsapp-status')
@login_required
def get_whatsapp_status():
    """Get WhatsApp service status"""
    try:
        enabled = WHATSAPP_CONFIG['enabled']
        connected = False
        
        if enabled and whatsapp_client:
            try:
                # Test connection by checking if client is ready
                connected = True  # Assume connected if client exists
            except:
                connected = False
        
        return jsonify({
            'enabled': enabled,
            'connected': connected,
            'target_number': WHATSAPP_CONFIG['target_number'] if enabled else None
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/admin/api/system-health')
@login_required
def get_system_health():
    """Get current system health status"""
    try:
        # Get latest health check results
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Create health_checks table if it doesn't exist
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS health_checks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                check_type TEXT NOT NULL,
                status TEXT NOT NULL,
                details TEXT,
                error_message TEXT,
                response_time_ms INTEGER
            )
        ''')
        
        # Get latest health check for each component
        health_data = {}
        for component in ['ai_diagnosis', 'database', 'whatsapp']:
            cursor.execute('''
                SELECT status, timestamp, error_message, response_time_ms, details
                FROM health_checks 
                WHERE check_type = ? 
                ORDER BY timestamp DESC 
                LIMIT 1
            ''', (component,))
            
            result = cursor.fetchone()
            if result:
                health_data[component] = {
                    'status': result[0],
                    'last_check': result[1],
                    'error': result[2],
                    'response_time_ms': result[3],
                    'details': json.loads(result[4]) if result[4] else None
                }
            else:
                health_data[component] = SYSTEM_HEALTH_STATUS.get(component, {
                    'status': 'unknown',
                    'last_check': None,
                    'error': None
                })
        
        # Get health check history (last 7 days)
        cursor.execute('''
            SELECT check_type, status, timestamp, response_time_ms
            FROM health_checks 
            WHERE timestamp >= datetime('now', '-7 days')
            ORDER BY timestamp DESC
        ''')
        
        history = []
        for row in cursor.fetchall():
            history.append({
                'component': row[0],
                'status': row[1],
                'timestamp': row[2],
                'response_time_ms': row[3]
            })
        
        conn.close()
        
        return jsonify({
            'current_status': health_data,
            'history': history,
            'last_updated': get_current_time().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error getting system health: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/admin/api/run-health-check', methods=['POST'])
@require_admin
def manual_health_check():
    """Manually trigger health check"""
    try:
        results = run_daily_health_check()
        return jsonify({
            'success': True,
            'results': results,
            'timestamp': get_current_time().isoformat()
        })
    except Exception as e:
        logger.error(f"Manual health check failed: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/admin/bug-reports')
@tab_permission_required('bug_reports')
def admin_bug_reports():
    """Bug reports management page"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Create bug_reports table if it doesn't exist
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS bug_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                description TEXT NOT NULL,
                contact_info TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                url TEXT,
                user_agent TEXT,
                status TEXT DEFAULT 'new',
                image_path TEXT
            )
        ''')
        
        # Add image_path column if it doesn't exist (for existing tables)
        try:
            cursor.execute('ALTER TABLE bug_reports ADD COLUMN image_path TEXT')
        except sqlite3.OperationalError:
            # Column already exists
            pass
        
        # Get all bug reports
        cursor.execute('''
            SELECT id, description, contact_info, timestamp, url, user_agent, status, image_path
            FROM bug_reports 
            ORDER BY timestamp DESC
        ''')
        bug_reports = cursor.fetchall()
        
        # Convert to list of dicts for easier template handling
        reports = []
        for report in bug_reports:
            reports.append({
                'id': report[0],
                'description': report[1],
                'contact_info': report[2],
                'timestamp': report[3],
                'url': report[4],
                'user_agent': report[5],
                'status': report[6],
                'image_path': report[7] if len(report) > 7 else None
            })
        
        # Get stats
        cursor.execute('''
            SELECT status, COUNT(*) 
            FROM bug_reports 
            GROUP BY status
        ''')
        status_counts = dict(cursor.fetchall())
        
        cursor.execute('SELECT COUNT(*) FROM bug_reports')
        total_count = cursor.fetchone()[0]
        
        stats = {
            'new': status_counts.get('new', 0),
            'in_progress': status_counts.get('in-progress', 0),
            'resolved': status_counts.get('resolved', 0),
            'total': total_count
        }
        
        conn.close()
        
        return render_template('admin/bug-reports.html', 
                             bug_reports=reports, 
                             stats=stats)
        
    except Exception as e:
        logger.error(f"Error loading bug reports: {e}")
        flash('è¼‰å…¥å•é¡Œå›å ±æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error')
        return redirect(url_for('admin_dashboard'))

@app.route('/admin/api/bug-reports/<int:report_id>/status', methods=['POST'])
@require_admin
def update_bug_report_status(report_id):
    """Update bug report status"""
    try:
        data = request.get_json()
        new_status = data.get('status')
        
        if new_status not in ['new', 'in-progress', 'resolved']:
            return jsonify({'error': 'ç„¡æ•ˆçš„ç‹€æ…‹'}), 400
        
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE bug_reports 
            SET status = ? 
            WHERE id = ?
        ''', (new_status, report_id))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True, 'message': 'ç‹€æ…‹å·²æ›´æ–°'})
        
    except Exception as e:
        logger.error(f"Error updating bug report status: {e}")
        return jsonify({'error': 'æ›´æ–°ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.route('/admin/api/bug-reports/<int:report_id>', methods=['DELETE'])
@require_admin
def delete_bug_report(report_id):
    """Delete bug report"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        cursor.execute('DELETE FROM bug_reports WHERE id = ?', (report_id,))
        conn.commit()
        conn.close()
        
        return jsonify({'success': True, 'message': 'å•é¡Œå›å ±å·²åˆªé™¤'})
        
    except Exception as e:
        logger.error(f"Error deleting bug report: {e}")
        return jsonify({'error': 'åˆªé™¤å•é¡Œå›å ±æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.route('/admin/api/whatsapp-test', methods=['POST'])
@login_required
def test_whatsapp_connection():
    """Test WhatsApp connection with provided config"""
    try:
        data = request.get_json()
        socket_url = data.get('socket_url', 'http://localhost:8086')
        target_number = data.get('target_number')
        api_key = data.get('api_key', '')
        session_name = data.get('session_name', 'default')
        
        if not target_number:
            return jsonify({'success': False, 'error': 'ç›®æ¨™è™Ÿç¢¼ä¸èƒ½ç‚ºç©º'})
        
        # Test message
        test_message = "ğŸ”§ WhatsAppé€£æ¥æ¸¬è©¦\n\né€™æ˜¯ä¸€æ¢æ¸¬è©¦æ¶ˆæ¯ï¼Œç”¨æ–¼é©—è­‰WhatsAppé€šçŸ¥é…ç½®ã€‚\n\nå¦‚æœæ‚¨æ”¶åˆ°æ­¤æ¶ˆæ¯ï¼Œè¡¨ç¤ºé…ç½®æ­£ç¢ºï¼"
        
        # Try to send test message
        try:
            if not WHATSAPP_AVAILABLE:
                return jsonify({'success': False, 'error': 'WhatsAppå®¢æˆ¶ç«¯ä¸å¯ç”¨ï¼špython-socketioæœªå®‰è£'})
            
            test_client = socketio.SimpleClient()
            test_client.connect(socket_url)
            test_client.emit('sendText', {
                'to': target_number,
                'content': test_message
            })
            test_client.disconnect()
            return jsonify({'success': True, 'message': 'æ¸¬è©¦æ¶ˆæ¯å·²ç™¼é€'})
        except Exception as e:
            return jsonify({'success': False, 'error': f'é€£æ¥å¤±æ•—: {str(e)}'})
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/update_whatsapp_config', methods=['POST'])
@login_required
def update_whatsapp_config():
    """Update WhatsApp configuration"""
    try:
        global WHATSAPP_CONFIG, whatsapp_client
        
        # Get form data
        enabled = request.form.get('whatsapp_enabled') == 'true'
        target_number = request.form.get('target_number', '').strip()
        socket_url = request.form.get('socket_url', 'http://localhost:8086').strip()
        api_key = request.form.get('api_key', '').strip()
        session_name = request.form.get('session_name', 'default').strip()
        
        # Validate required fields if enabled
        if enabled and not target_number:
            flash('å•Ÿç”¨WhatsAppé€šçŸ¥æ™‚ï¼Œç›®æ¨™è™Ÿç¢¼ä¸èƒ½ç‚ºç©º', 'error')
            return redirect(url_for('admin_config'))
        
        # Update configuration
        WHATSAPP_CONFIG.update({
            'enabled': enabled,
            'target_number': target_number,
            'socket_url': socket_url,
            'api_key': api_key,
            'session_name': session_name
        })
        
        # Update .env file
        update_env_file('WHATSAPP_ENABLED', 'true' if enabled else 'false')
        update_env_file('WHATSAPP_TARGET_NUMBER', target_number)
        update_env_file('WHATSAPP_SOCKET_URL', socket_url)
        update_env_file('WHATSAPP_API_KEY', api_key)
        update_env_file('WHATSAPP_SESSION_NAME', session_name)
        
        # Save to database
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Update or insert WhatsApp config
        cursor.execute('''
            INSERT OR REPLACE INTO admin_config (key, value) 
            VALUES (?, ?)
        ''', ('whatsapp_config', json.dumps(WHATSAPP_CONFIG)))
        
        conn.commit()
        conn.close()
        
        # Reload environment variables
        load_dotenv(override=True)
        
        # Reinitialize WhatsApp client if enabled
        if enabled:
            init_whatsapp_client()
            flash('WhatsAppé…ç½®å·²æ›´æ–°ä¸¦é‡æ–°åˆå§‹åŒ–', 'success')
        else:
            whatsapp_client = None
            flash('WhatsAppé€šçŸ¥å·²åœç”¨', 'success')
        
        return redirect(url_for('admin_config'))
        
    except Exception as e:
        logger.error(f"WhatsApp config update error: {e}")
        flash(f'æ›´æ–°WhatsAppé…ç½®å¤±æ•—: {str(e)}', 'error')
        return redirect(url_for('admin_config'))

def cleanup_old_analysis_reports():
    """Clean up analysis reports older than 30 days"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Calculate cutoff date (30 days ago)
        cutoff_date = datetime.now() - timedelta(days=30)
        cutoff_timestamp = cutoff_date.strftime('%Y-%m-%d %H:%M:%S')
        
        # Delete old analysis reports
        cursor.execute("""
            DELETE FROM analysis_reports 
            WHERE created_at < ?
        """, (cutoff_timestamp,))
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        logger.info(f"Cleaned up {deleted_count} diagnosis reports older than 30 days")
        return deleted_count
        
    except Exception as e:
        logger.error(f"Error during diagnosis reports cleanup: {str(e)}")
        return 0

@app.route('/submit-bug-report', methods=['POST'])
def submit_bug_report():
    """Handle bug report submissions and send to WhatsApp"""
    try:
        # Handle both JSON and form data
        if request.content_type and 'multipart/form-data' in request.content_type:
            description = request.form.get('description', '').strip()
            contact_info = request.form.get('contact_info', '').strip()
            url = request.form.get('url', '')
            user_agent = request.form.get('user_agent', '')
            image_file = request.files.get('image')
        elif request.content_type and 'application/json' in request.content_type:
            data = request.get_json()
            description = data.get('description', '').strip()
            contact_info = data.get('contact_info', '').strip()
            url = data.get('url', '')
            user_agent = data.get('user_agent', '')
            image_file = None
        else:
            # Fallback for other content types
            try:
                data = request.get_json(force=True)
                description = data.get('description', '').strip()
                contact_info = data.get('contact_info', '').strip()
                url = data.get('url', '')
                user_agent = data.get('user_agent', '')
                image_file = None
            except:
                description = request.form.get('description', '').strip()
                contact_info = request.form.get('contact_info', '').strip()
                url = request.form.get('url', '')
                user_agent = request.form.get('user_agent', '')
                image_file = request.files.get('image')
        
        if not description:
            return jsonify({'error': 'å•é¡Œæè¿°ä¸èƒ½ç‚ºç©º'}), 400
        
        # Handle image upload
        image_path = None
        if image_file and image_file.filename:
            import os
            from werkzeug.utils import secure_filename
            import time
            
            # Create uploads directory if it doesn't exist
            upload_dir = os.path.join('static', 'uploads')
            if not os.path.exists(upload_dir):
                os.makedirs(upload_dir)
            
            # Generate secure filename
            filename = secure_filename(image_file.filename)
            timestamp = str(int(time.time()))
            filename = f"{timestamp}_{filename}"
            
            # Save file
            file_path = os.path.join(upload_dir, filename)
            image_file.save(file_path)
            image_path = f"uploads/{filename}"

        # Format bug report message
        bug_message = f"""ğŸ› **ç³»çµ±å•é¡Œå›å ±**

ğŸ“ **å•é¡Œæè¿°:**
{description}

ğŸ“ **è¯çµ¡æ–¹å¼:** {contact_info}
ğŸ• **å›å ±æ™‚é–“:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸŒ **é é¢:** {url}
ğŸ’» **ç€è¦½å™¨:** {user_agent[:100]}...

---
æ­¤å•é¡Œç”± Doctor AI ç³»çµ±è‡ªå‹•è½‰ç™¼"""

        # Send to WhatsApp if enabled
        if WHATSAPP_CONFIG['enabled'] and whatsapp_client:
            try:
                # Send to the configured notification number
                target_number = WHATSAPP_CONFIG.get('target_number', '')
                if target_number:
                    whatsapp_client.emit('send_message', {
                        'to': target_number,
                        'message': bug_message
                    })
                    logger.info(f"Bug report sent to WhatsApp: {target_number}")
                else:
                    logger.warning("No WhatsApp target number configured for bug reports")
            except Exception as whatsapp_error:
                logger.error(f"Failed to send bug report to WhatsApp: {whatsapp_error}")
        
        # Connect to database
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Create bug_reports table if it doesn't exist
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS bug_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                description TEXT NOT NULL,
                contact_info TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                url TEXT,
                user_agent TEXT,
                status TEXT DEFAULT 'new',
                image_path TEXT
            )
        ''')
        
        # Insert bug report
        cursor.execute('''
            INSERT INTO bug_reports (description, contact_info, url, user_agent, image_path)
            VALUES (?, ?, ?, ?, ?)
        ''', (description, contact_info, url, user_agent, image_path))
        
        report_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        # Log to analytics
        log_analytics('bug_report_submitted', {
            'report_id': report_id,
            'has_image': image_path is not None,
            'has_contact': bool(contact_info),
            'description_length': len(description)
        }, get_real_ip(), request.user_agent.string)
        
        # Send to WhatsApp
        try:
            if whatsapp_client and whatsapp_client.connected:
                target_number = WHATSAPP_CONFIG.get('notification_number')
                if target_number:
                    bug_message = f"ğŸ› æ–°å•é¡Œå›å ± #{report_id}\n\næè¿°: {description}\n"
                    if contact_info:
                        bug_message += f"è¯çµ¡æ–¹å¼: {contact_info}\n"
                    if url:
                        bug_message += f"é é¢: {url}\n"
                    if image_path:
                        bug_message += f"é™„ä»¶: å·²ä¸Šå‚³åœ–ç‰‡\n"
                    bug_message += f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                    
                    whatsapp_client.emit('send_message', {
                        'to': target_number,
                        'message': bug_message
                    })
                    logger.info(f"Bug report sent to WhatsApp: {target_number}")
                else:
                    logger.warning("No WhatsApp target number configured for bug reports")
        except Exception as whatsapp_error:
            logger.error(f"Failed to send bug report to WhatsApp: {whatsapp_error}")
        
        return jsonify({'success': True, 'message': 'å•é¡Œå›å ±å·²æˆåŠŸæäº¤'})
        
    except Exception as e:
        logger.error(f"Error processing bug report: {e}")
        return jsonify({'error': 'è™•ç†å•é¡Œå›å ±æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

# Global variable to store system health status
SYSTEM_HEALTH_STATUS = {
    'ai_diagnosis': {'status': 'unknown', 'last_check': None, 'error': None},
    'database': {'status': 'unknown', 'last_check': None, 'error': None},
    'whatsapp': {'status': 'unknown', 'last_check': None, 'error': None}
}

def log_health_check(check_type: str, status: str, details: dict = None, error: str = None):
    """Log health check results to separate health check table"""
    try:
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        
        # Create health_checks table if it doesn't exist
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS health_checks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                check_type TEXT NOT NULL,
                status TEXT NOT NULL,
                details TEXT,
                error_message TEXT,
                response_time_ms INTEGER
            )
        ''')
        
        # Insert health check record
        cursor.execute('''
            INSERT INTO health_checks (check_type, status, details, error_message, response_time_ms)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            check_type, 
            status, 
            json.dumps(details) if details else None,
            error,
            details.get('response_time_ms') if details else None
        ))
        
        conn.commit()
        conn.close()
        
        # Update global status
        SYSTEM_HEALTH_STATUS[check_type] = {
            'status': status,
            'last_check': get_current_time().isoformat(),
            'error': error
        }
        
        logger.info(f"Health check logged: {check_type} = {status}")
        
    except Exception as e:
        logger.error(f"Failed to log health check: {e}")

def test_ai_diagnosis():
    """Test AI diagnosis system with multiple test cases"""
    start_time = time.time()
    
    # Test cases with different symptom combinations
    test_cases = [
        {
            'symptoms': 'é ­ç—›ã€ç™¼ç‡’ã€å’³å—½ä¸‰å¤©',
            'age': 30,
            'gender': 'ç”·',
            'chronic_conditions': '',
            'language': 'zh-TW'
        },
        {
            'symptoms': 'èƒƒç—›ã€å™å¿ƒã€è…¹ç€‰å…©å¤©',
            'age': 25,
            'gender': 'å¥³',
            'chronic_conditions': '',
            'language': 'zh-TW'
        },
        {
            'symptoms': 'èƒ¸ç—›ã€å‘¼å¸å›°é›£ã€å¿ƒè·³åŠ é€Ÿ',
            'age': 45,
            'gender': 'ç”·',
            'chronic_conditions': 'é«˜è¡€å£“',
            'language': 'zh-TW'
        }
    ]
    
    try:
        logger.info("Starting AI diagnosis health check with multiple test cases...")
        
        successful_tests = 0
        total_tests = len(test_cases)
        all_results = []
        
        for i, test_case in enumerate(test_cases, 1):
            case_start_time = time.time()
            
            logger.info(f"Running test case {i}/{total_tests}: {test_case['symptoms']}")
            
            try:
                # Call the AI diagnosis function
                diagnosis_result = analyze_symptoms(
                    age=test_case['age'],
                    gender=test_case['gender'],
                    symptoms=test_case['symptoms'],
                    chronic_conditions=test_case['chronic_conditions'],
                    detailed_health_info={},
                    user_language=test_case['language']
                )
                
                case_response_time = int((time.time() - case_start_time) * 1000)
                
                # Validate the response
                if (diagnosis_result and 
                    'diagnosis' in diagnosis_result and 
                    'recommended_specialty' in diagnosis_result and
                    len(diagnosis_result['diagnosis']) > 10):
                    
                    successful_tests += 1
                    all_results.append({
                        'case': i,
                        'symptoms': test_case['symptoms'],
                        'success': True,
                        'response_time_ms': case_response_time,
                        'specialty': diagnosis_result['recommended_specialty'],
                        'diagnosis_length': len(diagnosis_result['diagnosis'])
                    })
                    
                    logger.info(f"Test case {i} PASSED ({case_response_time}ms)")
                    
                else:
                    all_results.append({
                        'case': i,
                        'symptoms': test_case['symptoms'],
                        'success': False,
                        'response_time_ms': case_response_time,
                        'error': 'Invalid or incomplete response'
                    })
                    
                    logger.warning(f"Test case {i} FAILED: Invalid response")
                    
            except Exception as case_error:
                case_response_time = int((time.time() - case_start_time) * 1000)
                all_results.append({
                    'case': i,
                    'symptoms': test_case['symptoms'],
                    'success': False,
                    'response_time_ms': case_response_time,
                    'error': str(case_error)
                })
                
                logger.error(f"Test case {i} ERROR: {str(case_error)}")
        
        total_response_time_ms = int((time.time() - start_time) * 1000)
        success_rate = (successful_tests / total_tests) * 100
        
        # Consider health check successful if at least 2 out of 3 tests pass (66% success rate)
        is_healthy = successful_tests >= 2
        
        log_health_check('ai_diagnosis', 'healthy' if is_healthy else 'unhealthy', {
            'total_tests': total_tests,
            'successful_tests': successful_tests,
            'success_rate': success_rate,
            'response_time_ms': total_response_time_ms,
            'test_results': all_results
        }, None if is_healthy else f"Only {successful_tests}/{total_tests} tests passed")
        
        if is_healthy:
            logger.info(f"AI diagnosis health check PASSED: {successful_tests}/{total_tests} tests successful ({total_response_time_ms}ms)")
        else:
            logger.error(f"AI diagnosis health check FAILED: Only {successful_tests}/{total_tests} tests passed")
        
        return is_healthy
            
    except Exception as e:
        total_response_time_ms = int((time.time() - start_time) * 1000)
        error_msg = f"AI diagnosis health check failed: {str(e)}"
        
        log_health_check('ai_diagnosis', 'unhealthy', {
            'total_tests': len(test_cases),
            'successful_tests': 0,
            'response_time_ms': total_response_time_ms
        }, error_msg)
        
        logger.error(f"AI diagnosis health check ERROR: {error_msg}")
        return False

def test_database_connectivity():
    """Test database connectivity and basic operations"""
    start_time = time.time()
    
    try:
        # Test admin database
        conn = sqlite3.connect('admin_data.db')
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM admin_users')
        admin_count = cursor.fetchone()[0]
        conn.close()
        
        # Test doctors database
        conn = sqlite3.connect('doctors.db')
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM doctors')
        doctors_count = cursor.fetchone()[0]
        conn.close()
        
        response_time_ms = int((time.time() - start_time) * 1000)
        
        log_health_check('database', 'healthy', {
            'admin_users_count': admin_count,
            'doctors_count': doctors_count,
            'response_time_ms': response_time_ms
        })
        
        logger.info(f"Database health check PASSED ({response_time_ms}ms)")
        return True
        
    except Exception as e:
        response_time_ms = int((time.time() - start_time) * 1000)
        error_msg = f"Database connectivity test failed: {str(e)}"
        
        log_health_check('database', 'unhealthy', {
            'response_time_ms': response_time_ms
        }, error_msg)
        
        logger.error(f"Database health check ERROR: {error_msg}")
        return False

def test_whatsapp_connectivity():
    """Test WhatsApp service connectivity"""
    start_time = time.time()
    
    try:
        if not WHATSAPP_CONFIG['enabled']:
            log_health_check('whatsapp', 'disabled', {
                'response_time_ms': int((time.time() - start_time) * 1000)
            })
            return True
            
        if not whatsapp_client:
            error_msg = "WhatsApp client not initialized"
            log_health_check('whatsapp', 'unhealthy', {
                'response_time_ms': int((time.time() - start_time) * 1000)
            }, error_msg)
            return False
            
        # Test connection (without sending message)
        response_time_ms = int((time.time() - start_time) * 1000)
        
        log_health_check('whatsapp', 'healthy', {
            'target_number': WHATSAPP_CONFIG.get('target_number', 'not_set'),
            'response_time_ms': response_time_ms
        })
        
        logger.info(f"WhatsApp health check PASSED ({response_time_ms}ms)")
        return True
        
    except Exception as e:
        response_time_ms = int((time.time() - start_time) * 1000)
        error_msg = f"WhatsApp connectivity test failed: {str(e)}"
        
        log_health_check('whatsapp', 'unhealthy', {
            'response_time_ms': response_time_ms
        }, error_msg)
        
        logger.error(f"WhatsApp health check ERROR: {error_msg}")
        return False

def run_daily_health_check():
    """Run comprehensive daily health check"""
    logger.info("=== STARTING DAILY HEALTH CHECK ===")
    
    results = {
        'ai_diagnosis': test_ai_diagnosis(),
        'database': test_database_connectivity(),
        'whatsapp': test_whatsapp_connectivity()
    }
    
    # Count failures
    failures = [check for check, passed in results.items() if not passed]
    
    if failures:
        logger.warning(f"Health check FAILED for: {', '.join(failures)}")
        
        # Send WhatsApp notification if enabled and WhatsApp itself is working
        if WHATSAPP_CONFIG['enabled'] and whatsapp_client and 'whatsapp' not in failures:
            try:
                failure_message = f"ğŸš¨ ç³»çµ±å¥åº·æª¢æŸ¥è­¦å‘Š\n\nä»¥ä¸‹ç³»çµ±çµ„ä»¶å‡ºç¾å•é¡Œ:\n"
                for failure in failures:
                    status = SYSTEM_HEALTH_STATUS.get(failure, {})
                    error = status.get('error', 'Unknown error')
                    failure_message += f"âŒ {failure}: {error}\n"
                
                failure_message += f"\næª¢æŸ¥æ™‚é–“: {get_current_time().strftime('%Y-%m-%d %H:%M:%S')}"
                failure_message += f"\nè«‹æª¢æŸ¥ç³»çµ±ç‹€æ…‹: http://localhost:8081/admin"
                
                whatsapp_client.emit('send_message', {
                    'to': WHATSAPP_CONFIG.get('target_number'),
                    'message': failure_message
                })
                logger.info("Health check failure notification sent via WhatsApp")
                
            except Exception as e:
                logger.error(f"Failed to send health check notification: {e}")
    else:
        logger.info("=== ALL HEALTH CHECKS PASSED ===")
    
    return results

def run_scheduled_tasks():
    """Run scheduled maintenance tasks in background thread"""
    def scheduler_thread():
        # Schedule cleanup to run daily at 2 AM
        schedule.every().day.at("02:00").do(cleanup_old_analysis_reports)
        
        # Schedule daily health check at midnight (12:00 AM)
        schedule.every().day.at("00:00").do(run_daily_health_check)
        
        while True:
            schedule.run_pending()
            time.sleep(3600)  # Check every hour
    
    # Start scheduler in background thread
    scheduler = threading.Thread(target=scheduler_thread, daemon=True)
    scheduler.start()
    logger.info("Scheduled tasks initialized:")
    logger.info("- Diagnosis reports cleanup: daily at 2 AM")
    logger.info("- System health check: daily at 12 AM")

if __name__ == '__main__':
    # Initialize database and load saved config
    init_db()
    load_ai_config_from_db()
    load_whatsapp_config_from_db()
    
    # Initialize WhatsApp client
    init_whatsapp_client()
    
    # Start scheduled tasks
    run_scheduled_tasks()
    
    print(f"å·²è¼‰å…¥ {len(DOCTORS_DATA)} ä½é†«ç”Ÿè³‡æ–™")
    print("æ­£åœ¨å•Ÿå‹•AIé¦™æ¸¯é†«ç™‚é…å°ç³»çµ±...")
    print(f"ç•¶å‰AIæä¾›å•†: {AI_CONFIG['provider']}")
    
    if WHATSAPP_CONFIG['enabled']:
        print(f"WhatsAppé€šçŸ¥å·²å•Ÿç”¨ï¼Œç›®æ¨™è™Ÿç¢¼: {WHATSAPP_CONFIG['target_number']}")
    else:
        print("WhatsAppé€šçŸ¥æœªå•Ÿç”¨")
    
    if AI_CONFIG['provider'] == 'openrouter':
        if AI_CONFIG['openrouter']['api_key']:
            print(f"OpenRouteræ¨¡å‹: {AI_CONFIG['openrouter']['model']}")
            print("OpenRouter APIå¯†é‘°å·²è¨­ç½®")
        else:
            print("è­¦å‘Š: æœªè¨­ç½®OPENROUTER_API_KEYç’°å¢ƒè®Šæ•¸")
    elif AI_CONFIG['provider'] == 'openai':
        if AI_CONFIG['openai']['api_key']:
            print(f"OpenAIæ¨¡å‹: {AI_CONFIG['openai']['model']}")
            print("OpenAI APIå¯†é‘°å·²è¨­ç½®")
        else:
            print("è­¦å‘Š: æœªè¨­ç½®OPENAI_API_KEYç’°å¢ƒè®Šæ•¸")
    else:
        print(f"Ollamaæ¨¡å‹: {AI_CONFIG['ollama']['model']}")
        print("è«‹ç¢ºä¿Ollamaæœå‹™æ­£åœ¨é‹è¡Œï¼šollama serve")
    
    # Get host and port from environment variables
    host = os.getenv('FLASK_HOST', '0.0.0.0')
    port = int(os.getenv('FLASK_PORT', '8081'))
    debug = os.getenv('FLASK_DEBUG', 'True').lower() == 'true'
    
    app.run(debug=debug, host=host, port=port)
